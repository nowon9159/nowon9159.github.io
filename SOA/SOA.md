# Custom Instructions
## What would you like ChatGPT to know about you to provide better responses?
1. 나는 현재 AWS를 공부하고 있는 DevOps 엔지니어이다.
2. AWS SysOps 자격증을 기반으로 공부를 진행하고 있다.

## How would you like ChatGPT to respond?
1. 공부하는 내용을 정리하고 있으니, 형식을 구조화해서 동일한 형식으로 답변해줘
2. 형식은 아래 코드형식을 참조하면 돼. $overview는 개요 제목을 적어주면 돼. $title은 각 내용에 대한 주제의 제목을 적어주면 돼 $contents는 그 주제에 대한 내용을 일목 요연하게 정리해서 적어주면 돼 $tidr은 총 내용에 대한 정리를 해줬으면 좋겠어.
```markdown
**$overview**

**$title**
$contents

**$tidr**
```
3. 모든 문장은 영문으로 줄 건데, 영문은 출력할 필요 없고 한글로 출력해줘.
4. 제시해준 문장에 대해서 틀린 것 같은 내용이 있다면 해당 내용에 취소선 처리를 하고 아래에 왜 틀린지에 대한 설명을 부탁해. 설명은 Bold 처리해서 가시성을 확보해줘


# SOA 시험 대비
## **Enhanced Networking (향상된 네트워킹)**

인스턴스의 네트워크는 SR-IOV(Single Root - I/O Virtualization) 를 사용한다. 이는 더 높은 대역폭, 더 높은 PPS(초당 패킷), 낮은 지연을 제공한다.

이에 대한 두 가지 옵션이 있다.
가장 최근 옵션은 Elastic Network Adapter(ENA)로, 최대 100Gbps의 성능을 제공한다.
두번째로는 Legacy인 Intel VF(intel 82599 Virtual Function) 인터페이스가 있는데 10 Gbps를 제공한다.

ENA 어댑터는 T2를 제외한 최신 세대의 EC2 인스턴스에서 작동한다.

그리고 Elastic Fabric Adapter(EFA)가 있다. 이는 HPC(고성능 컴퓨팅) 전용으로 개선된 ENA이다. Linux에서만 작동하고, 같은 클러스터 내에 있는 경우 서로 결합된 많은 내부 노드 통신이 있다면 서로 더 나은 네트워크 성능을 얻는다. 이는 MPI(Message Passing Interface) 표준을 활용한다.

EFA는 EC2 인스턴스 간의 통신이 높아지기 때문에 더 고성능을 제공하며 기본 Linux OS를 우회하여 더 낮은 지연과 신뢰성 있는 전송을 제공한다.

요지는 낮은 지연을 위해 Enhanced Networking을 원한다면 ENA를 찾고, HPC 클러스터가 있다면 고성능을 위해 EFA를 찾아보자.

Amazon Linux 2 에는 모든 인스턴스에 ENA 모듈이 설치되어 있다.
`$ modinfo ena`를 입력하면 ENA 모듈이 EC2 인스턴스에 로드되어 있는 것을 볼 수 있다.
`$ ethtool -i eth0`를 입력하면 드라이버가 ena로 보여진다.

**정리**
-   인스턴스의 네트워크는 SR-IOV 유형을 사용해 더 높은 대역폭, 더 높은 PPS(초당 패킷), 낮은 지연을 제공한다.
-   SR-IOV는 ENA(Elastic Network Adapter)와 Intel VF(intel 82599 Virtual Function)가 있다.
    -   ENA의 경우 최대 100Gbps의 성능을 제공한다. 또한 t2를 제외한 최신 세대의 EC2 인스턴스에 기본적으로 설치되어 있다.
    -   Intel VF의 경우 10Gbps의 성능을 제공한다.
-   EFA(Elastic Fabric Adapter)가 있다.
    -   이는 HPC(고성능 컴퓨팅) 전용으로 개선된 ENA이다.
    -   Linux에서만 작동하고, MPI (Message Passing Interface) 표준을 활용해서 같은 클러스터 내에 있는 경우 서로 결합된 내부 노드 통신이 있다면 서로 더 나은 네트워크 성능을 얻는다. 
    -   EFA는 EC2 인스턴스 간 고성능 통신을 제공하고, 기본 Linux OS를 우회하여 더 낮은 지연과 신뢰성 있는 전송을 제공한다.
-   결과적으로 단순히 낮은 지연 시간을 위해 Enhanced Networking을 원한다면 ENA를, HPC 클러스터를 사용한다면 고성능을 위해 EFA를 선택하는 것이 좋다.

## **EC2 Placement Groups (배치 그룹)**
Placement Groups는 AWS 인프라 내에서 EC2 인스턴스가 어떻게 배치될지를 제어하려고 할 때 사용된다.

직접 AWS 하드웨어와 상호 작용하지는 않지만 EC2 인스턴스를 서로 어떻게 배치하길 원하는지 AWS에 알릴 수 있다. 

배치 그룹은 선택 사항이다. 인스턴스를 배치 그룹으로 시작하지 않으면 EC2는 기본 하드웨어 전반에 분산되어 인스턴스를 배치하려 한다.

인스턴스 생성시에 신규 또는 기존 배치 그룹에 인스턴스를 추가하도록 설정 가능

Placement Groups 를 생성할 때는 세 가지 전략을 사용할 수 있다.

### Cluster Placement Group (클러스터 배치 그룹)
인스턴스가 단일 가용 영역 내에서 저지연 하드웨어 설정에 그룹화된다.
이것은 높은 성능을 제공하지만 높은 위험도 제공한다.

모든 EC2 인스턴스가 동일한 랙에 배치되며 동일한 하드웨어를 공유하며 동일한 가용 영역에 속한다.
매우 낮은 대기 시간과 높은 네트워크 속도(대개 10 기가비트 정도)를 얻기 위해 수행된다.
우수한 네트워크를 얻지만, 우수한 네트워크의 단점은 랙에 장애가 발생하면 모든 EC2 인스턴스가 동시에 실패할 수 있다는 것이다.
모든 종류의 응용 프로그램에 적합한 것은 아니지만 응용 프로그램이 HPC와 같은 매우 높은 대역폭과 낮은 대기 시간이 필요한 경우 클러스터 배치 그룹이 좋은 방법이다.

### Spread Placement Group (분산 배치 그룹)
인스턴스가 서로 다른 랙에 분산된다.
이는 한 AZ 당 7개의 EC2 인스턴스로 제한되어 있다. 주로 중요한 응용 프로그램에 사용된다.

실패 위험을 최소화할 때 좋다.
EC2가 여러 가용 영역에 걸쳐 확장할 수 있으며 동시에 발생하는 실패의 위험이 줄어든다.
왜냐하면 하드웨어 1이 실패하면 하드웨어2가 실패하지 않을 것이기 때문이다.
이러한 구성에서는 AZ 당 Placement Group 당 7개의 인스턴스로 제한된다.
따라서 꽤 큰 규모의 응용 프로그램이어야 하지만 너무 크지 않아야 한다.
이는 고가용성을 극대화하고 위험을 감소시키려는 중요한 응용 프로그램에 사용된다.
AZ 당 Placement Group 당 7개의 인스턴스로 제한된다는 것을 명심해야한다.

### Partition Placement Group (파티션 배치 그룹)
Spread와 유사함. 인스턴스가 여러 파티션에 걸쳐 여러 가용 영역에서 분산된다.

한 AZ당 최대 7개의 파티션을 가질 수 있으며 이러한 파티션은 같은 Region의 여러 가용 영역에 걸쳐 확장될 수 있다.
각 파티션은 AWS에서 랙을 나타내며 많은 파티션을 가지고 있으면 인스턴스가 여러 하드웨어 랙에 분산되어 랙의 장애로부터 안전하다는 것을 보장한다.
이러한 설정으로 그룹 당 수백 개의 EC2 인스턴스까지 확장할 수 있다.

Spread Placement Group과의 차이점은 파티션 인스턴스와 다른 파티션의 인스턴스가 동일한 하드웨어 물리적 랙을 공유하지 않으며, 따라서 각 파티션은 실패로부터 격리된다.
하나의 파티션이 다운되면 파티션 번호 2가 다운되더라도 파티션 번호 1은 정상이어야한다.
이러한 EC2 인스턴스가 어느 파티션에 속하는지 알아내려면 메타데이터 서비스를 사용해 이 정보에 액세스할 수 있는 옵션이 있다.

파티션 배치 그룹의 경우 데이터를 분산하고 파티션 간에 서버를 분산할 수 있는 애플리케이션을 보유할 때 사용한다. 일반적으로 대용량 데이터 응용 프로그램에서 사용되며 HDFS, Hbase, Cassandra, Kafka를 사용하는 경우가 있다.


**정리**
-   배치 그룹은 EC2 인스턴스가 어떻게 배치될지를 제어하려고 할 때 사용된다.
-   배치 그룹은 선택 사항이며, 배치 그룹으로 시작하지 않으면 EC2는 기본 하드웨어 전반에 분산되어 인스턴스를 배치하려 한다.
-   배치 그룹은 세 가지 전략이 있다.
    -   **클러스터 배치 그룹**
        -   단일 가용 영역 내에서 저지연 하드웨어 설정에 그룹화된다. 높은 성능을 제공하지만 단일 가용 영역 내에 있기 때문에 높은 위험도 제공한다.
        -   모든 EC2 인스턴스가 동일한 랙에 배치되어 동일한 하드웨어, 동일한 가용 영역에 속한다.
        -   렉에 장애가 발생하면 모든 EC2 인스턴스가 동시에 실패하기 때문에 위험이 있다.
        -   HPC와 같은 매우 높은 대역폭과 낮은 대기 시간이 필요한 애플리케이션의 경우 클러스터 배치 그룹이 좋은 방법이다.
    -   **분산 배치 그룹**
        -   EC2가 여러 가용 영역에 걸쳐 확장할 수 있으며 동시에 발생하는 실패의 위험이 줄어든다.
        -   EC2 인스턴스가 각기 다른 랙에 분산된다.
        -   AZ 당, 배치 그룹 당 7개의 인스턴스로 개수가 제한된다.
        -   높은 가용성을 극대화하고 리스크를 줄이며 어느 정도 큰 규모의 애플리케이션에 적합하다.
    -   **파티션 배치 그룹**
        -   인스턴스가 여러 개의 파티션으로 여러 가용 영역에서 분산된다.
        -   한 AZ당 최대 7개의 파티션으로 동일 리전 내의 여러 가용 영역에 걸쳐 확장 가능. 파티션 당 수백 개의 인스턴스 실행 가능하다.
        -   한 파티션에 있는 랙을 다른 파티션은 공유하지 않는다.
        -   응용 프로그램이 데이터 및 서버를 파티션 간에 분산시킬 수 있는 경우 사용한다.

## EC2 Shutdown Behavior & Termination Protection

인스턴스는 중지(Stop)와 종료(Terminate)가 있음

종료는 또한 종료 방지(Termination Protection) 설정을 할 수 있어서 인스턴스를 생성하거나 생성하고 나서 종료 방지 설정을 할 수 있음. 훨씬 안전함
AWS Console이나 CLI의 우발적인 종료 동작을 막아준다.

종료 설정이 되어 있어도 OS 내에서 shutdown 명령어를 내리게 되면 Terminate 된다.
`$ sudo shutdown` 하게 되면 Terminated 되기 때문에 주의해야 함
> 팁으로는 init 0 또는 systemctl poweroff 명령어도 동일하다.

## Troubleshooting EC2 Launch Issues

**InsufficientInstanceCapacity**
리전 내에서 생성할 수 있는 최대 수치의 vCPU가 있다. 기본적으로 64GB인데 Service Quotas Request를 하게 되면 늘릴 수 있음

온디맨드 또는 Spot 인스턴스는 Default로 64GB로 되어 있음. 

만약 내가 Default 64GB인 상태에서 128GB의 인스턴스 타입을 선택하게 되면 인스턴스의 특정 AZ에 대해 온디맨드에 대한 특정 용량을 갖추지 못했다는 error임
이는 AWS에서 발생하는 문제이기도 하다. 왜냐하면 AZ에서 64GB가 준비되지 않았을 수도 있으니까

정리하자면 AWS에서 요청을 수행할 만큼의 충분한 가용 온디맨드 용량이 없기 때문이다.

해결 법은
-   몇 분 기다렸다가 다시 Request 하기
-   한 번에 적은 인스턴스를 요청해보기. 만약 내가 5개의 인스턴스를 한꺼번에 launch 했다고 했을 때, 1개 1개씩 신청하면 된다.
-   다른 인스턴스 형식을 요청하기. 완전 다른 인스턴스 유형을 선택 했다가 원하는 인스턴스 유형으로 스케일 업 해도 된다.
-   Service Quotas에 대한 Request하기

**Instance terminates immediately**
인스턴스가 pending 상태에서 Terminated 상태로 즉시 변경되는 것

이유는 아래와 같다.
-   EBS 볼륨 제한을 초과했을 때
-   EBS 스냅샷이 손상되었을 때
-   루트 볼륨이 암호화되어 있으며, 암호 해독을 위해 KMS 키에 액세스할 수 있는 권한이 없을 때
-   인스턴스 스토어 지원 AMI에 image.part.xx file과 같은 필수적인 부분이 누락 되었을 때

정확한 이유를 찾으려면 EC2 콘솔에서 Description 탭에 있는 State를 확인하면 된다.

**정리**
-   InsufficientInstanceCapacity
    -   리전 내에서 생성할 수 있는 최대 수치의 vCPU는 정해져있다. 예를 들어 최대 수치가 64로 되어 있다고 할 때 16 vCPU의 인스턴스를 5개 올리고 싶다면 16*5=80 이어서 최대 vCPU를 넘게 된다. 이 경우 해당 에러가 발생한다.
    -   또한 최대 수치를 조정했다고 하더라도 AWS 내에서 AZ에 64GB가 준비되지 않을 수도 있다.
    -   해결 법은 아래와 같다.
        -   몇분 기다렸다가 다시 Request
        -   한 번에 적은 인스턴스를 요청해보기 5개의 인스턴스를 1개씩 5번 시작
        -   다른 인스턴스 형식을 요청했다가 원하는 인스턴스 유형으로 스케일 업
        -   Service Qoutas에 대한 Request
-   Instance terminates immediately
    -   인스턴스가 Pending 상태에서 Terminated 상태로 즉시 변경되는 오류
    -   이유는 아래와 같다.
        -   인스턴스에는 할당할 수 있는 EBS 최대 개수가 있다. EBS 볼륨 제한을 초과했을 경우.
        -   EBS 스냅샷이 손상되었을 때
        -   루트 볼륨이 암호화되어 있을 경우 암호 해독을 위해 KMS 키에 액세스할 수 있어야 하는데 액세스 권한이 없을 때.
        -   인스턴스 스토어 지원 AMI에 image.part.xx file과 같은 필수적인 부분이 누락되어 있을 때

## Troubleshooting EC2 SSH Issues

### **Troubleshooting**
-   pem 키에 400 퍼미션이 아니라면 Unprotected private key file이라는 error가 발생하게 된다.
-   ssh 접속을 할 때 username이 맞지 않다면 "Host key not found", "Permission denied", "Connection closed by [instance] port 22" error가 발생하게 된다.
-   "Connection timed out" error 가 발생하게 되면 네트워크 오류이다.
    -   Security Group이 올바르게 되어있지 않은 경우
    -   NACL이 올바르게 되어있지 않은 경우
    -   Route table이나 subnet 문제 
    -   인스턴스가 Public IPv4 주소를 가지고 있지 않은 경우
    -   서버가 심각한 부하 상태여서 CPU가 100% 인 경우

### **SSH vs. EC2 Instance Connect**
-   SSH를 사용해 인스턴스에 연결하는 경우
    -   인바운드 룰에 맞는 host ip가 제대로 SG에 등록 되어 있는지
-   EC2 Instance Connect를 사용하는 경우
    -   SG에 [AWS IP Range](https://ip-ranges.amazonaws.com/ip-ranges.json)를 허용 했는지

**정리**
-   Troubleshooting
    -   pem 키에 퍼미션이 400이 아니라면 "Unprotected private key file"이라는 에러가 발생하게 된다.
    -   ssh 접속할 때 username이 맞지 않다면 "Host key not found", "Permission denied", "Connection closed by [instance] port 22" 에러가 발생하게 된다.
    -   "Connection imed out" 에러가 발생하게 되면 네트워크 오류
        -   Security group 문제
        -   NACL 문제
        -   Route table 또는 subnet 문제
        -   서버가 심각한 부하 상태여서 CPU가 100%인 경우


## \[CCP/SAA/DVA] EC2 Instance Purchasing Options
### **인스턴스 구매 옵션**
-   On-Demand Instance
    -   short workload, 예측 가능한 요금, 초 단위 비용 부과
-   Reserved (1 & 3 Year)
    -   Reserved Instances : long workload
    -   Convertible Reserved Instances : long workload, 어느정도 시간이 지난 후 인스턴스 유형을 변경할 경우 사용되는. 인스턴스 유형을 변경할 수 있는 Reserved Instances
-   Savings Plans (1 & 3 Year)
    -   특정 인스턴스 유형에 커밋하는 대신 특정 양의 사용량에 커밋해서 더욱 현대적이다.
    -   long workload
-   Spot instance
    -   짧은 워크로드에 적합함.
    -   언제든지 이 인스턴스를 잃을 수 있지만 가격이 굉장히 쌈
-   Dedicated Hosts
    -   전체 물리 서버를 예약하고 인스턴스 배치(Placement)를 조정 가능하다.
-   Dedicated Instances (전용 인스턴스)
    -   다른 고객에게 내가 사용하고자 하는 인스턴스의 하드웨어를 사용하게 하지 않는
-   Capacity Reservations (용량 예약)
    -   특정 AZ의 용량을 일정 시간동안 예약하는

### **EC2 On Demand**
-   Linux 나 Windows 인스턴스를 사용하게 되면 1분 후 초 단위 비용 과금이 되게 된다. 다른 OS의 경우 시간 단위 비용 과금이 된다.
-   원가는 제일 높지만 선급도 없고 장기적인 계약도 없다.
-   단기적이고 방해받지 않는 작업에 추천됨. 응용 프로그램이 어떻게 작동할지 예측할 수 없는 곳에 사용됨.

### **Reserved Instances**
-   온디맨드에 비해서 72% 정도 할인이 된다.
-   Instance Type(예:m4.large), Region, Tenancy, OS 등의 인스턴스 속성을 예약한다.
-   더 많은 할인을 받기 위해 1년이나 3년의 예약 기간을 명시하고 선결제 없음(No Upfront), 부분 선결제(partial Upfront), 전체 선결제(All Upfront)를 정해야한다.
-   범위 측면에서는 Regional 이거나 Zonal을 선택해야 한다. Zonal로 선택하게 되면 특정 Zone에 reserve 할 수 있고 조건이 맞을 시 할인이 됨
-   예약 인스턴스는 DB와 같이 꾸준히 사용되는 응용 프로그램에 추천된다.
-   예약 인스턴스를 Reserved Instance Marketplace에서 사거나 팔 수 있다.

### **Convertible Reserved Instance**
-   전환형 예약 인스턴스의 경우 EC2 instance type, instance family, OS, scope(Regional or zonal), tenancy를 변경할 수 있다.
-   더 많은 유연성을 가질 수 있어서 할인을 조금 덜 받을 수 있다. 66%

### **EC2 Savings Plans**
-   장기 사용량에 따라 할인을 받을 수 있도록 해준다. 예약 인스턴스와 같은 72% 임.
-   특정 Family에 대한 사용량을 기준으로 약정. 예를 들면 10$/hour로 1년 또는 3년 약정을 걸 수 있다.
-   Savings Plan로 약정을 건 외의 사용량은 On-demand 가격으로 청구된다.
-   특정 인스턴스 패밀리에 묶이게 된다. 예를 들어 us-east-1에 M5 타입의 인스턴스를 넣는다고 가정할 때 M5.xlarge 또는 M5.2xlarge 등 가능하다.
-   이외에 유연한 항목들은 Instance size, OS, Tenancy 가 있다.

### **Spot Instance**
-   온디맨드에 비해서 90%의 할인율을 자랑한다.
-   max price가 spot price 보다 작아지면 인스턴스는 중지 과정에 들어간다.
-   AWS에서 가장 비용 효율적인 인스턴스이다.
-   실패해도 크게 문제가 없는 workload에서 유용하게 사용될 것이다. 예를 들면 batch 작업이나, 데이터 분석, 이미지 프로세싱 등 모든 종류의 분산된 작업
-   그래서 데이터베이스나 종료되면 안되는 작업에는 적합하지 않다.

### **Dedicated Hosts**
-   물리적 서버와 EC2 인스턴스 용량을 확보해 실제 사용에 전념할 수 있다.
-   규정 요건을 준수하고 기존 서버 바운드 소프트웨어 라이센스를 사용할 수 있도록 허용한다. (소켓 당, 코어 당, VM 당 소프트웨어 라이센스)
-   요금의 경우 아래와 같다.
    -   온디맨드 : 1초당 요금 부과
    -   Reserved : 1 or 3 year (선결제 없음, 부분 선결제, 전체 선결제)
-   가장 비싼 Instance 옵션
-   사용 사례는 라이선스 모델이 있는 소프트웨어가 있을 때. (BYOL) , 규제 및 준수 요구가 강한 회사의 경우

### **Dedicated Instances**
-   인스턴스는 내 전용으로 할당된 하드웨어에서 실행된다. 동일 계정 내의 다른 인스턴스와 하드웨어를 공유할수도 있다.
-   인스턴스 배치에 대한 제어는 할 수 없다.
-   전용 인스턴스는 자체 하드웨어에서 실행되는 것을 의미하며, 전용 호스트는 물리적 서버에 직접 액세스 해 low-level의 하드웨어를 확인할 수 있다.

### **EC2 Capacity Reservations**
-   특정 AZ에 온디맨드 인스턴스를 일시적으로 예약할 수 있다. 예약 후에는 예약한 용량에 한해서 언제든지 액세스할 수 있다.
-   유일한 기능은 용량을 예약하는 것이기 때문에 요금이 할인되지는 않는다. 할인을 받으려면 Zonal RI나 SP와 결합해야한다.
-   인스턴스를 실행하던 실행하지 않던 온디맨드 요금이 청구된다.
-   이것은 특정 가용 영역에 필요한 단기의 작업에 적합하다.

**정리**
-   예를 들어 설명해보자
-   온디맨드는 리조트에 언제든지 들어가고 싶을 때마다 금액을 전액 지불해 시간제로 방을 사용할 수 있는 것과 같다.
-   Reserved Instance의 경우 미리 계획을 세우고 리조트에 1,3 년 동안 머물 생각이 확실항 때 사용한다.
-   Savings Plan의 경우 리조트에서 특정 금액을 지출할 것을 정확히 알고있을 때
-   Spot Instance의 경우 리조트가 빈 방이 있어서 사람들을 유치하려고 파격 세일을 하는 것과 같다. 근데 문제는 내가 지불한 금액보다 더 많이 지불하려하는 다른 사람이 있을 때 언제든지 방을 비워줘야한다.
-   Dedicated Instances 는 리조트 한 층을 예약하는 것과 같다.
-   Dedicated Host는 리조트 건물 전체를 예약하는 것과 같다.
-   Capacity Reservations는 내가 방을 예약할건데 언제 머물지 확실하지는 않지만 언제든지 머물수 있도록하는 것과 같다.
-   On-Demand
    -   Linux나 Window의 경우 1분 후 1초 단위의 비용 과금이 된다. 다른 OS의 경우 시간 단위 비용 과금이 된다.
    -   단기적이나 방해받지 않는 작업에 추천된다. 응용 프로그램이 어떻게 작동할 지 예측할 수 없는 곳에 사용된다.
-   Reserved Instance
    -   온디맨드 대비 72%의 할인이 된다. 할인을 받기 위해 1년 또는 3년의 약정 기간을 명시하고 선결제 없음(No Upfront)/부분 선결제(Partial Upfront)/전체 선결제(All Upfront) 등의 결제 방식을 정해야한다.
    -   범위 측면에서는 Regional 이나 Zonal을 선택해야한다. Zonal의 경우 특정 Zone에 예약되며 조건이 맞을 시 할인이 된다.
    -   Instance type(예:m5.large), Region, Tenancy, OS 등의 인스턴스 속성을 선택해야한다.
    -   예약 인스턴스는 DB와 같이 변동 없이 꾸준히 사용되는 응용 프로그램에 추천된다.
    -   예약 인스턴스는 Marketplace에서 사거나 팔수 있다.
-   Convertible Reserved Instance
    -   Reserved Instance와는 다르게 Instance type, Instance Family, OS, Scpoe, tenancy 등의 속성을 변경할 수 있다.
    -   더 많은 유연성을 가질 수 있어서 Reserved 보다는 할인이 덜 적용된다. (66%)
-   EC2 Savings Plan
    -   사용량에 따라 할인을 받을 수 있게 해준다. 예를들어 10$/hour로 1년 또는 3년 약정을 걸 수 있다.
    -   특정 인스턴스 Family에 약정된다. 예를 들어 M5 타입의 인스턴스에 약정되면 M5.large 또는 M5.midium 등 할인이 적용된다.
    -   Savings Plan으로 약정을 걸고 약정된 사용량을 넘어선 사용량은 On-Demand 가격으로 청구된다.
    -   Instance Size, OS, Tenancy는 변경이 가능하다.
-   Dedicated Instances
    -   하드웨어가 내 계정에 할당되어 동일 계정 내의 인스턴스만 해당 하드웨어에 할당되어 사용하는 옵션이다.
    -   인스턴스 배치에 대한 가시성이나 하드웨어 제어 기능을 제공하지 않고, 전용 인스턴스를 중지했다가 다시 실행하면 동일한 호스트에서 실행되지 않을 수도 있다.
    -   BYOL의 제한적 지원을 제공한다.
-   Dedicated Hosts
    -   물리적 서버를 구매하는 것과 동일하다고 생각하면 된다.
    -   가장 비싼 옵션
    -   사용 사례는 라이센스 모델이 있는 소프트웨어가 있을 때(BYOL), 규제 및 준수 요구가 강한 회사의 경우
-   Capacity Reservations
    -   특정 AZ에 온디맨드 인스턴스 용량을 일정 기간 예약할 수 있다. 용량을 확보하지 못할 위험을 줄일 수 있다.
    -   유일한 기능은 용량을 예약하느 것이기 때문에 요금이 할인되지는 않는다. 할인받기 위해서는 Zonal RI나 SP와 결합해야한다.
    -   인스턴스를 실행하던 실행하지 않던 온디맨드 요금이 청구된다.
    -   특정 가용 영역에 필요한 단기의 작업에 적합하다.

## **[SAA] Spot Instances & Spot Fleet**
### 스팟 인스턴스
온디맨드 가격보다 저렴한 비용으로 제공되는 예비 EC2 용량을 사용하는 인스턴스

스팟 인스턴스는 온디맨드 대비 최대 90% 할인을 받을 수 있다.

먼저 해당 스팟 인스턴스에 지불할 최대 스팟 가격(Maximum price)을 정의한다.
인스턴스의 현재 스팟 가격이 우리가 지불하려는 최대 가격보다 낮으면 인스턴스를 유지한다. 물론 시간 당 스팟 가격은 제공량과 capacity에 따라 변동하며 상승 및 하락한다.

현재 스팟 가격이 정의한 최대 가격을 초과하는 경우 두 가지 옵션이 있다. 이 두 가지 옵션에 대해서는 2분의 유예 기간이 제공된다. 그래서 이를 수행하는 데에는 약간의 시간이 주어진다.

옵션 중 하나는 수행 중인 모든 작업을 종료하고 인스턴스를 중지(Interruption)하는 것이다. Interruption된 상태에서 max 스팟 가격 아래로 내려간다면 인스턴스를 다시 시작하고 이전에 남은 작업을 계속할 수 있다.
또는 EC2 인스턴스를 종료(Terminate)하고 작업을 다시 시작해야 하는 경우 새로운 EC2 인스턴스로 시작할 수 있다.

워크로드 유형에 따라 두 가지 전략이 있지만 2분의 유예 기간이 주어진다.

### 스팟 블록
AWS에서 스팟 인스턴스를 회수하기를 원하지 않는다면 스팟 블록을 사용하면 된다.
스팟 블록은 정의된 기간 동안 용량을 예약하여 인스턴스가 지정된 기간 동안 실행되도록 하는 것이다.
BlockDuration 매개변수를 사용해 인스턴스를 실행할 시간과 지불할 최대 가격을 지정하기만 하면된다.

지정된 기간은 1시간부터 6시간까지 지정할 수 있으며 문서 상으로는 어떠한 interruption 없이 사용 가능하다.
문서 상으로는 특정 상황에서 인스턴스가 회수 될 수 있다. 전체적으로 고려했을 때 인스턴스가 회수되지 않을 것으로 예상된다.

스팟 인스턴스는 주로 배치 작업, 데이터 분석, 장애에 견딜 수 있는 작업에 사용된다. 그리고 중요한 작업이나 데이터베이스에는 적합하지 않는다.

***중요 : 스팟 블록은 Deprecated 되었음***

**스팟 인스턴스 가격**
특정 Region에 대해 특정 가용 영역에 해당하는 스팟 가격이 있다. 스팟 가격은 고려 중인 가용 영역에 따라 다양하다.

**스팟 인스턴스를 어떻게 종료하는가?**
스팟 request를 고려 해봐야한다. spot request에서는 원하는 인스턴스 수, 지불할 최대 가격, 런치 사양(AMI 등) 및 요청의 유효기간(valid to)과 두 가지 요청 유형 중 하나를 선택한다.

요청 유형은 두 가지이다.
-   일회성(One-time)
    -   일회성 요청의 경우 스팟 요청이 충족되면 즉시 인스턴스가 시작되고 스팟 요청이 사라진다.
-   영구 요청(Persistent request)
    -   영구 요청의 경우 특정 인스턴스 수가 스팟 요청의 valid 기간 내에서 유효할 때까지 요청이 계속 유효해야 한다.
    -   따라서 어떤 이유로든 인스턴스가 스팟 가격에 따라 중지(Interruption)되거나 중단(Termination)되면 스팟 요청이 다시 활성화된다. 그리고 유효한 경우 다시 시작된다.
    -   영구 요청에 경우 스팟 인스턴스를 중지하고 스팟 요청이 활성 상태인 경우 자동으로 인스턴스를 다시 시작한다.

스팟 요청을 취소하려면 open state, active state, disabled state 상태여야 한다.

인스턴스들을 종료하는 것은 AWS의 책임이 아닌 여전히 내 책임이다. 영구적으로 스팟 인스턴스를 종료하고 다시 시작하지 않으려면 스팟 요청을 취소한 다음 관련된 스팟 인스턴스를 종료해야 한다.
왜냐하면 스팟 인스턴스를 먼저 종료하면 스팟 요청으로 돌아가고 스팟 요청의 개수대로 유지하기 위해 인스턴스를 다시 실행할 것이기 때문이다.
https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/spot-requests.html

### 스팟 플릿 (강의 번역이 부실하여 강의 내용 기반 따로 정리함)
스팟 플릿은 사용자가 지정한 기준에 따라 시작되는 스팟 인스턴스의 집합이며 온디맨드 인스턴스도 선택적으로 집합을 구성할수 있다.

스팟 플릿은 사용자의 요구 사항을 충족하는 스팟 용량 풀을 선택하고 플릿에 대한 목표 용량을 충족하는 스팟 인스턴스를 시작한다.
* 스팟 용량 풀은 인스턴스 유형, 운영 체제, 가용 영역, 네트워크 플랫폼(EC2-Classic 또는 EC2-VPC)이 동일한 미사용 EC2 인스턴스의 집합입니다. 각 스팟 용량 풀은 수요와 공급에 따라 가격이 달라질 수 있습니다.

기본적으로 스팟 플릿은 스팟 인스턴스가 종료된 후 대체 인스턴스를 시작하여 target capacity를 유지하도록 설정되어 있다. 스팟 플릿 인스턴스가 종료된 후에 유지되지 않는 일회성 request로 제출할 수도 있다. 스팟 플릿 request에 온디맨드 인스턴스 요청을 포함할 수 있다.

요청 유형
-   request
    -   스팟 플릿이 원하는 용량을 얻기 위한 비동기식 일회성 요청을 한다.
    -   그 뒤에 스팟 중단으로 용량이 감소하게되면 인스턴스를 보충하려고 하지 않으며, 용량을 사용할 수 없는 경우 대체 스팟 용량에서 요청을 제출하지 않는다.
-   maintain
    -   스팟 플릿은 원하는 용량을 얻기 위한 비동기식 요청을 하고 중단된 모든 스팟 인스턴스를 자동으로 보충해 용량을 유지한다.
-   콘솔에서 유형을 지정하려면 Maintain target capacity 확인란을 선택/취소하면 된다.

launch configuration은 스팟 플릿이 스팟 인스턴스를 시작할 수 있는 모든 스팟 용량 풀(인스턴스 유형, 가용 영역)을 결정한다. 하지만 인스턴스를 시작할 때 스팟 플릿은 지정한 할당 전략을 사용하여 가능한 풀에서 특정 풀을 선택합니다.

스팟 인스턴스 할당 전략
-   priceCapacityOptimized(권장)
    -   스팟 플릿은 시작하는 인스턴스의 수에 맞추어 용량 가용성이 가장 높은 풀을 가져온다. 즉, 가까운 시일 내에 중단될 가능성이 가장 낮다고 판단되는 풀에서 스팟 인스턴스를 요청. 그러면 스팟 플릿이 해당 풀에서 가장 가격이 낮은 스팟 인스턴스를 요청한다.
-   capacityOptimized
    -   시작하는 인스턴스의 수에 맞추어 용량 가용성이 가장 높은 풀을 가져온다.
    -   즉, 가까운 시일 내에 중단될 가능성이 가장 낮다고 판단되는 풀에서 스팟 인스턴스를 요청.
    -   선택적으로 capacityOptimizedPrioritized를 사용하여 플릿의 각 인스턴스 유형에 대해 우선 순위를 설정할 수 있음
-   diversified
    -   스팟 인스턴스는 모든 풀에 두루 분산
-   lowestPrice
    -   스팟 인스턴스는 용량이 있는 최저 가격 풀에서 제공. 매우 짧은 워크 로드의 경우 좋은 옵션
    -   인스턴스 가격만 고려하고 용량 가용성은 고려하지 않기 때문에 중단률이 높아질 수 있다.
-   InstancePoolsToUseCount : 스팟 플릿에서 가격이 가장 낮은 스팟 풀을 선택하고 지정한 스팟 풀 수에 걸쳐 대상 스팟 용량을 균등하게 할당

기억해야할 점은 스팟 플릿을 사용하여 여러 launch pool과 여러 인스턴스 유형을 정의할 수 있다는 것

그리고 스팟 플릿에서 lowestPrice 전략을 사용하면 스팟 플릿은 자동으로 최저 가격의 스팟 인스턴스를 요청할 것이다.
따라서 스팟 플릿은 최대한의 절약을 얻을 수 있도록 올바른 인스턴스 풀을 선택하는 데 도움이 되어 추가 절약을 제공한다. 이것이 스팟 플릿의 이점

간단히 스팟 플릿을 요청하는 것과 스팟 플릿을 사용해 `내가 원하는 인스턴스 유형과 원하는 가용 영역을 정확히 알고 있고, 어떤 풀에서 최저 가격을 제공하더라도, 모든 인스턴스 유형과 모든 가용 영역 중에서 선택할 수 있도록 하겠습니다` 라고 말하는 것의 차이를 이해해야 한다.

**스팟 용량 풀**
-   스팟 용량 풀은 동일한 인스턴스 유형(예: m5.large), 운영 체제, 가용 영역 및 네트워크 플랫폼을 가지는 미사용 EC2 인스턴스의 세트입니다. 스팟 플릿 요청을 할 때 인스턴스 유형, AMI, 가용 영역 또는 서브넷에 따라 바뀌는 여러 시작 사양을 포함할 수 있습니다. 스팟 플릿은 요청에 포함된 시작 사양과 스팟 플릿 요청의 구성을 기반으로 스팟 플릿 요청을 이행하는 데 사용되는 스팟 용량 풀을 선택합니다. 스팟 인스턴스는 선택한 풀에서 가져옵니다.

**정리**
-   Spot Instance
    -   스팟 인스턴스는 온디맨드 가격보다 저렴한 비용으로 제공되는 예비 EC2 용량을 사용하는 인스턴스
    -   먼저 실행하고자 하는 스팟 인스턴스에 지불할 최대 스팟 가격을 지정하고, 인스턴스의 현재 스팟 가격이 우리가 지불하려는 최대 스팟 가격보다 미만이면 인스턴스를 유지한다.
    -   현재 스팟 가격이 최대 가격을 초과하는 경우 두 가지 옵션이 있다.
        1.   수행중인 모든 작업을 종료하고 인스턴스를 중지(Interruption)하는 것. Interruption 된 상태에서 최대 스팟 가격 아래로 내려간다면 인스턴스를 다시 시작하고 이전에 남은 작업을 계속할 수 있다.
        2.   EC2 인스턴스를 종료(Terminate)하고 작업을 다시 시작해야 하는 경우 새로운 EC2 인스턴스로 시작.
        -   워크로드 유형에 따라 두 가지 전략이 있고 위 작업을 수행하기 전에 2분의 유예 기간이 주어진다.
    -   스팟 인스턴스는 스팟 request에 따라 다르게 종료된다. request에는 원하는 인스턴스 수, 지불할 최대 가격, 런치 사양(AMI) 및 요청의 유효기간(valid to)(persistent의 경우)와 요청 유형이 있다.
        -   요청 유형은 두가지 이다.
        -   `일회성(One-time)` 요청의 경우 스팟 요청이 충족되면 인스턴스가 시작되고 스팟 요청이 사라진다.
        -   `영구 요청(Persistent request)` 요청의 경우 특정 인스턴스 수가 스팟 요청의 valid to 기간까지 또는 취소될 때까지 요청이 계속 유효하다.
        -   따라서 인스턴스가 중지되거나 중단되면 스팟 요청이 다시 활성화 돼 인스턴스 수를 보장해준다.
    -   영구적으로 스팟 인스턴스를 종료하는 것은 AWS가 아닌 내 책임이다. 영구적으로 스팟 인스턴스를 종료하려면 스팟 요청을 취소한 후 스팟 인스턴스를 종료해야 한다. 그렇지 않으면 request를 계속 유지하기 위해서 인스턴스를 다시 실행할 것이기 때문
-   Spot Fleet
    -   스팟 플릿은 사용자가 지정한 기준에 따라 시작되는 스팟 인스턴스의 집합이다. 선택적으로 스팟 인스턴스 외에 온디맨드 인스턴스도 구성 가능하다.
    -   스팟 플릿은 사용자 요구 사항을 충족하는 스팟 용량 풀을 선택하고 플릿에 대한 목표 용량을 충족하는 스팟 인스턴스를 시작한다.
    -   스팟 용량 풀: 스팟 용량 풀은 인스턴스 유형, 운영 체제, 가용 영역, 네트워크 플랫폼(EC2-Classic 또는 EC2-VPC)이 동일한 미사용 EC2 인스턴스의 집합입니다. 각 스팟 용량 풀은 수요와 공급에 따라 가격이 달라질 수 있습니다.
    -   기본적으로 스팟 플릿은 target capacity를 유지하도록 설정 돼 있다. 스팟 인스턴스가 종료되어도 대체 인스턴스를 시작한다.
    -   스팟 플릿 인스턴스가 종료된 후에 유지되지 않는 일회성 request로 제출할 수도 있다.
    -   요청 유형은 request와 maintain이 있다.
        -   request:
        -   스팟 플릿이 원하는 용량을 얻기 위한 비동기식 일회성 요청을 한다.
        -   그 뒤 스팟 중단으로 용량이 감소해도 인스턴스를 보충하지 않고, 용량을 사용할 수 없는 경우에도 대체 스팟 용량에서 요청을 제출하지 않는다.
        -   maintain: 
        -   스팟 플릿은 원하는 용량을 얻기 위한 비동기식 요청을 하고 중단된 모든 스팟 인스턴스를 자동으로 보충해 용량을 유지한다.
    -   요청 유형을 콘솔에서 지정하려면 Maintain target capacity 확인란을 선택/취소하면 된다.
    -   할당 전략이 있다.
        -   **priceCapacityOptimized(권장)**:
        -   스팟 플릿은 시작하는 인스턴스의 수에 맞춰 용량 가용성이 가장 높은 풀을 가져온다.
        -   가까운 시일 내에 중단될 가능성이 가장 낮다고 판단되는 풀에서 스팟 인스턴스를 요청하고, 해당 풀에서 가장 가격이 낮은 스팟 인스턴스를 요청한다.
        -   **capacityOptimized**:
        -   시작하는 인스턴스 수에 맞춰 용량 가용성이 가장 높은 풀을 가져온다.
        -   가까운 시일 내에 중단될 가능성이 가장 낮다고 판단되는 풀에서 스팟 인스턴스를 요청
        -   선택적으로 capacityOptimizedPrioritized를 사용해서 플릿의 각 인스턴스 유형에 대해 우선 순위를 설정할 수 있다.
        -   **diversified**:
        -   스팟 인스턴스를 모든 풀에 두루 분산
        -   **lowestPrice**:
        -   스팟 인스턴스를 용량이 있는 최저 가격 풀에서 제공, 매우 짧은 워크로드의 경우 좋은 옵션
        -   인스턴스 가격만 고려하고 용량 가용성은 고려하지 않기 때문에 중단률이 높아질 수 있다.
        -   **InstancePoolsToUseCount**: 
        -   스팟 플릿에서 가격이 가장 낮은 스팟 풀을 선택하고 지정한 스팟 풀 수에 걸쳐 대상 스팟 용량을 균등하게 할당


## **Burstable Instances (T2/T3)**
T2,T3 인스턴스 유형의 경우 부하가 급증하는 경우 CPU가 burst될 수 있다.
이 burst라는 것은 CPU가 부하를 처리할 수 있게 성능이 좋아진다는 말이다.

인스턴스가 burst되게 되면 통상 burst credit이라고 하는 크레딧이 있고, 인스턴스가 수명 주기를 가지고 있으며 CPU가 강력히 사용될 때 이 credit이 사용된다.

모든 크레딧이 소진되면 CPU 성능이 매우 나빠지며 인스턴스를 올바르게 사용할 수 없게 된다.
그러나 인스턴스의 부하가 급증하지 않아 CPU가 많이 사용되지 않으면 credit은 시간이 지나면서 다시 축적되어 필요할 때마다 재사용할 수 있다.

인스턴스는 예상치 못한 유형의 트래픽을 처리하는 데 훌룡할 수 있으며 올바르게 처리된다면 굉장히 유용한 유형의 인스턴스가 될 수 있다.
그러나 인스턴스가 일관되게 낮은 크레딧을 소비한다면 T 계열을 올바르게 사용하고 있는 것이 아닐 수 있으므로 다른 유형의 인스턴스로 전환해야 할 것이다.

CloudWatch 모니터링에서 이를 살펴볼 수 있다.

맹점은 credit이 0에 도달하면 CPU 사용률은 실제로 100%가 아니게 된다.

이를 해결하기 위해 T2 및 T3 Unlimited라는 것이 있다.

Unlimited는 무제한의 burst credit 잔액을 제공해 credit이 0에 도달해도 원하는 만큼 사용할 수 있다.
아무리 CPU가 과부하 되더라도 credit 잔액을 초과한 추가 비용만 지불하면 성능에 손실이 발생하지 않는다.

24시간 동안 또는 인스턴스 수명(더 짧음) 동안 인스턴스의 평균 CPU 사용률이 기준 이하인 경우에 모든 CPU 사용량 급증에 대해 시간당 CPU 인스턴스 요금이 적용된다.
이말인 즉슨 24시간 평균 CPU 사용률을 초과하는 사용량에 대해 사용한 CPU 당 시간 당 요금을 내게 된다.

그래서 항상 100%를 사용하는 CPU 인스턴스가 있다면 많은 요금이 추가 청구 될 수 있어 주의해야 한다.

**정리**
-   Burstable 은 T2, T3 인스턴스 유형군이다.
-   기본적으로 위 인스턴스 유형 군은 CPU 사용량 대비해 burst credit이라는 것을 가지고 있다.
-   이 burst credit이라는 것은 CPU가 과도하게 사용될 경우 credit을 소진해 CPU를 고성능으로 만들어 과부하된 CPU를 처리할 수 있게 해준다.
-   credit은 CPU가 과부하되지 않을 때 시간 단위로 축적이 되고, 최대 축적 credit이 정해져있다. credit을 다 소진하게 되면 CPU 성능이 현저히 떨어진다.
-   그래서 Unlimited라는 것이 있다. Unlimited는 무제한의 credit을 제공해 CPU 사용량이 과부하 되고 크레딧을 전부 소진하더라도 추가 비용만 지불하면 CPU 성능을 보장해준다.
    -   24시간을 기준으로 인스턴스 평균 CPU 사용률이 기준 사용률을 초과하는 사용률에 대해 사용한 vCPU 당 시간 당 요금을 내게 된다.

## **Elastic IPs**

EC2 인스턴스를 중지하고 시작하면 Public IP가 변경된다. 고정된 IP가 필요하다면 EIP가 필요하다.

EIP는 삭제하지 않는 한 변경되지 않고 소유할 수 있는 IPv4 IP이다. 이는 예약된 것이므로 EIP를 한 번에 한 EC2 인스턴스에 연결하고 해당 EC2 인스턴스가 해당 IP의 IPv4를 상속하도록 한다.

이 IP를 인스턴스 간에 다시 매핑할 수 있고, 서버에 연결된 경우 EIP에 대한 요금을 지불하지 않는다.
EIP를 연결하지 않은 경우 요금이 청구된다.

EIP를 사용하면 인스턴스나 소프트웨어의 장애를 순식간에 계정 내에서 소프트웨어를 실행 중인 다른 인스턴스로 주소를 다시 매핑하여 조치할 수 있다.

기본적으로 AWS 리전 당 최대 다섯 개의 EIP를 보유할 수 있다.
AWS에 요청해 Quota를 늘릴 수 있지만 강사 개인의 의견으로는 꼭 필요하지 않은 경우에 EIP를 사용하는 것을 피해야 한다고 한다.

다른 대안은 임의의 Public IP를 사용하고 Route53을 사용해 DNS 이름을 등록하거나 로드 밸런서를 사용하는 것이다.

로드 밸런서는 정적 호스트 이름을 가지고 있으며 로드 밸런서는 올바른 EC2 인스턴스로 리디렉션할 수 있다.


**정리**
-   EC2 인스턴스에 Public IP는 중지 후 재시작을 하게 되면 IP 주소가 변경이 된다. 이를 방지하기 위해서 Elastic IP라는 고정 IP가 있다.
-   이 IP를 자유롭게 Attach 또는 Detach 할 수 있고, EIP는 삭제하지 않는 한 변경되지 않고 소유하는 IP이다.
-   서버에 EIP가 연결된 경우 요금이 부과되지 않으며, EIP가 연결된 서버를 중지하거나 사용하지 않는 EIP의 경우 요금이 부과되게 된다.
-   리전 당 5개의 quota로 되어 있으며, 늘릴 수 있다. 강사는 EIP를 사용하기보다 ELB나 임의의 Public IP를 사용하는 것을 추천했다.

## **CloudWatch Metrics for EC2**
CloudWatch가 EC2와 어떻게 연결되어 있는지 알아보는 것은 중요하다. 이는 시험에서 중요한 부분이다.

AWS는 EC2 인스턴스에 대한 몇 가지 메트릭을 제공하며 AWS는 이러한 메트릭을 자동으로 수집(push)한다.
기본 모니터링이 있으며 이 경우 메트릭은 5분 간격으로 수집된다. 그러나 세부(detailed) 모니터링을 활성화할 수 있고, 이 경우에는 메트릭이 1분 간격으로 수집된다.

이 메트릭에는 CPU, 네트워크, 디스크 및 Status 확인 메트릭이 포함된다.
위 네 가지 매트릭은 매우 중요하다.

사용자 지정 메트릭을 사용할 수도 있다. 이는 사용자가 푸시하는 사용자 지정 메트릭이다. 사용자 지정 메트릭의 기본 resolution은 1분이지만 최대 1초까지의 사용자 지정 메트릭을 사용할 수 있다.

EC2의 사용자 지정 메트릭을 푸시하려면 EC2 인스턴스에 CloudWatch에 메트릭을 푸시할 수 있는 권한이 있는 IAM 역할이 있어야 한다. (Agent 설정해야해서)

**EC2 메트릭**
첫번째로는 CPU 메트릭이다.

CPU Utilization을 확인 가능하고, T2 또는 T3 인스턴스와 같이 버스트가 발생하는 경우에는 버스트의 크레딧 사용량과 크레딧 잔액을 확인할 수 있다.

네트워크의 경우 인스턴스로 들어오고 나가는 네트워크 양을 확인할 수 있다.

상태 확인(health check)은 본질적으로 인스턴스가 건강한지 여부를 확인한다.
EC2 인스턴스가 작동하는지 여부를 Amazon이 확인하고 기본 하드웨어가 작동하는지 확인하는 시스템 상태도 Amazon이 확인한다.
시스템 상태 확인은 Amazon이 수행하는 Health Check 이므로 사용자는 이에 대한 제어권이 없지만, instance status와 system status를 구분할 수 있어야 한다.

인스턴스 스토어를 사용하는 경우에만 EC2 인스턴스에 대한 디스크 정보를 얻을 수 있다. 이 인스턴스 스토어는 디스크에 대한 읽기 및 쓰기 작업 또는 바이트를 제공한다. (EBS에 대한 지표를 확인하기 위해서는 Agent를 설치해야 함)

RAM은 AWS EC2 메트릭에 포함되어 있지 않는다.
시험에 자주 CloudWatch에서 RAM 사용량을 얻을수 있는지 물어본다.
AWS는 CloudWatch에 RAM 사용량을 푸시하지 않는다.

Metric에 대해 자세히 확인해보자

상태 확인의 경우 EC2 인스턴스가 하드웨어 레벨이나 소프트웨어 레벨에서 문제를 겪고 있는지 여부를 확인하는 방법이다. 0과 1 사이의 값으로 나타나고 1의 경우 Fail이 되었다는 이야기

네트워크 IN과 OUT은 당연하게 EC2 인스턴스에 들어오고 나가는 네트워크의 양 및 패킷 수를 나타낸다.

디스크 읽기 및 디스크 쓰기는 0처럼 보이며 우리의 EC2 인스턴스에 EBS 볼륨이 연결되어 있기 때문에 정상이다.
디스크 읽기 및 쓰기 메트릭은 EBS 볼륨 자체에서 확인할 수 있다.
그러나 EC2 인스턴스가 인스턴스 스토어가 있는 EC2 인스턴스인 경우 이러한 메트릭이 채워져 있는 것을 볼 수 있다.

AWS 버스터블 유형의 경우 CPU 크레딧 사용량을 확인할 수 있다.
또한 CPU 크레딧 밸런스가 있다. EC2 인스턴스를 사용하지 않으면 CPU 크레딧 밸런스가 시간이 지남에 따라 증가한다.

EC2 Detailed monitoring을 활성화하면 다음 과정을 거친다.
상태 확인 -> 모니터링 -> 자세한 모니터링 관리
이렇게 하면 5분 간격이 아닌 1분 간격의 그래프가 표시된다.
자세한 모니터링을 활성화하면 추가 비용이 발생할 수 있다.

**정리**
-   AWS는 EC2 인스턴스에 대한 몇 가지 메트릭을 제공하며 AWS는 이러한 메트릭을 자동으로 수집(push)한다.
-   기본 모니터링은 5분 간격으로 수집하지만 detailed monitoring을 활성화하게되면 1분 간격으로 수집한다.
-   메트릭은 CPU, Network, 디스크, Status 메트릭이 포함된다.
-   기본적으로 RAM에 대한 지표는 지원하지 않는다. 기본적으로 CloudWatch에서 RAM 사용량을 확인할수는 없다.
-   사용자 지정 메트릭을 사용할 수도 있다. 사용자 지정 메트릭의 기본 resolution은 1분이지만 최대 1초 간격의 메트릭을 수집할수도 있다.
    -   사용자 지정 메트릭을 사용하려면 EC2에 CloudWatch에 메트릭을 푸시할수 있는 IAM Role이 필요하다.
-   EC2 메트릭
    -   CPU Utilization은 0~100% CPU 사용량을 확인 가능하다.
    -   Status check는 EC2 인스턴스가 하드웨어 또는 소프트웨어 레벨에서 문제를 겪고 있는지 확인하는 방법이다. 0과 1의 값이고 1의 경우 Fail이 발생했다는 이야기
    -   Network in and out은 EC2 인스턴스에 들어오고 나가는 네트워크의 양 및 패킷 수를 나타낸다.
    -   디스크 읽기 및 디스크 쓰기는 0으로 보일 것이다. 인스턴스는 EBS 볼륨이 연결되어 있기 때문에 0으로 보이는 것이 정상 상태이다. 디스크 읽기 및 쓰기 메트릭은 EBS 볼륨에서 볼 수 있다. 그러나 인스턴스 스토어가 있는 EC2의 경우 이러한 메트릭이 0이 아닐 것이다.
    -   CPU 크레딧 사용이 있다. AWS 버스터블 유형(t2/t3) 인스턴스의 경우 크레딧을 사용한다.
    -   CPU 크레딧 밸런스를 확인할 수 있다. EC2 인스턴스를 사용하지 않으면 CPU 크레딧 밸런스가 시간이 지남에 따라 증가한다.

## **CloudWatch - Unified CloudWatch Agent - Overview**
EC2 인스턴스 내에서 메트릭 및 로그를 수집하는 방법에 대해 알아보자.
이를 위한 것이 CloudWatch Unified Agent이다.

EC2 인스턴스나 온프레미스 서버에도 적용할 수 있다.

이 에이전트를 사용해 추가적인 시스템 수준 메트릭(RAM, 프로세스, 사용중인 디스크 공간 등)을 수집할 수 있다.

또한 로그를 CloudWatch Logs로 전송할 수 있다.
기본적으로 EC2 인스턴스를 시작하면 인스턴스에서 CloudWatch Logs로 파일이나 로그가 전송되지 않는다.

에이전트를 구성하려면 SSM Parameter Store를 사용해 구성을 중앙 집중식으로 저장하거나 대안으로 Configuration 파일을 지정할 수 있다.

통합 CloudWatch 에이전트가 있는 EC2 인스턴스에서 메트릭 및 로그를 CloudWatch로 전송하려면 에이전트를 구성하고 올바른 권한이 있는지 확인해야 한다.

온프레미스에서도 동일하게 권한 설정을 해주어야한다. 온프레미스에서 Agent에 대한 권한은 Agent를 실행하는 데 필요한 IAM User를 생성하고 해당 User에 대한 권한을 받는 형식이다.

Agent에 의해 푸시되는 모든 메트릭은 CWAgent 접두사로 시작한다. 이는 네임스페이스에 해당한다. 변경할 수는 있지만 기본값은 이것이다.

시험에서 나오는 중요한 내용 중 하나는 Agent에 procstat 플러그인이 있다는 것이다.
procstat 플러그인을 사용하면 Linux 또는 Windows 서버에서 실행 중인 개별 프로세스의 메트릭을 수집하고 시스템 사용률을 모니터링할 수 있다.

예를 들어 프로세스가 사용하는 CPU 사용 시간, 프로세스가 사용하는 메모리 양 또는 EC2 인스턴스에서 직접 실행되는 프로세스에 대한 정보를 얻을 수 있다.

pid_file로 모니터링할 프로세스를 선택할 수 있다. PID 번호 또는 프로세스의 이름 또는 패턴으로 파일을 얻을 수 있다.

이 플러그인을 사용해 모니터링할 프로세스를 필터링하려면 프로세스에 관한 통계와 관련된 모든 메트릭은 procstat 접두사로 시작한다. 따라서 프로세스가 실행되고 관련 메트릭을 얻고자 하는 경우 Unified CloudWatch Agent를 사용하고 해당 플러그인을 구성해야한다.

**정리**
-   EC2 인스턴스 내에서 메트릭 및 로그를 수집하는 방법은 CloudWatch Unified Agent이다. EC2 인스턴스 또는 온프레미스 서버에서도 사용 가능하다.
-   이 에이전트를 사용해 추가적인 메트릭(RAM, 프로세스, 사용중인 디스크 공간)이나 로그를 수집할 수 있다.
-   기본적으로 EC2 인스턴스를 실행하면 CloudWatch Logs로 파일이나 로그가 전송되지 않는데, Agent를 설치하면 전송할 수 있다.
-   Agent를 구성하려면 SSM Parameter Store를 이용해서 중앙 집중식으로 Config를 저장하거나 대안으로 Configuration 파일을 직접 지정할 수 있다.
-   EC2 인스턴스에서 메트릭 및 로그를 CloudWatch로 전송하려면 올바른 권한이 있는지 확인해야한다. 이는 온프레미스에서도 동일하며 온프레미스의 경우 AWS IAM User를 생성해 해당 User의 권한을 이용해야 한다.
-   Agent에 의해 푸시되는 모든 메트릭은 CWAgent 접두사로 시작한다. Namespace라는 항목으로 표시되고 변경 가능하다.
-   시험에서 나오는 중요한 내용 중 하나는 Agent에 procstat 플러그인이 있다는 것이다.
    -   procstat 플러그인은 Linux 또는 Windows 서버에서 실행 중인 개별 프로세스의 메트릭을 수집하고 시스템 사용률을 모니터링할 수 있다.
    -   예를 들어 프로세스가 사용하는 CPU 사용 시간, 프로세스가 사용하는 메모리 양 또는 EC2 인스턴스에서 직접 실행되는 프로세스에 대한 정보를 얻을 수 있다.
    -   pid_file로 모니터링할 프로세스를 선택할 수 있다. PID 번호 또는 프로세스의 이름 또는 프로세스의 이름 정규식 패턴으로 프로세스를 지정할 수 있다.
    -   procstat을 사용해 모니터링할 모든 메트릭은 procstat 접두사로 시작된다.

## **EC2 Instance Status Checks**

EC2 인스턴스의 상태 확인은 AWS가 자동으로 수행하는 작업으로, EC2 인스턴스의 하드웨어 및 소프트웨어 문제를 식별한다.

두 가지 유형이 있다. 

첫 번째 유형은 system status check 이는 AWS 시스템에서 발생하는 문제를 모니터링한다.

예를 들어 실제 물리 호스트에 대한 소프트웨어 또는 하드웨어 문제 또는 호스트가 시스템 전원을 잃는 경우와 같은 상황이다.
이러한 문제에 대한 overview를 확인하려면 personal health dashboard를 확인하면 된다.
이 대시보드에서는 AWS가 예정된 사항이나 critical maintenance 항목을 제공하며 이 항목들은 EC2 인스턴스 호스트에 영향을 미칠 것으로 조치해야 한나다.
조치 방법 중 하나는 인스턴스를 중지하고 시작하는 것이다. 

EC2는 우리 눈에는 보이지 않는 과정을 거친다. 우리가 EC2 인스턴스를 중지하고 시작하게 되면 자동으로 AWS 데이터센터 내의 다른 호스트로 마이그레이션 된다.

예를 들어 호스트 1에서 EC2 인스턴스가 실행중이던 상황에서 중지하고 시작하게 되면 호스트 2로 EC2 인스턴스가 마이그레이션 된다.

단순히 중지하고 시작했기 때문에 새로 시작된 호스트 2에는 문제가 없으며, 하드웨어 장애 문제를 해결할 수 있다.

두 번째 유형은 instance status check 이다.

인스턴스의 소프트웨어 및 네트워크 구성을 모니터링한다. 예를 들어, 네트워크 구성이 잘못 되었거나 메모리가 고갈된 경우이다.

이 문제를 해결하려면 EC2 인스턴스를 reboot하거나 인스턴스 구성을 변경하면 된다.

자동으로 복구하고 CloudWatch 메트릭을 확인하는 방법도 있다.
StatusCheckFailed_System, StatusCheckFailed_Instance 또는 이러한 두 메트릭을 하나의 메트릭으로 그룹화한 StatusCheckFailed이 있다.

첫번째로는 CloudWatch Alarm으로 복구하는 방법이 있다. 이 Alarm에는 인스턴스를 복구하는 recover instance라는 작업(Action)이 있다.
작업이 수행되면 인스턴스는 동일한 Private IP, 동일한 Public IP, 동일한 EIP, 동일한 메타데이터 및 동일한 배치 그룹을 사용해 인스턴스를 복구한다.

또한 CloudWatch Alarm이므로 SNS와 같은 곳으로 알림을 보낼 수도 있다.
EC2 인스턴스는 CloudWatch 메트릭을 통해 상태 확인이 실패한 경우를 모니터링하고 복구할 수 있다.

또한 두번째로는 다른 방법 옵션 2도 있다. 덜 일반적인 방법이다.

auto scaling group min max와 desired 1을 설정하는 것이다.
그리고 상태 확인을 통해 EC2 인스턴스의 상태 확인을 확인한다.

이 경우 EC2 인스턴스에 문제가 발생하면 ASG에 의해 인스턴스가 종료된다. 따라서 최소, 최대 및 원하는 대상이 1인 경우 동일한 ASG 내에서 새 EC2 인스턴스가 시작된다.

이 경우 EBS 볼륨, Private IP, EIP 등을 이전과 동일하게 가져갈수는 없다.
자동화를 잘 설정하면 동일하게 복구 할수도 있을 것이다.

특정 EC2 인스턴스에 중점을 둔 경우 옵션 1이 훨씬 선호될 것이다.

**정리**
-   EC2 인스턴스의 상태 확인은 AWs가 자동으로 수행하는 작업으로 하드웨어 및 소프트웨어의 문제를 식별한다.
-   system status check 와 instance status check가 있다.
-   system status check는 AWS 시스템에서 발생하는 문제를 모니터링 한다.
    -   예를 들어 실제 물리 호스트에 대한 소프트웨어 또는 하드웨어 문제 또는 호스트가 시스템 전원을 잃는 경우와 같은 상황이다.
    -   이러한 문제에 대한 overview를 확인하려면 personal health dashboard를 확인하면 된다. 이 대시보드에는 AWS가 예정된 사항이나 critial maintenance 항목을 제공하며 이 항목들은 EC2 인스턴스 호스트에 영향을 미친다.
    -   문제를 해결하기 위해서는 인스턴스를 중지하고 시작하면 된다. 인스턴스 중지 및 시작할 때 EC2는 우리 눈에는 보이지 않는 과정을 거친다. 
    -   AWS 데이터센터 내의 다른 호스트로 마이그레이션 된다. 예를 들어 호스트 1에서 실행중인 EC2 인스턴스가 있었다고 하면 중지 및 시작하고 나면 호스트 2에서 EC2 인스턴스가 실행되게 된다.
-   instance status check는 인스턴스의 소프트웨어 및 네트워크 구성을 모니터링한다.
    -   예를 들어 네트워크 구성이 잘못 되었거나 메모리가 고갈된 경우이다.
    -   이 문제를 해결하려면 EC2 인스턴스를 reboot 하거나 인스턴스 구성을 변경하면 된다.
    -   CloudWatch 메트릭 기반으로 자동으로 recover하는 방법도 있다. StatusCheckFailed_System, StatusCheckFailed_Instance 또는 이 두 메트릭을 하나의 메트릭으로 그룹화한 StatusCheckFailed이 있다.
    -   recover는 두 가지 방법이 있다. 
    -   하나는 CloudWatch Alarm과 Action을 이용해서 복구할 수 있다. 이 방법의 경우 recover instance라는 작업(Action)을 사용할 수 있다. 작업이 수행되면 인스턴스는 동일한 Private IP, 동일한 Public IP, 동일한 EIP, 동일한 메타데이터, 동일한 Placement Group을 사용해 인스턴스를 복구한다.
    -   또한 CloudWatch Alarm이기 때문에 SNS로 알림을 보낼수 있다.
    -   하나는 Auto Scailing Group Min, Max, desired 1을 설정하는 것이다. 그리고 ASG 상태 확인을 통해 EC2 인스턴스의 StatusCheck를 확인한다. 이 경우 EC2 인스턴스에 문제가 생겨도 desired 1 을 유지한다. EBS 볼륨, Private IP, EIP 등을 이전과 동일하게 가져갈수는 없다.


## **EC2 Instance Status Checks - MUST KNOW**

이러한 내용은 시험에서 2~3문제의 주요 내용일 수 있으므로 차이를 알아두는 것이 중요합니다.

SYSTEM status checks
시스템 상태 확인은 인스턴스가 실행 중인 AWS 시스템을 모니터링합니다.

기본 호스트에 문제가 있는 경우, 예를 들면:

-   네트워크 연결 손실
-   시스템 전원 손실
-   물리 호스트에서의 소프트웨어 문제
-   물리 호스트에서의 하드웨어 문제로 네트워크 접근성에 영향을 미침
-   AWS가 호스트를 수정하기를 기다리거나, EC2 인스턴스를 새 호스트로 이동시킬 수 있음 = 인스턴스 중지 및 시작 (EBS로 백업된 경우)

INSTANCE status checks
인스턴스 상태 확인은 개별 인스턴스의 소프트웨어 및 네트워크 구성을 모니터링합니다.

문제의 예:

-   올바르지 않은 네트워킹 또는 시작 구성
-   메모리 부족
-   손상된 파일 시스템
-   호환되지 않는 커널
-   수정이 필요할 때는 직접 개입이 필요함
-   EC2 인스턴스를 다시 시작하거나, EC2 인스턴스 구성 변경


## **EC2 Hibernate**
EC2 Hibernate 설명에 앞서 이해해야할 내용이 있다.

우리는 인스턴스를 중지하고 종료할 수있다는 것을 알 수 있다. 중지하면 EBS 디스크의 데이터가 다음 시작까지 유지 된다. 

그리고 종료하면 루트 볼륨이 인스턴스와 함께 삭제되도록 설정한 경우 삭제되지만 종료 시 인스턴스와 함께 삭제되지 않도록 설정된 모든 볼륨은 유지된다.

그리고 인스턴스를 시작하면 운영 체제가 부팅되고, EC2 User data가 실행되고, 그런 다음 운영 체제가 부팅된다.

그리고 응용 프로그램이 시작되고 캐시가 초기화되며 이는 시간이 소요될 수 있다. 왜냐면 기계를 부팅하는 것이기 때문이다.

그러나 Hibernate를 사용하면 RAM에 있던 내용이 보존된다. 즉, 인스턴스 부팅이 훨씬 빨라질 것이다. 왜냐하면 운영 체제가 중지되거나 다시 시작되지 않고 동결되어 있기 때문이다.

내부적으로 RAM 상태가 루트 EBS 볼륨의 파일에 기록된다. 즉, 루트 EBS 볼륨은 암호화되어 있어야 하며 RAM을 포함할 만큼 충분한 공간이 있어야 한다.

사용 사례는 장기 실행 프로세스를 중지하지 않거나 RAM 상태를 저장하려는 경우, 또는 빠르게 부팅하고 초기화에 시간이 오래 걸리는 서비스르 가지고 있는 경우 등이 있다.

EC2 Hibernate에 관한 몇 가지 사항은 다음과 같다.
-   여러가지 다양한 패밀리를 지원하며 인스턴스 RAM 크기는 150GB 미만이어야한다.
-   베어 메탈 인스턴스는 적용되지 않는다.
-   Linux 및 Windows를 비롯한 여러 가지 운영 체제에서 작동한다.
-   루트 볼륨에 적용되며 해당 루트 볼륨은 EBS 볼륨이어야 하며, 암호화 되어 있어야하고, RAM을 담을 충분한 크기가 있어야한다.
-   온디맨드, 예약 및 스팟 인스턴스와 같은 모든 종류의 인스턴스에서 사용 가능하다.
-   60일 이상 Hibernate 되지 않으므로, 60일 이상 하려고 한다면 시작하고 다시 중지 해야한다.

**정리**
-   Hibernate는 최대 절전 모드이다. 무슨말이냐? 우리가 일반적으로 인스턴스를 중지하고 시작하게되면 OS 부팅, 캐시 초기화, user data 실행 등등 과정을 거치게 된다.
-   Hibernate는 이러한 과정을 거치지않고 RAM의 데이터를 루트 볼륨 EBS에 저장해 부팅 시 이를 활용해 더욱 빠른 부팅을 하게 해준다.
-   Hibernate를 사용하기 위해서는 루트 EBS 볼륨은 암호화되어 있어야하고, EBS 볼륨에 RAM 데이터를 담을 만한 충분한 공간이 있어야 한다.
-   사용 사례는 장기 실행 프로세스를 중지하지 않거나 RAM 상태를 저장하려는 경우, 또는 빠르게 부팅하고 초기화에 시간이 오래 걸리는 서비스를 가지고 있는 경우 등이 있다.
-   Hibernate 관련 사항
    -   여러가지 다양한 패밀리를 지원하며 RAM 크기는 150GB 미만이어야 한다.
    -   베어메탈 인스턴스는 지원되지 않는다.
    -   Linux 및 Windows 및 다른 운영체제도 지원된다.
    -   온디맨드, 예약 및 스팟 인스턴스등 모든 종류의 인스턴스에서 지원된다.
    -   60일 이상 Hibernate 되지 않으며, 60일 이상하려면 중지 상태에서 실행 했다가 다시 Hibernate 해야한다.

## **\[CCP/SAA/DVA] AMI Overview**

AMI는 Amazon Machine Image 의 약자이며 EC2 인스턴스의 사용자 정의를 나타낸다.

AWS에서 생성한 AMI를 사용하거나 사용자 정의 AMI로 만들 수 있다.

AMI에는 소프트웨어 구성뿐만 아니라 운영 체제를 정의하고 설정하며 모니터링 도구를 설정할 수 있다.

우리가 직접 AMI를 만들면 EC2 인스턴스에 설치하려는 모든 소프트웨어가 AMI를 통해 미리 패키지되기 때문에 부팅 시간 및 구성 시간이 빨라진다.

그래서 우리는 자체 AMI를 작성해야 하며 특정 Region에 대해 작성할 수 있으며 원한다면 AWS 글로벌 인프라를 활용해 다른 Region으로 복사할 수 있다.

Amazon Linux 2 AMI도 있다. 이 AMI는 AWS에서 제공하는 매우 인기 있는 AMI 중 하나이다.

AWS Marketplace AMI에서 EC2 인스턴스를 시작할 수도 있다. 이는 다른 사람이 만든 AMI로서 판매되는 AMI이다.
AWS에서는 자체 소프트웨어를 설정하고 판매하는 벤더가 자체 AMI를 생성하여 마켓플레이스에서 AMI를 판매하는 것이 일반적이다.

사용자로서 우리도 AWS 마켓 플레이스에서 AMI를 판매하는 비즈니스를 만들 수 있다.

AMI는 어떤 프로세스로 EC2 인스턴스에서 동작하는 가? 먼저 EC2 인스턴스를 시작하고 사용자가 인스턴스를 구성한다. 그런 다음 데이터 무결성이 올바르게 유지 되도록 인스턴스를 중지한다. 그런 다음 이를 기반으로 AMI를 작성할 수 있으며 EBS 스냅샷이 생성된다. 마지막으로 다른 AMI에서 인스턴스를 시작할 수 있다.

**정리**
-   AMI는 Amazon Machine Image의 약자로서 인스턴스의 사용자 정의를 나타낸다.
-   AMI는 소프트웨어 구성뿐만 아니라 운영 체제를 정의하고 설정하며 모니터링 도구를 설정할 수 있다.
-   직접 AMI를 생성하거나 AWS에서 제공해주는 AMI를 사용할 수 있다.
-   특정 Region에 대해 AMI를 생성할 수 있고 원한다면 다른 Region 또는 계정으로 복사할 수 있다.
-   AWS Marketplace AMI에서 EC2를 시작할 수도 있다. 이는 다른 사람이 만든 AMI로서 판매되는 AMI이다.
    -   자체 소프트웨어를 설정하고 판매하는 벤더가 자체 AMI를 생성해 Marketplace에서 판매하는 것이 일반적이다.
-   AMI는 먼저 구성된 인스턴스가 있으면 데이터 무결성이 올바르게 유지 되도록 중지하고, 이 인스턴스를 기반으로 AMI를 작성할 수 있으며 EBS 스냅샷이 생성된다. 생성된 AMI를 기반으로 인스턴스를 시작할 수 있다.

## **AMI No Reboot Option**
"No-Reboot" 이 옵션을 사용하면 EC2 인스턴스를 먼저 종료하지 않고도 AMI를 생성할 수 있다.

기본적으로 이 옵션은 선택되어 있지 않으며, AMI를 생성하기 전에 인스턴스를 중지해야 한다는 것을 의미한다. 이는 파일 시스템 무결성을 유지하기 위함이다.

No-Reboot가 비활성화된 상태에서 AMI를 생성하려면 인스턴스가 중지된다. 중지된 후 연결된 EBS 볼륨은 EBS 스냅샷이 생성된다. 이후 EBS 스냅샷은 AMI로 변환된다.

그러나 No-Reboot 옵션을 활성화하면 현재 실행중인 EC2 인스턴스에 연결된 EBS 볼륨에 대한 스냅샷이 직접 생성되고, 그 다음 AMI 이미지가 생성된다. 이 경우 파일 시스템 무결성이 보장되지 않을 수 있으며, 스냅샷이 생성되기 전에 OS 버퍼가 디스크로 플러시되지 않는다. ***인스턴스가 계속 실행 중인 상태에서 AMI를 생성할 때는 주의가 필요하다.***

AWS 백업 서비스를 사용할 때는 Backup Plan을 만들어 AMI를 생성할 수 있다. 그러나 백업 서비스는 EBS 스냅샷을 찍는 동안 인스턴스를 재부팅하지 않는다.
따라서 기본 옵션은 사실상 No-Reboot 동작이다. 
즉, AWS 백업을 사용할 때는 인스턴스가 작동 중일 때에도 중단되지 않고 AMI가 생성된다.
backup plan을 사용하면 무결성이 보장되지 않으므로 주의해야 한다.

대안으로 Amazon EC2 인스턴스를 AMI로 스케줄 백업하려면 EventBridge 규칙을 생성할 수 있다. 예를 들어 매주 한 번 Lambda 함수를 호출하는 일정을 만들 수 있다.

Lambda 함수에는 reboot 옵션과 함께 image를 생성하는 고유의 코드가 있을 것이다.
이렇게 한다면 EC2는 rebooting을 진행하고 AMI를 생성할 것이다.

**정리**
-   No-Reboot 이라는 옵션이 있다.
-   이는 실행중인 인스턴스에 AMI를 생성할 때 재부팅을 하지 않는다는 의미이며, 기본적으로 AMI를 생성하기 전에 인스턴스를 중지해야한다.
-   No-Reboot 옵션을 활성화하게 되면 실행중인 인스턴스에 연결된 EBS 볼륨에 대한 스냅샷이 직접 생성되고, 그 다음 AMI 이미지가 생성된다.
-   이 경우 파일 무결성이 보장되지 않을 수 있고, 스냅샷이 생성되기 전에 OS 버퍼가 디스크로 플러시되지 않는다.
-   AWS 백업 서비스를 사용하는 경우도 인스턴스를 재부팅하지 않는다. 사실상 No-Reboot 동작이다.
-   대안으로는 EventBridge와 Lambda를 이용해서 특정 기간에 람다 함수를 실행 시켜 인스턴스를 재부팅하고 AMI를 생성하는 코드를 작성해 실행시키면 된다.

## **EC2 Instance Migration using AMIs**

EC2 인스턴스를 한 AZ에서 다른 AZ로 마이그레이션하려면 AMI를 사용한다.

기본적으로 AMI는 원본과 동일한 데이터, 파일 시스템 및 응용 프로그램을 가지고 있기 때문에 마이그레이션 된 인스턴스도 동일한 내용을 가진다.

다른 AWS 계정과 AMI를 공유하는 **Cross-Account AMI Sharing** 도 있다.

AMI를 공유할 때 AMI의 소유권(ownership)에는 영향을 미치지 않는다. 여전히 공유를 한 계정이 소유자로 남아있다.

AMI를 공유할 수 있는 경우는 두 가지이다.
1. 볼륨이 암호화되지 않은 경우
2. 볼륨이 암호화되었는데 사용자 고유의 고객 관리 키(CMK)로 암호화된 경우

예를 들어 설명해보자
계정 A에서는 암호화되지 않은 AMI가 생성되며, 이를 계정 B와 공유한다. 그러면 계정 B는 해당 소스 AMI에서 직접 EC2 인스턴스를 시작할 수 있다. 마찬가지로 암호화 키를 사용하여 AMI를 공유할 때는 해당 AMI뿐만 아니라 암호화된 키도 공유해야 한다. 그리고 대상 계정에는 해당 키를 사용하여 특정 작업을 수행할 수 있는 권한을 부여해야 한다.

다음으로는 **Cross-Account AMI Copy**이다. 

소스 AMI의 소유자인 상태에서 대상에 복사하면 대상 AMI의 소유자가 된다.
따라서 소스 AMI의 소유자는 대상 AMI의 저장소(EBS 스냅샷)에 대한 읽기 권한을 부여해야 한다.
계정 B는 이제 AMI의 EBS 스냅샷을 읽을 권한이 있으므로 소스 AMI를 자체 계정으로 복사할 수 있다. 이 과정에서 필요에 따라 스냅샷을 자체 키로 암호화할 수 있다.

공유된 AMI가 암호화된 스냅샷인 경우 소유자는 암호화된 키를 공유해야 한다. 복사 중에 자체 CMK로 AMI를 암호활 수도 있다.

예를들어 기본 EBS 스냅샷을 공유하고 대상 계정에 KMS 키 권한을 부여한다. 대상 계정은 CMK-A를 사용해 암호를 해독하고 CMK-B 및 자체 계정을 사용해 다시 암호화할 수 있는 복사 명령을 실행할 수 있다. 이렇게하면 대상 계정 B가 소유하는 자체 암호화 매커니즘을 사용하는 사용자 정의 AMI가 생성된다.

정리하자면 AMI를 복사하려면 복사를 위해 AMI 소유자가 되어야한다. 그리고 소스 AMI의 소유자는 대상 AMI의 EBS 스냅샷에 대한 읽기 권한을 부여해야한다.

AMI가 공유된 경우 해당 AMI를 복사하여 소유자가 되는 대신 복사를 통해 자체 계정에서 AMI를 소유할 수 있다.

또한 AMI 자체를 사용하려면 해당 AMI의 권한을 확인하고 편집할 수 있다. 콘솔에서 권한을 수정하려면 AMI - Action - Edit AMI permissions를 선택하면 된다. 여기에는 AMI의 공개 여부를 포함해 여러 옵션이 제공된다. 특정 계정, 조직 또는 OU와 공유하려면 해당 계정 ID를 추가할 수있다. 그리고 권한을 부여할 때 해당 스냅샷을 만들 때 연결된 스냅샷에 볼륨 권한을 추가할 수도 있다.

**정리**
-   EC2 인스턴스를 한 AZ에서 다른 AZ로 마이그레이션하려면 AMI를 사용하면 된다.
-   기본적으로 AMI는 원본과 동일한 데이터, 파일 시스템 및 응용 프로그램을 가지고 있기 때문에 마이그레이션 된 인스턴스도 동일한 내용을 가진다.
-   다른 AWS 계정과 AMI를 공유할수도 있다. **Cross-Account AMI Sharing**
    -   AMI를 공유할 때 AMI의 소유권에는 영향을 미치지 않고 공유를 한 계정이 소유자로 남아있다. 공유를 받은 계정은 해당 AMI에 대해 삭제, 공유, 수정은 불가하다.
    -   AMI를 공유할 수 있는 방법은 두 가지이다.
    1.  볼륨이 암호화되어 있지 않은 경우
    2.  볼륨이 암호화되어 있는데 사용자 고유의 고객 관리 키(CMK)로 암호화된 경우
    -   볼륨이 암호화되어 있지 않은 경우 단순히 공유만 하면 대상 계정에서 해당 AMI를 이용해 EC2 인스턴스를 생성 가능하다.
    -   만약 암호화된 AMI를 공유할 때에는 해당 AMI 뿐만 아니라 암호화된 키를 공유해야 하며, 대상 계정에 해당 키를 사용해 특정 작업을 수행할 수 있는 권한을 부여해야 한다.
-   다른 AWS 계정과 AMI를 공유하고 해당 AMI를 Copy 가능하다. **Cross-Account AMI Copy**
    -   소스 AMI 소유자인 상태에서 대상에 복사하면 대상 AMI의 소유자가 된다.
    -   복사하는 과정은 공유된 소유자 AMI를 대상 계정에서 Copy하면 Copy된 AMI는 대상자의 소유가 되며 복사가 된다.
    -   Copy 과정에서 CMK를 이용해 대상 계정이 소유하는 암호화된 AMI가 생성된다.


## **EC2 Image Builder**

가상 머신이나 컨테이너 이미지의 자동 생성을 위해 사용되는 서비스

EC2 Image Builder를 이용하면 EC2 인스턴스용 AMI를 자동으로 생성, 유지 관리, 유효성 검사 및 테스트할 수 있게 된다.

예를 들어 설명해보자면 EC2 Image Builder 서비스가 실행될 때 자동으로 인스턴스를 생성하게 되는데, 이 인스턴스는 구성 요소를 빌드하고 소프트웨어를 사용자 정의한다.
예를 들어 JAva 설치, CLI 업데이트, 소프트웨어 시스템 업데이트, 방화벽 설치 또는 EC2 인스턴스에서 정의한 내용을 수행할 수 있다.

그 다음 이 모든 작업이 완료되면 해당 EC2 인스턴스에서 AMI가 생성된다. 이 모든 것들이 자동화된다.

AMI를 생성하고 유효성 검사를 하고 싶다면 Image Builder는 해당 AMI에서 테스트 EC2 인스턴스를 자동으로 생성하고 미리 정의한 여러 테스트를 실행한다.
테스트를 실행하고 싶지 않다면 테스트를 건너 뛸 수 있다.

그 다음 AMI가 테스트되면 해당 AMI가 배포된다.

Image Builder는 AMI를 가져와 여러 Region에 배포할 수 있어 응용 프로그램 및 워크플로우가 실제로 글로벌하게 동작하도록 할 수 있다.

EC2 Image Builder는 스케줄에 따라 실행할 수 있다. 매주 스케줄을 정의하거나 패키지가 업데이트될 때 실행하거나 수동으로 실행할 수 있다.

이 서비스는 무료 서비스여서 기본 리소스에 대해서만 비용이 청구된다. 
이 프로세스 동안 EC2 인스턴스를 생성하면 Image Builder가 이러한 EC2 인스턴스를 생성하게 되므로 해당 EC2 인스턴스에 대한 비용이 청구된다.
또한 AMI가 생성되고 배포되면 해당 AMI의 스토리지에 대한 비용이 청구된다.

**정리**
-   Image Builder는 가상 머신이나 컨테이너 이미지의 자동 생성을 위해 사용되는 서비스이다.
-   Image Builder를 이용하면 EC2 인스턴스 용 AMI를 자동으로 생성, 유지 관리, 유효성 검사, 테스트 할 수 있다.
-   AMI를 생성하고 유효성 검사를 하고 싶다면 Image Builder는 해당 AMI에서 테스트 EC2 인스턴스를 자동으로 생성하고 미리 정의한 여러 테스트를 실행할 수 있다. 테스트는 건너뛸 수 있다.
-   Image Builder는 AMI를 가져와 여러 Region에 배포할 수 있어 응용 프로그램 및 워크 플로우가 실제로 글로벌하게 동작하도록 할 수 있다.
-   또한 스케줄링도 가능하다. 매주 스케줄을 정의하거나 패키지가 업데이트될 때 실행하거나 수동으로 실행 가능하다.
-   Image Builder는 무료 서비스여서 기본 리소스에 대해서만 비용이 청구된다. 프로세스 동안 EC2 인스턴스가 생성되면 해당 인스턴스에 대해서만 청구가 되며, 생성된 AMI 저장 비용이 청구가 된다. 이외에 별도의 빌드 및 테스트 및 배포에 대한 비용은 청구되지 않는다.


## **AMI In Production**
프로덕션 환경에서 사용하는 방법에 대한 설명

사용자가 사전 승인된 AMIs에서만 EC2 인스턴스를 시작하도록 강제하는 방법이 있다.

사전 승인된 AMI란 특정 태그로 AMI에 태그를 지정해 IAM 정책과 결합하면 사용자가 특정 태그가 지정된 AMI만 시작할 수 있도록 제한할 수 있다.

예를 들어 env='prod' 환경으로 태그를 AMI에 할당해 제한하는 것이다.

계정 내 두 종류의 AMI가 있다고 가정 해보자 태그가 없는 AMI와 env='prod'로 태그가 있는 AMI

AMI에 태그를 추가할 수 있는 사용자를 제한하는 것도 중요하다. 하지만 태그와 IAM 정책의 조합 덕분에 사용자는 승인되지 않은 AMI에서 EC2 인스턴스를 시작할 수 없고, 승인된 AMI에서 EC2 인스턴스를 시작할 수 있다.

결론적으로 AMI가 승인되지 않았을 때 인스턴스를 시작하지 못하도록 하는 것

두 번째로는 AWS Config를 사용해 승인되지 않은 EC2 인스턴스로 정의되는 EC2 인스턴스를 찾을 수 있다.

예를 들어 사용자가 승인된 AMI와 승인되지 않은 AMI에서 인스턴스를 launch 하는 방법을 찾았다면 Config를 사용해 이 두 EC2 인스턴스가 규정을 따르는지 여부를 모니터링하는 규칙을 작성할 수 있다.

규정을 따르지 않는 것은 Config에 의해 플래그가 지정되며, 조치를 취할 수 있다. 규정을 따르는 것은 문제가 없다. 플래그는 콘솔 - Rules에서 확인 가능

**정리**
-   프로덕션 환경에서는 사용자가 사전 승인된 AMI로만 EC2 인스턴스를 시작하도록 강제하는 방법이 있다.
-   사전 승인된 AMI란 특정 태그를 AMI에 지정하는 것이고, 이를 IAM 정책과 결합하면 사용자가 특정 태그가 지정된 AMI로만 인스턴스를 시작할 수 있는 개념이다.
-   예를 들어 env='prod' 라는 태그가 지정된 AMI만 특정 사용자가 시작할 수 있는 것이다.
-   또한 태그를 추가할 수 있는 사용자를 제한하는 것도 중요하다.
-   태그를 추가하는 방법 또는 AWS Config를 사용해 승인되지 않은 EC2 인스턴스로 정의되는 EC2 인스턴스를 찾을 수 있다.
-   예를 들어 사용자가 승인이 되었거나 되지 않았거나 인스턴스를 시작할 수 있을 때 Config를 사용해 이 두 EC2 인스턴스가 규정을 따르는지 여부를 모니터링하는 규칙을 작성할 수 있다.
-   규정을 따르지 않는 것은 Config에 의해 플래그가 지정되고, 조치를 취할 수 있으며, 규정을 따르는 것은 문제가 없다. 플래그는 콘솔에서 확인 가능하다.


## **Systems Manager Overview**

System Manager는 확장 가능한 EC2 Fleet 인스턴스와 온프레미스 서버를 관리하는 데 도움이 된다. 

여러 도구들이 Systems Manager에 존재하고 인프라 상태에 대한 인사이트를 얻게하고 문제를 쉽게 감지하며 패치 자동화와 향상된 규정 준수를 제공한다.

시험에서는 패치를 적용할 때 대개 시스템 매니저를 사용하거나 실행중인 모든 종류의 자동화에 시스템 매니저를 사용할 것이다.

이 서비스는 Windows 및 Linux 운영 체제 모두에서 작동하며 CloudWatch Metrics와 대시 보드와 완전히 통합되어 있다.

또한 Config와 통합되어 있으며 무료 서비스이고 사용하는 리소스 또는 생성하는 리소스에 대해서만 비용이 발생한다.

**정리**
-   System Manager는 확장 가능한 EC2 Fleet 인스턴스와 온프레미스 서버를 관리하는데 도움이 된다.
-   시험에서는 패치를 적용하거나 실행 중인 모든 종류의 서버에 대해 자동화하는 작업에 System Manager를 이용한다.
-   Window 및 Linux 운영체제 모두에서 작동하며 CloudWatch Metric, CloudWatch 대시보드와 완전히 통합되어 있다.
-   System Manager는 무료 서비스이고, 사용하는 리소스 또는 생성하는 리소스에 해당해서만 비용이 부과된다.



## **AWS Tags & SSM Resource Groups**

태그와 리소스 그룹에 대해 알아보자

태그는 많은 AWS 리소스에 적용할 수 있는 key-value 쌍이다.
일반적으로 EC2에서 사용되지만 다양한 소스에서도 사용된다.

일반적으로 "Environment", "Team" 등의 태그가 사용된다.

태그는 리소스 그룹화, 자동화, 보안 및 비용 할당을 위해 사용된다. 일반적인 규칙은 너무 적은 태그보다는 많은 태그를 가지는 것이 더 좋다.

태그를 사용해 리소스 그룹을 생성하고 동일한 태그를 공유하는 두 리소스 및 여러 리소스를 그룹화할 수 있다.

예를 들어 "Environment"="dev"로 태그된 두 개의 EC2 인스턴스를 그룹화할 수 있다.
Region 수준에서 수행할 수 있는 작업이며, EC2 인스턴스뿐만 아니라 S3, DynamoDB, Lambda 등과 함께 작동한다.

시스템 매니저에서 리소스 그룹을 만들고 태그 기반으로 선택하면 여러 리소스를 관리할 수 있다.

예를 들어 "Environment"="dev" 태그가 할당된 EC2 가 두개 있다고 했을 때 리소스 그룹을 생성해서 AWS::service::resource 형식의 리소스 유형을 선택하고 "Environment"="dev" 태그를 지정하게 되면 해당 리소스 그룹은 태그 기반으로 SSM을 직접 작업할 수 있다.

**정리**
-   태그는 많은 리소스에 적용할 수 있는 Key Value 쌍이다. 다양한 리소스에서 사용된다.
-   일반적으로 "Environment":"prod", "Team":"Infra" 등의 태그로 많이 정의된다.
-   태그는 리소스 그룹화, 자동화, 보안 및 비용 할당으로 많이 사용된다. 일반적으로 적은 태그보다 많은 태그를 가지는 것이 더 좋다.
-   태그를 사용해 리소스 그룹을 생성하고 여러 리소스를 그룹화할 수 있다.
-   동일한 태그를 사용해 리소스를 그룹화하면 태그 기반으로 그룹화된 SSM 작업을 할 수 있다.


## **SSM Documents & SSM Run Command**

SSM Documents는 JSON 또는 YAML로 작성될 수 있으며, 매개변수를 정의해 Documents가 무엇을 수행하는지, 즉 작업을 정의하고 특정 서비스에서 문서가 실행된다.

AWS에는 이미 많은 문서가 존재하며, 우리가 하는 작업을 더 빨리 진행하기 위해 이를 활용할 수 있다.

SSM을 자주 사용하기 시작하면 자체 SSM Documents를 작성할 것이다.

이러한 Documents를 state manager, patch manager, automation 와 같은 다른 SSM 기능에 적용할 수 있으며, SSM Parameter Store에서 일부 데이터를 검색하여 문서가 어떻게 작동할지에 대한 일종의 모듈성과 동적성을 제공할 수 있다.

SSM 은 Amazon 소유의 Documents, 내 소유의 Documents 등이 있다. 내가 소유한 Documents도 있고 다른 사람들과 Documents를 공유할 수도 있다.

Documents를 적용하는 첫 번째 방법은 Run Command SSM 기능을 사용하는 것이다.

Run command를 사용하여 전체 Documents를 실행하거나(EC2 인스턴스 플릿 전체에 대한 스크립트인 경우) 간단히 EC2 인스턴스 플릿 전체에서 단일 명령을 실행할 수 있다.
이를 위해 이전에 만든 리소스 그룹을 사용할 수 있다.

run command에는 rate control 및 error contorl 기능이 있다. 예를 들어 1,000개의 인스턴스에 명령을 실행한다면 1,2 분 동안 다운될 것이다. 점진적으로 수행해야 하며, 오류가 발생할 경우 플릿의 명령을 중단할 수 있어야 한다.

IAM & CloudTrail과 완전히 통합되어 있다. 
그래서 누가 명령을 실행하는지 알 수 있다. 

SSH가 필요 없다. 에이전트가 명령을 실행하지만 system manager는 명령을 실행하기 위해 인스턴스에 SSH 액세스 권한을 필요로 하지 않는다.

명령 output은 콘솔에서 볼 수 있지만 S3 버킷이나 CloudWatch로 보낼 수도 있다.

명령 실행 상태를 알려면 콘솔을 살펴볼 수도 있고 SNS로 정보를 보낼 수도 있다. 진행 중인지, 성공 했는지 실패 했는지 등을 알 수 있다.

자동화와 EvnetBridge를 위한 CloudWatch Events의 실행 명령을 호출하는 데 사용될 수 있다.

**정리**
-   SSM Documents는 JSON 또는 YAML로 작성될 수 있고, Document에 작업을 정의해 특정 서비스에서 정의된 매개변수와 함께 Document를 수행할 수 있다.
-   AWS에서는 미리 정의된 제공되는 Documents가 있으며, 사용자가 자체적으로 SSM Documents를 작성할 수도 있다. 또한 다른 사용자에게 내 Documents를 공유할 수도 있다.
-   Documents는 State Manager, Patch Manager, Automation 등의 다른 SSM 기능에 적용 가능하고 SSM Parameter Store에서 일부 데이터를 검색해 문서에 대한 일종의 모듈성과 동적성을 제공할 수 있다.
-   SSM Run Command를 사용하면 Documents를 적용할 수 있다.
-   Run Command를 사용해 이전에 만든 리소스 그룹(EC2 인스턴스 플릿 전체)을 활용하여 단일 명령을 실행할 수 있다.
-   Run Command에는 Rate Control 또는 Error Control이 있다.
    -   Rate Control은 말그대로 한 번에 수행해야 할 인스턴스의 비율이다. 예를 들어 1,000개의 인스턴스에 한번에 명령어를 수행한다면 문제가 발생할 수 있으니 점진적으로 수행하는 기능이다.
    -   Error Control은 명령어 수행 중 에러가 발생할 경우 Run Command 자체를 중단하는 기능이다. 예를들어 10개의 인스턴스가 있는 리소스 그룹에 대해 10%의 비율을 설정하게 되면 1개 이상의 Error가 발생하면 Command를 중단하는 것이다.
-   IAM & CloudTrail과 통합되어 있어 누가 명령을 실행하는 지 알 수 있다.
-   Output을 출력받아 콘솔에서 확인하거나 S3 또는 CloudWatch로 Export 가능하다.
-   명령 수행 상태를 확인하려면 콘솔을 살펴보거나 SNS로 정보를 보내 진행 중인지 성공 했는지 실패 했는지 등을 알 수 있다.
-   EventBridge나 CloudWatch Events를 연동해 Run Command를 호출할 수도 있다.


## **SSM Automation**
Automation은 EC2 인스턴스나 다른 AWS 리소스를 위한 일반적인 유지 관리와 배포 작업을 단순화하도록 도와준다.

예를 들어 Automation을 사용하면 인스턴스 재시작이나 AMI 생성, EBS 스냅샷 작업같은 걸 할 수 있다.

run command의 경우 인스턴스의 내부에서 명령어를 실행했지만 automation의 경우 외부에서 실행한다.

Automation Runbook의 경우 자동화 형식이 될 SSM을 위한 문서의 이름이다. 일반적으로 runbook이라고 한다.

runbook은 EC2 인스턴스나 AWS 리소스에 작업을 정의하고 수행하는 것이다.
AWS가 미리 정의한 Runbook을 사용할 수도 있고 custom runbook을 만들 수도 있다.

SSM Automation은 콘솔이나 CLI, SDK를 이용해 트리거 된다.
또한 EventBridge Rule을 이용해서 자동화 할 수 있다.
SSM Maintenance Windows를 이용해서 특정 일정에 수행되는 자동화도 가능하다.
AWS Config rules remediation으로 규칙에 준수되지 않는 리소스를 발견할 때마다 자동화도 가능하다.

Documents가 실행될 곳을 선택할 수도 있다.
simple execution, Rate control, Multi-account and Region, Manual execution 등이 가능하다.

**정리**
-   Automation은 EC2 인스턴스나 다른 AWS 리소스를 위한 일반적인 유지 관리와 배포 작업을 단순화한다.
-   Run Command와의 다른 점은 Run Command는 단일 명령어 및 스크립트를 수행하는데, Automation은 여러 작업을 단계적으로 수행하거나 Task의 형태로 나누어 수행 가능하다.
-   Automation Runbook의 경우 자동화 형식이 될 문서의 이름이다. Runbook은 EC2 인스턴스나 AWS 리소스에 작업을 정의하고 수행하는 것이다. SSM Run Command로 비교하면 Documents == Runbook인 느낌
-   Runbook의 경우 AWS가 미리 정의한 Runbook도 있고 Custom Runbook을 만들 수도 있다.
-   Automation은 콘솔이나 CLI, SDK를 이용해 트리거 된다. EventBridge Rule을 이용해서 자동화할 수도 있다. 
-   SSM Maintenance Windows를 이용해서 특정 일정에 수행되는 자동화도 가능하다.
-   AWS Config rules remediation으로 규칙에 준수되지 않는 리소스를 발견할 때마다 수행하는 자동화도 가능하다.

## **[SAA/DVA] SSM Parameter Store Overview**

SSM 파라미터 스토어는 configuration과 secrets를 위한 보안 저장소이다.
선택적으로 configuration을 KMS 서비스를 이용해서 암호화할 수도 있다.
SSM 파라미터 스토어는 serverless이며 확장 가능하며 durable하고 사용이 쉬운 SDK가 특징이다.

configuration과 secrets를 업데이트하면 버전 트래킹을하게 된다.

보안은 IAM을 통해 제공된다.

아마존 EventBridge로 알림을 받을 수 있다.

CloudFormation과 통합될 수 있다. CloudFormation이 파라미터 스토어의 매개 변수를 stack의 input 매개 변수로 활용할 수 있다.

예를 들어 Application과 SSM Parameter Store가 있을 때 일반 텍스트 구성을 저장할 수 있고, Application의 IAM 사용 권한(EC2 인스턴스 역할이나 암호화된 Configuration을 통해서 권한이 부여된)을 확인하게된다.
이 경우 Parameter Store는 KMS로 암호화될 것이다.
KMS 서비스는 암호화와 Devryption에 사용될 것이다.

물론 Application은 기본 KMS 키에 액세스 권한이 있어야 암호화와 복호화를 실행할 수 있다.

파라미터 스토어에 매개 변수를 계층 구조와 함께 저장 가능하다.

예를 들어 부서를 경로로 정의할 수 있다. 그리고 부서 아래에 application 그리고 dev prod 등등 원하는 방식으로 변수를 정리할 수 있게 해준다.
/my-department/my-app/dev/db-url/
/my-department/my-app/dev/db-password/
/my-department/my-app/prod/db-url/
/my-department/my-app/prod/db-password/
등등..

그 다음 IAM 정책을 단순화해 Application이 전체 부서나 전체 앱 또는 앱 부서 환경 특정 경로에 액세스할 수 있도록 할 수 있다.

파라미터 스토어를 통해 Secrets Manager에 접근할수도 있다.
ex) /aws/reference/secretsmanager/secret_ID_in_Secrets_Manager

또한 AWS가 발행하는 퍼블릭 파라미터라는 것도 사용할 수 있다.
예를 들어, 우리 특정 Region에서 최신 AMI를 찾으려면 API 호출로서 파라미터 스토어에서 가져올 수 있다.
ex) /aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2 (public)

Application을 예로 들면 Dev Lambda Function은 IAM 롤이 있고, /my-department/my-app/dev/db-url 등에 액세스를 가능하게 한다.

Systems Manager에는 두 종류의 매개 변수 계층이 있다.
하나는 Standard 하나는 Advanced이다.

가장 큰 차이는 최대 변수 값 크기이다. Standard는 4KB Advanced는 8KB이다.
그리고 매개 변수 정책의 가용성도 있다. 

Standard는 공짜고 Advanced는 한달에 advanced parameter 당 0.05$이다.

매개 변수 정책이란 무엇인가?
-    매개 변수에 TTL을 설정할수 있다. 만료일을 의미한다. 패스워드 같은 민감한 데이터를 업데이트하거나 삭제하도록 강요하는 것이다.
-    한번에 여러 가지 정책을 할당할 수 있다.
    -    예를 들어서 매개 변수가 만료되기 15일 전에 이벤트 브릿지에서 알림을 받거나, 20일 동안 매개 변수가 업데이트되지 않는다면 알림을 받는 것처럼 두 개의 알림을 한번에 받을 수도 있다.

**정리**
-   SSM Parameter Store는 configuration과 secrets를 위한 보안 저장소이다. 파라미터 스토어는 Serverless이며, 확장 가능하고 사용이 쉬운 SDK가 특징이다.
-   선택적으로 configuration을 KMS 서비스를 이용해 암호화할 수도 있다.
-   CloudFormation과 통합해서 CloudFormation이 파라미터 스토어의 매개변수를 Stack의 input 매개 변수로 활용할 수 있다.
-   파라미터 스토어 매개 변수를 계층 구조와 함께 저장 가능하다.
    -   예를 들어 특정 부서별 db를 관리하고 있고 해당 db에 대한 url과 패스워드 값을 파라미터로 저장해 특정 부서 경로에 액세스할 수 있도록 IAM 정책을 구성하면 부서 별 파라미터 접근 권한을 관리할 수 있다.
    -   /infra-department/my-app/dev/db-url
    -   /infra-department/my-app/dev/db-password
    -   /dev-department/my-app/dev/db-url
    -   /dev-department/my-app/dev/db-password 등등..
-   파라미터 스토어를 통해 secrets Manager에 접근할수도 있다.
    -   /aws/reference/secretsmanager/secret_ID_in_Secrets_Manager
-   AWS가 관리하는 퍼블릭 파라미터를 사용할 수도 있다.
    -   예를 들어 특정 Region에서 최신 AMI를 찾으려면 파라미터 스토어에서 값을 가져올 수 있다.
    -   /aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2
-   Parameter Store에는 두 종류의 매개 변수 Tier가 있다.
    -   Standard
        -   무료 요금
        -   Standard의 경우 매개 변수 정책을 설정할 수 없다.
    -   Advanced
        -   한달에 parameter 당 0.05$
        -   매개 변수 정책 설정 가능
-   매개 변수 정책
    -   매개 변수에 TTL을 설정해서 매개 변수가 만료되는 시점을 설정할 수 있다. 패스워드 같은 민감 데이터를 업데이트하거나 삭제하도록 강제하는 것이다.
    -   한번에 여러 정책을 설정할 수 있다.
        -   예를 들어 매개 변수가 만료되기 15일 전 이벤트 브릿지에서 알람을 받고, 20일 동안 매개 변수가 업데이트되지 않는다면 알람을 받아 두 개의 알람을 한 번에 받을수도 있다.

## **SSM Inventory & State Manager**

**SSM Inventory**
SSM의 인벤토리 기능을 살펴보자.
관리되는 인스턴스로부터 메타데이터를 수집하는 데 사용된다. EC2일수도 있고 On-premises일 수도 있다.

메타데이터는 많은 것을 포함할 수 있다. 설치된 소프트웨어, OS 드라이버, configurations, 설치된 업데이트, 실행중인 서비스 등등

AWS 콘솔에서 데이터를 볼 수도 있고 S3에 저장할 수도 있다. 서버리스 용 Athena를 이용해서 쿼리 후 분석할 수도 있고, 대시보드를 구축하고 싶다면 QuickSight를 이용할 수도 있다.

메타데이터의 수집 간격을 지정할 수 있다. 분, 시간, 일 단위로 가능하다.

여러 계정 및 Region에서 데이터를 모아 하나의 계정에서 중앙 집중형으로 쿼리를 날릴 수 있다.

마지막으로, 원한다면 사용자 지정 인벤토리를 만들 수 있다. 예를들어 각각의 관리되고 있는 인스턴스의 rack 위치를 확인하거나 할 수 있다.

초기에는 enable inventory를 해야 모든 인스턴스에 대한 inventory를 활성화 할수있다.

**State Manager**
State Manager는 관리되고 있는 EC2를 우리가 정의한 상태로 유지하는 프로세스를 자동화하는 데 사용된다.
사용 사례는 소프트웨어의 인스턴스를 부트스트랩하거나, OS나 소프트웨어 업데이트를 일정에 따라 패치하는 것이다.

State Manager Association을 만들어야한다.
인스턴스가 유지되어야하는 상태를 정의한다. 예를 들어 무조건 포트 22번을 닫거나 EC2의 안티 바이러스를 설치해야 하는 등의 상태이다.
그리고 해당 configuation이 적용 될 스케줄을 지정해준다.

State Manager를 활용하려면 SSM Documents를 사용하고 Association을 생성해야한다.
예를 들어 CloudWatch Agent를 설정하는 SSM Document를 생성할 수 있다.

**정리**
-   SSM Inventory는 관리되는 인스턴스(EC2, 온프레미스)로부터 메타데이터를 수집하는 데 사용된다.
    -   메타데이터에는 많은 것이 포함된다. 설치된 소프트웨어, OS 드라이버, Configurations, 설치된 업데이트, 실행중인 서비스 등등
    -   AWS 콘솔에서 데이터를 보거나 S3에 데이터를 저장해 Athena를 이용해 쿼리 후 분석하거나 QuickSight를 이용해 데이터 대시보드를 구축할 수도 있다.
    -   수집 간격은 분, 시간, 일 단위로 가능하다.
    -   여러 계정 및 Region에서 데이터를 모아 하나의 계정에서 중앙 집중형으로 쿼리를 날릴 수 있다.
    -   사용자 지정 인벤토리를 만들 수도 있으며, 설정 초기에 Click here to enable inventory on all instances 를 해주면 모든 인스턴스에 대한 inventory를 활성화 할 수 있다.
-   SSM State Manager는 관리되는 EC2를 우리가 정의한 상태로 유지하는 데 사용된다.
    -   사용 사례는 소프트웨어의 인스턴스를 부트스트랩하거나, OS나 소프트웨어 업데이트를 일정에 따라 패치하는 것이다.
    -   State Manager Association을 만들어 인스턴스가 유지되어야하는 상태를 정의할 수 있다. 예를 들어 무조건 포트 22번을 닫거나 EC2에 안티 바이러스를 설치해야 하는 등의 상태. 
    -   그리고 해당 Configuration이 적용 될 스케줄을 지정해줄수 있다.
    -   State manager를 활용하려면 SSM Documents를 사용하고 Association을 생성해야한다.

## **SSM Patch Manager and Maintenance Windows**

SSM 패치 매니저 개요
-   패치 매니저를 사용하여 관리되는 인스턴스의 패치 프로세스를 자동화
-   OS 업데이트, 응용 프로그램 업데이트 및 보안 업데이트를 포함한다.
-   EC2 인스턴스 및 온프레미스 서버, Linux, MacOS 및 Windows를 모두 지원한다.

-   패치 관리자를 사용하여 패치를 원할 때 실행하거나 Maintenance Windows를 사용하려면 일정에 따라 패치 관리자를 실행할 수 있다.
-   패치 관리자는 인스턴스를 스캔하고 패치 컴플라이언스 보고서를 생성한다. 이 보고서는 모든 Machine의 목록이고, 이 보고서에 따른 조치를 취할 수 있다.

**패치 매니저 구성 요소**
-   패치 베이스라인
    -   패치 베이스라인은 EC2 인스턴스에 설치해야하는 패치와 설치해서는 안되는 패치를 정의하며 사용자 정의 패치 베이스라인을 생성할 수 있다.
    -   사용자 정의 패치 베이스라인을 사용하여 인스턴스에서 승인 또는 거부된 패치를 지정할 수 있다. 패치는 출시된 지 일정 기간 이내에 자동으로 승인될 수도 있다.
    -   기본적으로 패치 베이스라인은 SSM 매니지드 인스턴스에 크리티컬 패치 및 보안 관련 패치만을 설치하도록 설정된다.
-   패치 그룹
    -   특정 패치 베이스라인을 정의하는 경우 배치 그룹을 생성하여 이를 연결할 수 있다. 예를들어 dev, test, prod에 대한 패치 그룹을 생성할 수 있다.
    -   패치 그룹을 사용할 때는 인스턴스가 tag key가 정의되어야 하고, 각 인스턴스는 언제든지 하나의 패치 그룹에만 속할 수 있다.
    -   패치 그룹은 하나의 패치 베이스라인에만 등록될 수 있다.

**패치 베이스라인 종류**
-   패치 베이스라인은 미리 정의된 베이스라인이 있고, 이는 AWS에서 관리하며 수정할 수 없다.
-   또한 사용자 정의 패치 베이스라인을 정의할 수 있다.
    -   여기에는 자동으로 승인되는 패치, 허용되는 패치, 거부되는 패치 및 운영체제가 포함될 수 있다.
    -   또한 사용자 지정 또는 대체 패치 저장소를 지정할 수 있다.

**Maintenance Windows**
-   인스턴스에서 작업을 수행할 일정을 정의할 때 사용된다.
-   OS 패치, 드라이버 업데이트 및 소프츠웨어 설치 등의 작업을 할 수 있으며, 특정 시간 및 기간에 수행 가능하다. (03:00 ~ 05:00 등)
-   Maintenance window는 일정과 기간 그리고 등록된 인스턴스의 집합 그리고 수행되어야할 태스크 등이 포함되어 있다.

**시험 관점에서 알아야할 내용**
-   패치 매니저가 인스턴스에 패치를 적용하는 데 사용된다는 것
-   필요하다면 특정 Maintenance Windows에서 특정 rate control도 가능하다.

**정리**
-   Patch Manager는 관리되는 인스턴스의 패치 프로세스를 자동화할 수 있다.
-   OS 업데이트, 응용 프로그램 업데이트 및 보안 업데이트를 포함하고, EC2 및 온프레미스 서버, Linux/MacOS/Windows OS를 모두 지원한다.
-   패치 매니저를 사용하여 패치를 원할 때 실행하거나 Maintenance Windows를 사용하여 일정에 따라 패치 매니저를 실행할 수 있다.
-   인스턴스를 스캔하고 모든 관리되는 인스턴스에 대한 패치 컴플라이언스 보고서를 생성하고, 이 보고서에 따른 조치를 취할 수 있다.
-   패치 매니저는 구성 요소가 있음
    -   패치 베이스 라인
        -   패치 베이스라인은 EC2 인스턴스에 설치해야되는 패치와 설치해서는 안되는 패치를 정의하며, 사용자 정의 패치 베이스라인을 생성할 수 있다.
        -   패치는 승인 또는 거부할 수 있으며 승인의 경우 자동 승인을 설정해 일정 기간까지 패치를 완료하거나 일정 기간 이후 패치를 완료하도록 설정할 수 있다.
        -   custom 베이스라인을 사용하게 되면 심각도 카테고리를 설정해 critical patch 및 important patch만을 패치를 설치하도록 구성할 수도 있다.
    -   패치 그룹
        -   특정 패치 베이스라인을 정의하는 경우 배치 그룹을 생성해 이를 연결할 수 있다.
        -   패치 그룹을 사용할 때는 인스턴스에 `Patch Group` 또는 `PatchGroup` 태그가 설정되어야 하고, 각 인스턴스는 key value만 같다면 언제든지 하나의 패치 그룹에 속한다. 또한 한 인스턴스는 하나의 패치 그룹에만 속할 수 있고, 패치 그룹은 하나의 패치 베이스라인에만 등록될 수 있다.
-   Maintenance Windows
    -   인스턴스에서 작업을 수행할 일정을 정의할 때 사용된다.
    -   OS 패치, 드라이버 업데이트 및 소프트웨어 설치 등의 작업을 할 수 있으며, 특정 시간 및 기간에 수행 가능하다. (03:00 ~ 05:00 등)
    -   일정과 기간 그리고 등록된 인스턴스의 집합 그리고 수행되어야할 태스크 등이 포함 돼 있다.
-   시험관점에서는 패치 매니저가 인스턴스에 패치를 적용하는 데 사용된다는 것, 필요하다면 특정 Maintenance Windows에서 특정 rate control도 가능하다는 것을 알면 된다.

## **SSM Session Manager Overview**
**개요**
-   EC2 인스턴스 및 온프레미스 서버에서 안전한 셸 환경을 시작하는 방법
-   콘솔, CLI 또는 세션 매니저 SDK를 통한 액세스를 지원하며, 세션 매니저의 중요한 이점은 인스턴스에 직접 SSH 액세스가 필요하지 않다는 것
-   배스쳔 호스트나 SSH 키가 필요하지 않다.

**작동 방식**
-   EC2 인스턴스는 SSM 에이전트를 실행하고 SSM 서비스에 등록할 Role이 있어야한다.
-   사용자는 올바른 IAM 권한으로 세션 매니저 서비스에 연결한다.
-   세션 매니저는 EC2 인스턴스에서 명령을 실행하여 Run commands 서비스 기능과 유사한 기능을 제공한다.
-   Linux, MacOS, Windows에 대한 공통 쉘 인터페이스를 제공한다.
-   모든 연결, 인스턴스 및 실행된 명령은 로그로 기록되며 로그는 Amazon S3 또는 CloudWatch Logs로 전송할 수 있다.

**보안 및 규정 준수**
-   CloudTrail은 StartSession 이벤트를 확인할 수 있어 자동화, 규정 준수 및 경고에 대한 가시성을 제공한다.
-   IAM Policy는 사용자 또는 그룹이 세션 매니저에 액세스하고 인스턴스 액세스를 정의하는 데 사용된다.
-   태그를 사용해 특정 EC2 인스턴스에만 액세스를 제한할 수 있다.

**IAM 정책 예시**
```json
{
  "Effect": "Allow",
  "Action": "ssm:StartSession",
  "Resource": "arn:aws:ec2:*:*:instance/*",
  "Condition": {
    "StringEquals": {
      "ssm:resourceTag/environment": "dev"
    }
  }
}
```

**추가 정보**
-   SSM에 액세스하고 S3 및 CloudWatch에 쓰기 권한이 필요하다.
-   선택적으로 세션에서 사용자가 실행할 수 있는 명령을 제한할 수 있다.

**정리**
-   세션 매니저는 EC2 인스턴스 및 온프레미스 서버에서 셸 환경을 안전하게 시작하는 방법이다.
-   콘솔, CLI 또는 세션 매니저 SDK를 통한 액세스를 지원하며, 세션 매니저는 인스턴스에 직접 SSH 연결하거나 배스쳔 호스트를 사용 하지 않아서 굉장한 이점이 있다.
-   EC2 인스턴스는 SSM Agent를 실행하고 SSM 서비스에 등록할 Role이 있어야 한다. 사용자는 IAM 권한을 사용해 세션 매니저 서비스에 연결한다. 세션 매니저는 EC2 인스턴스에서 명령을 실행한다.
-   Linux, MacOS, Windows에 대한 공통 셸 인터페이스를 제공한다.
-   모든 연결, 인스턴스에서 실행된 명령은 로그로 기록되며 로그는 S3, CloudWatch Logs로 전송할 수 있다.
-   CloudTrail은 StartSession 이벤트를 확인할 수 있어 자동화, 규정 준수 및 경고에 대한 가시성을 제공한다.
-   IAM Policy는 사용자 또는 그룹이 세션 매니저에 액세스하고 인스턴스 액세스를 정의하는 데 사용된다.
-   태그를 사용해 특정 EC2 인스턴스에만 액세스할 수 있도록 제한할 수 있다.
-   선택적으로 세션에서 사용자가 실행할 수 있는 명령을 제한할 수 있다.


## **[SAA/DVA] What is High Availability and Scalability?**
**개요**
Scalability와 고가용성
-   Scalability는 응용프로그램 시스템이 적응해 더 큰 부하를 견딜 수 있다는 것을 의미한다.
-   Scalability는 수직 Scalability, 수평 Scalability로 나뉜다.
-   Scalability는 Availability와는 다른 말이다.

**수직 Scalability**
-   인스턴스의 사이즈를 증가해야 한다는 것을 의미한다.
-   인스턴스 타입을 t2.micro 에서 t2.large로 업스케일링하는 경우를 말한다.
-   비분산 시스템의 경우 수직 Scalability를 사용해야한다. 예를 들어 데이터베이스가 있다.
-   일반적으로 수직으로 얼마나 확장할 수 있는지에는 제한이 있다.
**수평 Scalability**
-   응용 프로그램에 대한 인스턴스/시스템 수를 증가시킨다는 것을 의미한다.
-   모든 응용 프로그램이 분산 시스템이 될수 있는 것은 아니다.
**High Availability**
-   일반적으로 수평 Scalability와 함께 진행되지만 항상 그런것은 아니다.
-   응용 프로그램 또는 시스템을 최소한 두 개의 데이터 센터 또는 AWS의 두 가용 영역에서 실행한다는 것을 의미한다.
-   고가용성의 목표는 데이터 센터 손실을 견딜 수 있도록 하는 것이므로 한 센터가 다운 되더라도 여전히 운영이 가능하다.
-   RDS Multi AZ에서는 수동 형태의 고가용성이 있을 수 있다.

인스턴스를 수평으로 확장/축소 하는 것은 scale out/in 이라고 한다. 그리고 수직으로 확장/축소 하는 것은 scale up/down 이라고 한다.

고가용성은 Multi AZ가 활성화된 오토 스케일러 그룹이나 로드 밸런서를 위한 것이다.

## **[SAA/DVA] Elastic Load Balancing (ELB) Overview**
**개요**
-   로드 밸런서는 받은 트래픽을 여러 백엔드 또는 다운스트림 EC2 인스턴스 또는 서버로 전달하는 서버이다.
-   사용자가 많아질수록 로드는 EC2 인스턴스 전체에 고르게 분배된다. 그런데 핵심은 사용자가 어떤 백엔드 인스턴스에 연결되어 있는지 모른다는 것이다.
-   ELB를 사용해야하는 이유는 우리의 응용 프로그램에 대한 단일 액세스 포인트를 노출하기 때문이다.
-   다운스트림 인스턴스의 장애를 원활하게 처리할 수 있다.
-   로드 밸런서는 헬스 체크 매커니즘을 갖추고 있으며 어떤 인스턴스에 트래픽을 보내지 않아야 하는지 이해할 수 있다.
-   웹 사이트에 HTTPS 암호화 트래픽이 있는 경우 SSL Termination을 수행할 수 있다.
-   쿠키를 사용해 지속성을 강제할 수 있다.

**ELB란?**
-   ELB는 관리형 로드 밸런서이다. AWS가 관리하고 무슨 일이 있든 작동함을 보장한다. 업그레이드, 유지보수 및 고가용성을 처리한다.
-   자체 로드 밸런서를 관리해야 한다면 확장성 측면에서 어려움이 있을 것이다.
-   로드 밸런서는 다양한 AWS 오퍼링 및 서비스와 통합되어 있다. ASG, ECS, ACM, CloudWatch 등등 많은 서비스와 통합된다.

**Health check**
-   헬스 체크는 우리의 ELB가 EC2 인스턴스가 제대로 작동하는지 여부를 확인하는 방법이다. EC2가 제대로 작동하지 않는다면 해당 인스턴스로 트래픽을 보내고 싶지 않기 때문이다.
-   헬스 체크는 포트와 라우트를 사용하여 수행된다. 예를들어 프로토콜은 HTTP이고 포트는 4567이며 엔드 포인트는 /health이다. 이 같은 경우 200 상태 코드를 응답하지 않으면 인스턴스는 건강하지 않다고 표시될 것이다. 건강하지 않다고 생각이 되면 트래픽을 보내지 않을 것이다.

**ELB 종류**
-   CLB (Classic Load Balancer)
    -   구 버전 로드 밸런서이다.
    -   HTTP, HTTPS, TCP, SSL 등과 호환된다.
    -   전반적으로 AWS에서는 더이상 이 로드 밸런서를 사용하지 않기를 원한다.
-   ALB (Application Load Balancer)
    -   HTTP, HTTPS, 웹 소켓을 지원한다.
-   NLB (Network Load Balancer)
    -   TCP, TLS, UDP 프로토콜을 지원한다.
-   GWLB (Gateway Load Balancer)
    -   네트워크 레이어에서 작동하므로 세 가지 및 IP 프로토콜이 있다.

-   전반적으로 더 최신 세대의 로드 밸런서를 사용하는 것이 좋다.
-   네트워크나 외부 공개 로드 밸런서로 설정되거나 내부로 설정될 수 있다.

## **[SAA/DVA] Application Load Balancer (ALB)**

**개요**
-   레이어 7에서만 작동하는 로드 밸런서, 즉 HTTP에 특화되어 있다. 여러 대의 머신에 HTTP 응용 프로그램으로 라우팅할 수 있게 해준다.
-   여러 대의 머신은 대상 그룹(Target Group)이라 불리는 것에 그룹화된다.
-   컨테이너와 ECS를 사용할 때 유용하다
-   HTTP/2와 웹소켓을 지원하며, 리다이렉트를 지원한다. 로드 밸런서 수준에서 HTTP에서 HTTPS로 트래픽을 자동으로 리다이렉트 한다.
-   URL의 대상 경로를 기반으로 경로 라우팅을 지원한다. 예를들어 example.com/users 및 example.com/posts와 같이 URL의 대상 경로를 기반으로 라우팅할 수 있다.
-   또한 URL의 hostname 기반으로 라우팅할 수도 있다. 따라서 one.example.com 또는 other.example.com 을 사용해 액세스되는 경우 서로 다른 대상 그룹으로 라우팅될 수 있다.
-   그리고 쿼리 문자열과 헤더를 기반으로 라우팅할 수도 있다. 예를 들어 example.com/reserves 및 id=123&order=false는 서로 다른 대상 그룹으로 라우팅될 수 있다.
-   ALB는 마이크로 서비스와 컨테이너 기반 애플리케이션을 보유할 때 훌룡하다.
-   Auto Scaling 그룹에 의해서 ALB 뒤에 있는 애플리케이션이 관리될 수 있다.
-   Lambda 함수를 ALB 뒤에 둘수도 있다.
-   IP 주소를 ALB 뒤에 둘 수도 있으며, 이 IP는 반드시 Private IP 주소여야한다.
-   헬스 체크는 대상 그룹 수준에서 이뤄진다. 대상 그룹을 구성하려면 서버의 사설 IP를 지정해야한다.
-   ALB는 고정된 hostname을 얻게 된다. 
-   애플리케이션 서버는 클라이언트의 IP를 직접적으로 확인할 수 없다 클라이언트의 실제 IP는 X-Forwarded-For 헤어데 삽입된다.
-   X-Forwarded-Ports를 사용해 실제 클라이언트의 포트를 얻을 수 있고, X-Forwarded-Proto를 사용해 사용중인 프로토콜도 얻을 수 있다.

## **[SAA/DVA] Network Load Balancer (NLB)**
-   레이어 4 로드 밸런서이며 TCP 및 UDP 트래픽을 처리할 수 있다.
-   매우 높은 성능을 가지고 있어 백만 건 이상의 요청을 처리할 수 있다.
-   ALB에 비해 대기 시간이 줄어든다. 약 400밀리초 대비 100밀리초 정도가 된다.
-   가용 영역당 정적 IP가 하나뿐이며 각 AZ에 Elastic IP를 할당할 수 있다. 응용 프로그램을 정적 IP 집합으로 노출해야할 때 매우 유용하다. 시험에서 "애플리케이션은 오직 한/두/세 개의 다른 IP에서만 액세스 가능하다" 라고 한다면 NLB를 옵션으로 생각해야 한다.
-   극도의 성능, TCP 또는 UDP, 정적 IP를 보면 NLB라고 생각하면 된다.

**NLB 작동**
-   ALB와 매우 유사하게 작동한다.
-   대상 그룹을 생성하고 NLB가 해당 대상 그룹으로 리디렉션한다.
-   대상 그룹은 EC2 인스턴스가 될 수 있으며, IP 주소도 등록할 수 있다. IP 주소는 하드 코딩되어 있어야 하며, Private IP여야 한다. 소유한 EC2 인스턴스의 Private IP를 등록하거나 자체 데이터 센터에 있는 서버의 Private IP를 사용할수도 있다.
-   NLB를 ALB 앞에 놓을 수도 있다. 이렇게 하는 이유는 NLB 덕분에 고정 IP 주소를 얻을 수 있고, ALB 덕분에 HTTP 유형의 트래픽 처리에 대한 모든 규칙을 얻을 수 있다.
-   NLB 대상 그룹에서 수행되는 헬스 체크는 TCP, HTTP, HTTPS 의 세 가지 다른 종류의 프로토콜을 지원한다. 백엔드 애플리케이션이 HTTP 또는 HTTPS 프로토콜을 지원하는 경우 이러한 프로토콜에 대한 헬스 체크를 정의할 수 있다.


## **[SAA/DVA] Gateway Load Balancer (GWLB)**
-   게이트웨이 로드밸런서는 모든 네트워크 트래픽이 방화벽, 침입 탐지 및 방지 시스템(IDPS) 또는 패킷 검사 시스템을 통화하도록 하거나 네트워크 수준에서 일부 페이로드를 수정하려는 경우 사용한다.
-   사용자가 애플리케이션에 액세스할 때 모든 네트워크 트래픽을 애플리케이션에 도달하기 전에 검사하고 싶으면 third-party 어플라이언스(EC2와 같은)를 배치해야 했는데 GWLB를 사용하면 매우 간단해진다.
-   GWLB를 통과하면 로드 밸런서는 해당 트래픽을 가상 어플라이언스의 대상 그룹에 분산시킨다. 따라서 모든 트래픽은 애플라이언스에 도달하게 되고 애플라이언스는 트래픽을 분석하고 해야 할 작업을 수행한다. 작업은 방화벽, 침입자 탐지 등이 있을 수 있다. 만약 해당 작업에서 만족하지 않다면 트래픽을 드롭할 수 있다.(방화벽의 경우) 트래픽은 게이트웨이 로드 밸런서를 다시 통과하고 게이트웨이 로드 밸런서가 트래픽을 애플리케이션으로 전달한다.
-   위 과정을 정리하면 모든 트래픽이 GWLB를 통과하고 분산된 third-party appliance가 모든 네트워크 트래픽을 분석하고 필요에 따라 드롭했다고 보면 된다.
-   게이트웨이 로드 밸런서는 L3에서 동작한다. 
-   게이트웨이 로드 밸런서는 두 가지 기능이 있다.
    1.  명료한 네트워크 게이트웨이.
        -   왜냐하면 VPC의 모든 트래픽이 단일 진입 및 단일 탈출인 게이트웨이 로드 밸런서를 통과하기 때문이다.
    2.  로드 밸런싱
        -   트래픽을 가상 어플라이언스 및 대상 그룹의 세트에 분산 시킨다.
-   시험에서 "GENEVE 프로토콜을 사용하고 포트 6081에서 사용하려면" 이라면 게이트웨이 로드 밸런서를 사용한다는 것이다.
-   게이트웨이 로드 밸런서의 대상 그룹이 될 수 있는 것은 Third-party 애플라이언스이다. 이것은 EC2 인스턴스일 수 있고 인스턴스 ID로 등록할 수 있다. 그리고 Private IP 주소로 등록할 수 있다. 자체 네트워크 또는 자체 데이터 센터의 서버도 등록 가능하다.


## **[SAA/DVA] Elastic Load Balancer - Sticky Sessions**
-   ELB에 대해 스티키 세션 또는 세션 어피니티를 구현하는 것이 가능하다.
-   이것은 로드 밸런서로 두 번의 요청을 하는 클라이언트가 동일한 백엔드 인스턴스를 가지고 응답하도록 하는 것이다.
-   클라이언트에서 로드 밸런서로 요청할 때 요청과 함께 쿠키가 전송되며 쿠키 안에는 스티키 세션이 있고 만료 날짜가 있다. 따라서 쿠키가 만료되면 클라이언트는 다른 EC2 인스턴스로 리디렉션될 수 있다.
-   사용 사례는 사용자가 세션 데이터를 잃지 않기 위해 동일한 백엔드 인스턴스에 연결되어 있는지 확인하는 것이다. 세션 데이터에는 사용자의 로그인과 같은 중요한 정보가 포함될 수 있다.
-   스티키 세션을 활성화 하면 일부 인스턴스에 요청이 고정 돼 인스턴스에 불균형을 초래할 수 있다.
-   쿠키 자체는 어떻게 되는걸까? 스티키 세션에는 두 가지 유형의 쿠키가 있다.
    -   첫 번째는 응용 프로그램 기반 쿠키
        -   응용 프로그램 기반 쿠키의 경우 대상(응용 프로그램 자체)에서 생성하는 사용자 정의 쿠키이다.
        -   여기에는 응용 프로그램에서 필요한 모든 사용자 정의 속성을 포함할 수 있다.
        -   쿠키 이름은 각 대상 그룹에 대해 개별적으로 지정되어야하며 다음 이름을 사용해서는 안된다. AWSALB, AWSALBAPP, AWSALBTG. 이것은 이미 ALB에서 사용하기 위해 예약되어 있다.
    -   두 번째는 기간 기반 쿠키
        -   ALB의 경우 쿠키 이름은 AWSALB이고, CLB의 경우 AWSELB이다. 이 쿠키는 특정 기간에 기반하여 만료되며, 해당 기간은 로드 밸런서에서 생성된다.
    -   응용 프로그램 기반 쿠키의 경우 응용 프로그램 자체에서 지정할 수 있다.
-   스티키 세션은 타겟 그룹에서 설정 가능하다.
-   기간형 스티키 세션의 경우 1초에서 7일 사이의 기간을 설정 가능하다. 또는 응용 프로그램 기반 쿠키로 1초에서 7일까지의 기간을 설정할 수 있지만 애플리케이션에서 로드 밸런서로 전송하는 쿠키 이름을 지정해야 한다.

## **[SAA/DVA] Elastic Load Balancer - Cross Zone Load Balancing**
-   예를 들어 두 가용 영역이 있고 첫 번째 영역에는 두 개의 인스턴스가 그리고 두 번째 영역에는 여덟 개의 EC2 인스턴스가 있다고 가정할때 Cross Zone Load Balancing을 사용하면 로드 밸런스에 등록된 인스턴스에 트래픽이 고르게 분배된다.
-   기존에는 ALB에 부여된 타겟 그룹을 기준으로 50% / 50% 의 트래픽을 분산시키지만 위와 같은 경우에는 불균형을 초래할 수 있으니 10개의 인스턴스를 기준으로 트래픽을 리디렉션해 고르게 분배한다.
-   Cross Zone을 사용하지 않는 경우 트래픽이 각 AZ 내에서 유지된다.
-   ALB의 경우 Cross Zone Load Balancing이 기본적으로 활성화되어 있지만 타겟 그룹 수준에서 비활성화할 수 있으며 AZ 간에 데이터 이동 시 원래는 비용을 지불해야 하지만 활성화 된 경우 요금이 부과되지 않는다.
-   NLB, GWLB의 경우 Cross Zone Load Balancing이 기본적으로 비활성화되어 있다. ALB 같은 경우와 다르게 GWLB의 경우 기본적으로 비활성화 상태에서 활성화를 하게 되면 AZ 간 데이터 이동 시 일정량의 비용이 발생한다.

## **[SAA/DVA] Elastic Load Balancer - SSL Certificates**
-   SSL 인증서는 클라이언트와 로드 밸런서 간의 트래픽을 전송 중에 암호화할 수 있게 한다. 이를 "In-flight encryption"이라고 한다. 데이터가 네트워크를 통과하는 동안 암호화되고 보내는 사람 및 수신자만 해독할 수 있다.
-   SSL은 Secure Sockets Layer의 약자이며 전송 연결을 암호화하는 데 사용된다. TLS는 SSL의 최신 버전으로 Transport Layer Security를 나타낸다.
-   Public SSL 인증서는 Certificate Authorities(인증 기관)에 의해서 발급되며, CA는 Letsencrypt/symantec/GoDaddy/Digicert 등이 있다.
-   Public SSL 인증서를 로드 밸런서에 연결해 클라이언트와 로드 밸런서 간의 연결을 암호화할 수 있다.
-   SSL 인증서는 설정한 만료 날짜를 가지고 정기적으로 갱신되어야 한다.
-   인증서의 만료일은 ACM(AWS Certificate Manager)을 사용하여 AWS에서 관리할 수 있으며, 필요한 경우 ACM에 직접 인증서를 업로드할 수도 있다.
-   HTTPS 리스너를 설정할 때는 기본적으로 인증서를 지정해야 한다. 다중 도메인을 지원하는 선택적인 인증서 목록을 추가할 수 있으며, SNI(Server Name Indication)을 사용해 hostname을 지정할 수 있다.
-   예를 들어 ALB가 두 개의 SSL 인증서, domain1.example.com domain2.example.com 두 개의 도메인 주소를 가지며 해당하는 타겟 그룹이 각각 있다고 가정했을 때, ALB에 클라이언트가 domain1.example.com에 들어오고자 하면 ALB는 그에 맞는 SSL 인증서와 타겟그룹을 사용해야할 것이다. 
-   ALB는 올바른 SSL 인증서를 가져와서 트래픽을 암호화 한 다음 경로를 통해 올바른 타겟 그룹으로 리디렉션할 것이다. SNI를 사용하면 다른 SSL 인증서를 사용해 여러 웹 사이트에 대한 여러 타겟 그룹을 가질 수 있다는 말이다.
-   CLB의 경우 하나의 SSL 인증서만 지원할 수 있고, ALB v2의 경우 여러 리스너와 여러 SSL 인증서를 지원할 수 있다.
-   NLB의 경우도 SNI를 지원한다.

## **[SAA/DVA] Elastic Load Balancer - Connection Draining**
-   CLB를 사용하는 경우 Connection Draining 이라고 하지만 ALB 또는 NLB를 사용하는 경우 Deregistration Delay 라고 불린다.
-   인스턴스가 Deregestration 즉, 등록 해제되거나 Unhealthy 상태로 표시될 때 In-flight 요청 또는 active 요청을 완료할 충분한 시간을 제공하는 것이다.
-   인스턴스가 Drain 되어서 연결이 드레인되면, ELB는 인스턴스가 Deregistration되는 동안 드레인 중인 EC2 인스턴스로 요청을 보내지 않는다.
-   deregistration_delay.timeout_seconds 파라미터 값이 존재하는 데 이는 기본값 300초(5분)이며, 값이 0으로 설정되면 Drain이 발생하지 않는다. 최소 1에서 최대 3,600 사이의 값을 설정할 수 있다.
-   애플리케이션의 요청이 짧은 경우(ex:1초 미만) 매개변수를 30초로 설정하는 것이 좋다. 이렇게 하면 EC2 인스턴스가 매우 빨리 드레인되고 오프라인으로 전환된다. 업로드 또는 긴 지속 요청이 있는 경우 값을 높게 설정하는 대신에 인스턴스가 빨리 사라지지는 않을 것이다.

## **Elastic Load Balancer - Health Checks**
-   ALB 또는 대상 그룹 자체에서 Health check를 설정할 수 있다.
-   예를 들어 백엔드 인스턴스에 Health check 설정을 한다고 가정해보자.
-   프로토콜은 HTTP 프로토콜을 사용하고, 포트는 인스턴스에 연결할 포트이다. 기본적으로 80은 HTTP 포트지만 사용자 정의할 수 있다. Check path는 Health check 요청을 보낼 위치이다. 
-   path가 "/" 로 되어 있는 경우는 웹 사이트의 루트로 보내라는 것을 의미하지만 많은 웹 사이트나 애플리케이션은 "/health" 경로를 가지고 있으며 이는 EC2 인스턴스에서 특정 테스트를 하기 위한 health check 경로이다.
-   check timeout은 health check가 실패로 간주되기까지의 시간으로 기본적으로 5초이다. 따라서 5초 안에 health check 가 성공하지 않으면 5초 후에 실패로 간주된다.
-   interval은 대상 그룹 또는 ALB가 Health check를 수행하는 빈도이다. 매우 낮은 값을 설정하면 응용 프로그램이 과도하게 사용될 수 있다. 30초가 health check 하는 좋은 기본값이지만 물론 이를 감소시킬 수 있다.
-   healthy threshold counts는 대산이 건강한 것으로 간주되기 전에 health check가 성공해야 하는 횟수이며, unhealthy threshold counts는 인스턴스가 건강하지 않다고 간주되기 전에 연속으로 health check가 실패해야 하는 횟수이다.
-   health status는 초기 등록 중인 경우 healthy, 건강하지 않은 경우 unhealthy, 사용되지 않는 경우 unused(대상이 등록되지 않음), 드레인 중인 경우 draining(대상이 등록 해제 중), health check가 비활성화된 경우 unavailable이 있다.
-   시험에서 알면 좋은 것은 대상 그룹에 unhealthy만 포함된 경우 ELB는 모든 unhealthy 대상으로 요청을 라우팅할 것이다. 이 경우는 health check 자체가 잘못 되었고, 인스턴스는 여전히 작동할수도 있기 때문에 health check가 잘못되었다고 가정하고 요청을 라우팅하는 것이다.
-   health check가 EC2 인스턴스의 다른 포트에서 수행되는 경우 트래픽 포트 오버라이드를 수행할 수 있다.
-   health check 를 완료하고 200 status code를 재전송하는 대신에 특정 code를 설정할 수 있다.

## **Elastic Load Balancer - Monitoring, Troubleshooting, Logging and Tracing**
**개요**
-   로드밸런서에서 발생할 수 있는 에러 유형을 살펴보자
-   일반적으로 성공적인 요청은 200으로 나타난다.
-   클라이언트의 웹 브라우저에서 오류가 발생하는 등 클라이언트가 오류를 발생시키면 4XX 유형의 오류를 수신하게 된다.
    -   400은 잘못된 요청, 401은 권한 없음, 403은 Forbidden, 460은 클라이언트가 연결을 닫음, 463은 헤더 X-forwarded-for가 잘못된 경우
-   로드 밸런서 또는 백엔드 EC2 인스턴스가 잘못되어 서버 측에서 발생하는 모든 오류는 5XX 유형의 코드가 된다.
    -   500은 내부 서버 오류, 502는 잘못된 게이트웨이, 503은 서비스를 사용할 수 없음(EC2 인스턴스가 로드 밸런서에 응답을 보낼 수 없는 경우), 504는 게이트웨이 시간 초과, 561은 권한 없음
-   시험 관점에서 4XX 코드는 클라이언트 측 오류이므로 클라이언트 문제를 나타내며, 5XX 오류는 서버 문제이다. 이것은 로드 밸런서에서 확인할 메트릭 유형을 결정하는 데 도움이 되는 정보이다.

**로드 밸런서의 메트릭**
-   로드 밸런서에서 CloudWatch 메트릭으로 직접 전송되는 메트릭이 있다.
-   예를들어 백엔드 연결 오류를 모니터링해 EC2 인스턴스가 오류를 발생시키는지 확인할 수 있다.
-   UnHealthyHostCount와 HealthyHostCount는 매우 중요하다. 로드 밸런서에 6개에 인스턴스가 등록되어 있고 2개가 다운되었다고 가정할 때 HealthyHostCount는 4개이고, UnHealthyHostCount는 2개이다.
-   다음으로 2XX, 3XX, 4XX, 5XX 가 있다.
-   클라이언트에게 요청을 얼마나 빨리 받아올 수 있는지에 대한 정보인 latency 정보가 있다.
-   로드 밸런서의 전체 요청 횟수를 나타내는 RequestCounts
-   평균적으로 얼마나 많은 EC2 인스턴스가 요청을 받는지에 대한 RequestCountPerTarget
-   대기 중이며 Healthy한 인스턴스로 라우팅되는 총 요청 수이며, ASG를 확장하는 데 도움이 될 수 있는 SurgeQueueLength. 최대 값은 1000이며, 큰 요청 대기열이 필요가 없기 때문에 이 대기열이 0에 가깝게 유지 되도록 해야한다.
-   SpilloverCount는 대기열이 가득 차서 거부된 요청의 수이다. 0보다 큰 값을 갖는 것을 절대로 피해야한다. 0보다 크다면 백엔드를 확장해 추가 요청을 처리하고 클라이언트가 일부 요청을 잃고 있는지 확인해야 한다.

**예시**
-   메트릭을 사용해 문제를 해결하려면 다음과 같다.
    -   400 Bad Request는 클라이언트가 잘못된 요청을 보냈다는 것을 의미한다.
    -   503은 로드 밸런서에 사용가능한 healthy한 인스턴스가 없다는 것을 의미하므로 HealthyHostCount 메트릭 및 CloudWatch를 확인할 수 있다.
    -   504는 게이트웨이 시간 초과다. EC2 인스턴스의 keep-alive 설정이 활성화되어 있는지 확인하고, keep-alive timeout이 로드 밸런서의 idle timeout 설정보다 큰지 확인해야한다.

전반적으로 로드 밸런서에대한 Alarm을 설정하고 문서 기반의 문제 해결을 해야한다.

**Load Balancer Access Log**
-   로드 밸런서의 액세스 로그는 S3에 저장될 수 있다. 이 로그에는 로드 밸런서에 대한 모든 요청이 포함된다.
-   time, client IP address, latencies, request paths, server response, trace ID와 같은 메타데이터가 포함된다.
-   S3로 로그를 전송할 때 비용이 발생하고 전송 비용만 지불하게 된다.
-   액세스 로그는 규정 준수 및 디버깅에 매우 유용하며 ELB 또는 EC2 인스턴스가 종료된 후에도 액세스 데이터를 보관하는 데 도움이 된다.
-   액세스 로그는 추가 보안을 위해서 암호화된다.
asdasd
**request tracing**
-   X-Amzn-Trace-Id라는 사용자 지정 헤더가 각 HTTP 요청에 추가된다.
-   이 헤더는 단일 요청을 추적하는 데 분산 추적 플랫폼이나 로그에서 매우 유용하다.
-   ~주의할 점은 ALB가 아직 X-Ray와 통합되어 있지 않다는 것이며 따라서 X-Ray에서 이러한 request tracing이 나타나지 않을 것이다.~
    -   240227 기준으로 HTTP 요청을 추적할 수 있다. [확인 링크](https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/load-balancer-request-tracing.html)

**모니터링 옵션**
-   ELB 콘솔창에서 확인할 경우 Monitoring 탭에서는 모든 로드 밸런서에 대한 사용 가능한 메트릭을 확인할 수 있다.
-   Target Response Time, 부하 확인하기에 좋은 
Requests(시간 당 요청 수), 어디서 문제가 발생했는지 이해하기 위한 오류 코드 메트릭, ASG에서 scale용도로 사용하기 좋은 ActiveConnectionCount, 로드 밸런서가 실제로 얼마나 지불하는 지에 대한 Consumed Load Balancer Capacity Units(ConsumedLCUs) 등 중요한 메트릭이 있다.
-   로그에 대한 옵션을 살펴볼수도 있다. 액세스 로그를 모니터링하려면 속성을 편집하고 활성화할 수 있으며, 로드 밸런서로 전송된 모든 로그를 S3 버킷으로 전송하도록 설정할 수 있다.
-   Amazon Athena 서비스를 사용해 이러한 액세스 로그를 쿼리할 수 있다.

## **Elastic Load Balancer - Monitoring, Troubleshooting, Logging and Tracing**
-   대상 그룹에 설정할 수 있는 모든 옵션을 살펴보자
-   등록 취소 지연 (deregistration delay)
    -   로드 밸런서가 대상을 등록 취소하기 전에 대기해야 하는 시간에 해당하는 초 단위의 시간 제한이다.
-   느린 시작 (slow start)
    -   느린 시작 모드를 사용하면 로드 밸런서가 대상으로 전체 요청 공유를 보내기 전에 대상에 워밍업 시간이 제공된다. 초 단위의 워밍업 시간
-   라우팅 알고리즘이 있다.
    -   라운드 로빈
    -   최소 미해결 요청
    -   흐름 해시 알고리즘(Flow hash)
-   스티키 설정이 있다.
    -   활성화 여부, type(애플리케이션 기반 또는 기간 기반), 쿠키 이름(애플리케이션 기반, 기간 기반), 초 단위의 애플리케이션 기반의 쿠키 만료 기간
-   slow start 와 routing 알고리즘의 차이를 알아보자
    -   slow start는 기본적으로 타겟 그룹에서 온라인 상태가 될 때마다 전체 요청을 수신하기 때문에 트래픽을 EC2 인스턴스로 점진적으로 전송하는 방법이다. slow start를 사용하지 않으면 EC2 인스턴스가 대상 그룹의 일부가 되자마자 전체 요청을 받게 되어 인스턴스에 과부하가 걸릴 수 있다.
    -   따라서 로드 밸런서는 0에서 시작해 슬로우 스타트가 종료될 때까지 대상에 보내는 요청의 수를 선형적으로 증가시킨 다음 전체 몫을 차지하게 된다.
    -   slow start를 사용하지 않으려면 slow start duration을 0으로 설정하면 된다. duration은 최대 900초까지 설정 가능하다.
    -   라우팅 알고리즘 중 **최소 미해결 요청**은 기본적으로 가장 사용량이 적은 인스턴스가 다음 요청을 수신할 인스턴스가 된다. 일반적으로 수신되는 요청의 복잡성이 다양하고 등록된 대상의 처리 능력이 다를때 사용된다.
    -   최소 미해결 요청은 slow start 모드에서는 사용할 수 없다.
    -   **라운드 로빈**의 경우 사용 가능한 요청의 수에 관계없이 대상이 차례로 다음 요청을 받게 된다. 대상 그룹에 3개의 인스턴스가 있다고 가정하면 1, 2, 3 의 순서대로 요청을 전달하고 다시 1에게 요청을 받게되는 것
    -   NLB에는 **flow hash 요청 라우팅**이 있는데, 프로토콜의 해시, 소스 대상 IP 주소, 소스 대상 포트 및 TCP 시퀀스 번호를 기반으로 대상이 선택된다. 각 TCP 및 UDP 연결은 연결이 지속되는 동안 단일 대상으로 라우팅되며, NLB의 스티키 세션과 동일하다. 간단하게 사용자가 요청을 할 때마다 방금 말한 모든 정보가 flow hash 알고리즘을 통해 해시된다. 그리고 해시 번호 덕분에 TCP 연결이 열려 있는 한 동일한 사용자의 동일한 요청을 동일한 EC2 인스턴스로 라우팅 할 수 있다.

## ALB Rules - Deep Dive
-   ALB에는 리스너 규칙(Listener Rule)이 있다.
-   ALB는 여러 규칙이나 한 규칙만 가질 수 있고, 항상 가장 마지막으로 수행되는 기본 규칙이 있다. 각 규칙은 특정 대상을 가진다.
-   규칙은 순서(Priority)가 있으며 순서대로 처리된다.
-   예를 들면 특정 대상 그룹으로 전달하거나 다른 특정 URL로 리디렉션하거나 고정 response를 보낼 수 있다.
-   기본 규칙을 제외한 나머지 규칙은 특정 조건을 가질 수 있다.
    -   예를 들어 host header 규칙, HTTP request method(GET 또는 POST인지 확인하는), path pattern("/myapp1","/myapp2"), Source IP(어디서 요청이 오는지 확인), http-header, query-string 등이 있다.
    -   이와 같은 특정 조건을 이용해 다양한 대상 그룹으로의 복잡한 라우팅을 만들 수 있게 해준다.
-   ALB의 단일 규칙에서 대상으로서 여러 대상 그룹을 가질수 있다.
    -   하나의 규칙 내에서 각 대상 그룹에 대한 가중치를 지정할 수 있게하는 방법이다.
    -   가중치를 통해 백엔드 서비스를 한 대상 그룹에서 다른 대상 그룹으로 업데이트할 수 있다. 예를 들어 v1을 한 대상 그룹에 두고 v2를 다른 대상에 둔 후 가중치를 사용해 트래픽을 제어해 v2를 시험해볼 수도 있다.

## [SAA/DVA] Auto Scaling Groups (ASG) Overview
-   웹 사이트나 응용 프로그램을 배포할 때 시간이 지남에 따라 웹 사이트를 방문하는 사용자가 많아져 부하가 변경될 수 있다.
-   AWS에서 EC2 인스턴스 생성 API 호출로 서버를 빠르게 생성하고 제거할 수 있기 때문에 이를 자동화한 것이 Auto Scaling Group이다.
-   ASG의 목표는 EC2 인스턴스를 확장(out)하는 것이다. 기억해야 할 중요한 점은 늘어난 부하에 맞춰 확장(out)하거나 축소(in)하여 부하가 감소하는 것이다.
-   ASG는 최소 및 최대 EC2 인스턴스 수를 보장하기 위한 매개변수를 정의할수도 있다. 그래서 ASG의 크기는 시간에 따라 변할 것이다.
-   ASG는 로드 밸런서와 결합하는 경우 ASG의 일부로 있는 모든 EC2 인스턴스가 로드 밸런서에 연결된다.
-   하나의 인스턴스가 Unhealthy 상태로 판단되면 해당 인스턴스가 종료되고 대신에 새로운 EC2 인스턴스가 생성된다.
-   ASG는 무료이며 EC2 인스턴스와 같은 하위 리소스가 생성된 만큼만 요금을 지불하면 된다.
-   ASG는 최소한으로 필요한 인스턴스 수인 minimum capacity 을 설정하고 최대 인스턴스 수인 maximum capacity를 설정하고, Desired capacity를 최대 용량보다는 작게 필요에 따라 확장할 수 있다.
-   ELB는 EC2의 상태를 health check를 사용해 확인하고 해당 상태를 ASG에 전달할 수 있다. 로드 밸런서의 판단에 따라 ASG가 해당 EC2 인스턴스를 종료할 수 있어 편리하다.
-   ASG에 인스턴스가 추가되면 ELB도 트래픽을 해당 인스턴스로 보내고 부하를 분산 시킬 것이다. 따라서 로드 밸런서와 ASG를 함께 사용하는 것은 훌룡한 조합이다.
-   ASG를 만들려면 launch templates을 만들어야한다. launch configurations가 templates 이전에 있었지만 현재는 사용되지 않는 개념이다.
-   launch template
    -   런치 템플릿은 ASG 내에서 EC2 인스턴스를 시작하는 방법에 대한 정보를 포함한다.
    -   AMI 및 인스턴스 유형, EC2 User data, EBS 볼륨, 보안 그룹, SSH 키페어, EC2 인스턴스용 IAM 역할, 네트워크 및 서브넷 정보, 로드 밸런서 정보 등이 포함된다. 이 모든 매개변수는 우리가 EC2 인스턴스를 생성할 때 지정한 것과 매우 유사하다.
-   ASG에는 우리가 정의해야 할 최소 크기, 최대 크기 및 초기 용량이 있으며 스케일링 정책도 있다.
-   스케일링 정책
    -   CloudWatch 알람을 기반으로 ASG의 인스턴스를 확장 및 축소할 수 있다.
    -   예를 들어 ASG 전체의 평균 CPU와 같은 메트릭을 기반으로 알람을 생성하고 평균 CPU가 너무 높다면 알람이 발생해 트리거되고 ASG에서 스케일링을 하게 된다. 
    -   결과적으로 알람을 기반으로 스케일 아웃 또는 스케일 인 정책을 생성해 인스턴스를 증가 또는 감소할 수 있다.


## [SAA/DVA] Auto Scaling Groups - Scaling Policies
**ASG에는 여러가지 스케일링 정책이 있다.**
-   동적 스케일링
    -   트래픽의 변화에 따라 ASG의 용량을 조정하는 정책
    -   Target tracking scaling
        -   CPU 사용률 같이 ASG에 대한 메트릭을 정의하고 목표 값을 정의하는 것이다.
        -   CPU 사용률을 40%로 설정하면 ASG는 자동으로 확장 또는 축소 해 메트릭을 약 40%로 유지한다.
    -   Step scaling과 Simple scaling의 경우 CloudWatch 알람을 정의해 ASG에 용량 단위를 추가하거나 제거하려는 경우 트리거 되게 된다.
-   예약된 스케일링(scheduled scaling)
    -   운영자가 알고 있는 사용 패턴을 기반으로 스케일링을 예측하는 경우
    -   예를 들어 매주 금요일 오후 5시에 사용자가 발생할 것으로 예상되면 최소 용량을 늘릴 수 있다.
-   예측 스케일링(predictive scaling)
    -   주기적인 데이터가 있는 경우 매우 유용하다.
    -   ASG는 자동으로 기존에 남아있는 기록을 분석한 다음 예측을 생성하고 예측을 기반으로 스케줄링 작업을 수행한다.
-   스케일링을 위한 좋은 메트릭은 의문이다. 보통 여러가지가 있다.
-   첫 번째는 CPU 사용률이다. 왜냐하면 모든 인스턴스의 평균 CPU 사용률을 확인하고 이 값이 높아지면 인스턴스가 더 많이 사용된다는 의미이므로 이를 기반으로 스케일링하는 것이 좋다.
-   두번째는 RequestCountPerTarget이다. 응용 프로그램에 특화된 메트릭이다. 3 개의 인스턴스가 있는 ASG가 있고 ALB가 이를 통해 요청을 분산하고 있을 때 RequestCountPerTarget 메트릭 값은 3이다. 왜냐하면 각 인스턴스는 평균적으로 3개의 요청이 처리 대기 중이기 때문이다.
-   다음으로는 ASGAverageNetworkIn, ASGAverageNetworkOut이 있다. 응용 프로그램이 네트워크에 제한되어 있고 업로드 및 다운로드가 많은 경우 인스턴스에 대한 평균 네트워크 In 또는 Out 바이트수를 기준으로 스케일을 조절할 수 있다.
-   그리고 CloudWatch에서 설정하는 사용자 지정 메트릭 중 하나를 사용할 수 있어 응용 프로그램 별로 사용자 지정 메트릭을 설정하고 이를 기반으로 스케일링 정책을 설정할 수 있다.

**스케일링 쿨다운**
-   인스턴스를 추가하거나 제거하는 등의 스케일링이 발생한 후 항상 쿨다운 기간에 들어가는데 그 동안 ASG는 추가로 인스턴스를 시작하거나 종료하지 않는다. 기본 300초/5분이다.
-   이유는 메트릭이 안정화되고 새로운 인스턴스가 이펙트를 발휘하여 메트릭이 어떻게 변화되는지 확인하기 위해서.
-   그래서 스케일링 활동이 발생하면 쿨다운이 적용되었는지 여부를 확인하게 된다.
-   쿨다운이 기본적으로 적용되어 있다면 scaling을 무시하고 그렇지 않다면 scaling을 진행한다.
-   한 가지 팁은 인스턴스의 구성 시간을 줄이기 위해 준비된 AMI를 사용하는 것이다. 인스턴스를 구성하는 데 시간을 낭비하지 않으면 인스턴스가 즉시 활성화돼 요청에 빠르게 응답할 수 있다. 그리고 활성화되는 시간이 더 빨라 쿨다운 기간은 줄일 수 있고 ASG의 더 동적인 스케일링을 얻을 수 있다
-   ASG에 대한 Detailed monitoring을 활성화해 메트릭을 1분마다 얻고 이러한 메트릭이 충분히 빠르게 업데이트되도록 확인하는 것도 방법이다.

## **ASG for SysOps**
-   시험에 참여하기 전에 알아야 할 몇 가지 기능을 살펴보자.
-   ASG에 속해있는 인스턴스에 대한 라이프사이클 훅이 있다.
-   인스턴스를 시작하거나 종료할 때 실행되는 것을 의미한다.
-   기본적으로 인스턴스를 생성하면 pending 상태에서 in service 상태로 즉시 전환된다. 그러나 추가적인 단계를 수행하기 위해 라이프사이클 훅을 설정할 수 있다.
-   pending 후에 라이프사이클 훅의 일부로 pending wait 상태로 이동할 수 있으며 이 상태에서는 인스턴스가 시작될 때 실행할 스크립트를 정의할 수 있다. 예를 들어 초기 설정을 위해 EC2 인스턴스의 초기 설정이 완료되면 pending proceed 상태로 이동하도록 만들 수 있다.
-   그 후에 in service 상태로 이동한다. 따라서 이 라이프사이클 훅을 사용하면 pending과 in service 상태 사이에서 사용자 지정 로직을 수행할 수 있다.
-   또한 인스턴스가 종료되기 전에 어떤 작업을 수행할 수도 있다. 예를 들어 인스턴스가 in service에서 terminating으로 전환된다면 라이프사이클 훅의 일부로 termination wait 상태로 이동할 수 있다. 이 상태에서 다시 스크립트를 실행하거나 몇 가지 로그를 가져오거나 원하는 작업을 수행하거나 정보를 가져오거나 AMI를 만들거나 EBS 스냅샷을 찍을 수도 있다.
-   그 다음 terminating proceed로 이동한 후 terminated 상태로 전환된다.
-   이러한 모든 라이프사이클 훅의 사용 사례는 인스턴스가 시작되고 서비스로 전환되기 전에 cleanup, 로그 추출 또는 특수 헬스 체크를 수행하는 것이다.
-   라이프사이클 훅에 스크립트를 통합하려면 EventBridge, SNS 및 SQS를 사용하면 된다. 라이프사이클 이벤트가 트리거될 때 이 세 가지 대상 중 하나로 메시지가 전송될 수 있다.
-   예를 들어 EventBridge로 전송되면 람다 함수를 호출해 추가적인 스크립팅을 수행할 수 있다.
-   ASG에는 launch configurations, launch templates가 있다.
-   두 가지 모두 EC2 인스턴스를 시작하기 위한 AMI, 인스턴스 유형, 키페어, 보안 그룹 및 기타 매개변수를 지정할 수 있게 해주며, 태그 및 사용자 데이터가 포함된다. 이것은 모두 ASG가 인스턴스를 시작하는 데 사용된다.
-   런치 구성은 편집할 수는 없다. 따라서 새로운 환경 설정의 런치 구성을 만들고 싶을 때마다 실제로 런치 구성을 새로 만들어야한다.
-   그리고 런치 템플릿의 경우 새 버전을 만들어야 한다.
-   ***런치 구성은 AWS의 레거시한 부분이어서 실제로 더이상 사용되지 않는다.***
-   런치 템플릿은 매개 변수 하위 집합을 만들 수 있어서 구성 재사용 및 상속을 위해 다른 런치 템플릿을 기반으로 하는 런치 템플릿을 가질 수 있다.

-   런치 템플릿의 일부로 온디맨드 및 스팟 인스턴스 또는 둘을 혼합하여 프로비저닝 해 최적화된 Fleet을 가질 수 있다. (런치 구성으로는 불가능함)
-   런치 템플릿은 Placement Group, capacity reserve, dedicated host 및 여러 인스턴스 유형을 지원한다.
-   T2 무제한 버스트 기능을 사용할 수 있다.

SQS와 Auto Scaling
-   어떻게 SQS 큐 상태를 기반으로 ASG를 스케일링할 것인가에 대한 내용이다.
-   SQS 큐와 해당 큐에서 메시지를 처리하는 여러 EC2 인스턴스가 있다고 가정해보자, 여기서 할 일은 SQS 큐에 있는 메시지의 양에 따라 ASG를 조정하는 것이다.
-   이를 위해서 CloudWatch 메트릭을 만들 수 있다. 예를 들어 queue length에 대한 메트릭이다. 메트릭은 ApproximateNumberOfMessages 이다.
-   처리해야 할 메시지가 너무 많은 큐 길이가 너무 길때 알람을 발생하고 ASG에서 스케일링 정책을 트리거할 수 있다.

ASG 헬스체크
-   고가용성을 보장하려면 ASG에 적어도 두 개의 인스턴스가 있어야 한다.
-   그리고 EC2 health check와 같은 몇 가지 헬스 체크를 수행할 수 있다. EC2 인스턴스의 기본 소프트웨어 및 하드웨어가 여전히 작동 중인지 확인하기 위한 것으로 기본적으로 활성화되어 있다.
-   ELB 헬스 체크도 있다. 애플리케이션이 대상 그룹 및 ALB에 연결되어 있다면 해당 애플리케이션이 ELB에 의해 헬스 체크되는지 확인하기 위한 것이다. ELB에 대항하는 인스턴스가 건강하지 않다고 판단하면 ASG에서 해당 인스턴스를 종료한다.
-   사용자가 수동으로 또는 CLI, SDK를 사용하여 ASG에 인스턴스 health check를 자동으로 보내는 사용자 정의 헬스 체크도 있다.
-   인스턴스 헬스 체크가 실패하게 되면 인스턴스를 종료한 후에 새 인스턴스를 시작하며, Unhealthy의 인스턴스는 재부팅하지 않는다.
-   사용자 정의 헬스 체크에 사용되는 API 호출을 하는 `set-instance-health` 명령어가 있다. 사용해보기 좋을 것이다.
-   `terminate-instance-in-auto-scaling-group`와 같이 지정된 인스턴스 종료를 요청하는 명령어도 있다.

ASG의 몇 가지 일반적인 문제 해결 방법
-   이미 실행중인 인ㅇ스턴스가 있지만 새로운 EC2 인스턴스를 시작할 수 없는 경우가 있다.
-   ASG가 최대 용량 매개변수로 설정한 제한에 도달한 경우일 수 있다. 이 경우 더 많은 인스턴스를 할당하기 위해서 최대 용량을 늘려야한다.
-   또 다른 경우는 AZ에서 용량 문제가 있는 경우이다.
-   전체 중 특정 EC2를 시작하는 것이 실패하는 경우 보안 그룹이 존재하지 않는 경우일 수 있다.
-   키페어가 존재하지 않을 수 있다.
-   ASG가 24시간 동안 인스턴스를 시작하는 데 문제가 있는 경우 자동으로 디버그를 위해 ASG의 자동 스케일링 프로세스를 중지한다.

## **CloudWatch for ASG**

**ASG 수준 메트릭 (Opt-in)**
-   1분마다 수집되는 ASG 수준의 메트릭.
-   GroupMinSize: ASG 내의 최소 인스턴스 수.
-   GroupMaxSize: ASG 내의 최대 인스턴스 수.
-   GroupDesiredCapacity: ASG 내의 원하는 인스턴스 수.
-   GroupInServiceInstances: "InService" 상태의 인스턴스 수.
-   PendingInstances: "Pending" 상태의 인스턴스 수.
-   StandbyInstances: "Standby" 상태의 인스턴스 수.
-   TerminatingInstances: "Terminating" 상태의 인스턴스 수.
-   TotalInstances: ASG 내의 총 인스턴스 수.
-   참고: 이러한 메트릭에 액세스하려면 ASG 수준에서 메트릭 수집을 활성화해야 합니다.

**EC2 수준 메트릭 (기본 활성화)**

-   CPU Utilization: EC2 인스턴스의 CPU 사용량.
-   Network In/Out: 네트워크 트래픽의 데이터 전송률.
-   Disk Read/Write: 디스크 I/O 메트릭(인스턴스 스토어의 경우 해당 없음).
-   Status Checks: EC2 인스턴스의 상태 확인.
-   참고: 기본 모니터링은 5분 간격으로 메트릭을 제공하며, 상세 모니터링은 1분 간격으로 제공됩니다.

**그룹 메트릭 수집**
-   
-   ASG 설정으로 이동합니다.
-   "Enable" 버튼을 클릭하여 그룹 수준 메트릭 수집을 시작합니다.

## **Auto Scaling Overview**
-   AWS의 모든 확장 가능한 리소스에서 사용 가능하다.
-   EC2 인스턴스를 시작하거나 종료할 수 있게 해준다.
-   Spot Fleet 요청을 총해 Spot Fleet 요청 자체에서 인스턴스를 시작하거나 종료할 수 있다. 그리고 가격이나 용량 문제로 인해 중단된 인스턴스를 자동으로 교체할 수 있다.
-   ECS에도 사용되어 ECS 서비스의 원하는 수를 상향 및 하향 조정한다.
-   DynamoDB 테이블에서는 테이블이나 글로벌 보조 인덱스에 Auto Scaling을 사용해 시간에 따라 WCU(Write Capacity Units) RCU(Read Capacity Units)를 조정한다.
-   Aurora는 Dynamic Read Replica Auto Scaling을 위해 Auto Scaling을 사용한다.
-   Scaling Plans는 동적 스케일링을 포함한 여러 가지 스케일링 옵션을 제공한다.
-   동적 스케일링이 없으면 시간이 지남에 따라 동일한 용량을 유지한다. 그러나 동적 스케일링에서는 시간에 따라 용량을 조정한다. 
-   따라서 utilization을 안정화할 수 있다. 
-   또한 가용성을 최적화할 수 있으며, 이 경우 utilization의 40%를 목표로 설정할 수 있다.
-   또는 비용을 최적화할 수 있으며 이 경우 70%의 utilization을 목표로 삼는다.
-   그러나 100%에 가까워질수록 스케일링은 효율적이지 않아지고, 성능 병목 지점에 도달하게 된다.
-   자체 메트릭 또는 특정 값을 선택할 수도 있다. AWS에서는 Utilization을 권장 사항으로 제공한다.
-   동적 스케일링의 옵션으로는 scail in 비활성화가 있고, ASG의 쿨 다운 기간과 워밍업 시간 지정이 있다.
-   동적 스케일링의 대안으로는 예측 스케일링이 있다.
-   예측 스케일링은 AWS에서 제공하는 머신러닝 알고리즘을 사용해 과거 로드를 분석하고 예측을 생성한 다음 해당 예측을 기반으로 자동으로 스케줄링 작업이 수행된다.

## **[SAA/DVA] Beanstalk Overview**
배포할 애플리케이션이 많고 이러한 애플리케이션이 동일한 아키텍처를 따르는 경우 매번 재생성하는 것은 번거롭다.

개발자의 입장에서 인프라를 관리하고 코드로 배포하는 것은 복잡할 수 있다.
Beanstalk는 AWS에서 애플리케이션을 배포하는 개발자 중심의 관점을 제공한다.

아이디어는 단일 인터페이스에서 EC2, ASG, ELB, RDS와 같은 모든 구성 요소를 자동으로 배포하고 모든 구성 요소를 재사용하는 관리형 서비스이다.

Beanstalk는 아래와 같은 간단한 기능을 한다.
-   용량 프로비저닝
-   로드 밸런서의 모든 구성
-   스케일링
-   응용 프로그램 상태 모니터링
-   인스턴스 구성 등

Beanstalk를 사용하며 개발자로서 유일하게 신경써야할 부분은 코드 자체이다.

여전히 각 구성 요소의 구성에 대한 완전한 제어를 가지고 있지만 Beanstalk는 하나의 단일 인터페이스 번들로 묶여있다.

또한 Beanstalk는 애플리케이션을 업데이트하는 매우 편리한 방법도 제공한다.

Beanstalk 서비스는 그 자체로 무료이지만 ASG나 ELB에서 활용하는 기본 인스턴스에 대한 비용이 발생할 것이다.

Beanstalk의 구성 요소는 아래와 같다.
-   애플리케이션
-   애플리케이션의 버전
    -   말그대로이다. 버전 1, 버전 2, 버전 3 등이 될 수 있다.
-   환경 (Environment)
    -   환경은 특정 응용 프로그램 버전을 실행하는 리소스의 모음이다.
    -   한 번에 한 환경에서만 한 응용 프로그램 버전을 가질 수 있으며 버전 1에서 버전 2로 응용 프로그램 버전을 업데이트할 수 있다.
    -   Tier: Beanstalk에는 웹 서버 Tier, Worker Tier 두 가지가 있다.
    -   Beanstalk에서 여러 환경을 만들 수 있다. 예를들어 dev, test, prod와 같은 환경.

전체적으로 프로세스를 정리하자면
1.  응용 프로그램 생성
2.  새 버전 업로드
3.  환경 시작
4.  환경 관리

이런 순서로 구성이 되지만 환경 관리를 하는 과정에서 새 버전을 업데이트하고 새 버전을 다시 배포할 수 있다.

Beanstalk는 Go, Java SE, Java with Tomcat, .NET Core on Linux, .NET on Windows Server, Node.js, PHP, Python, Ruby, Packer Builder, Single Docker Container, Multi Docker Container, Pre-configured Docker와 같은 많은 프로그래밍 언어를 지원한다.

Beanstalk에서 Web server Tier 와 Worker Tier를 알아보자

웹 서버 티어는 로드 밸런서가 트래픽을 보내는 여러 EC2 인스턴스를 포함하는 ASG에 트래픽을 보내는 전통적인 아키텍처이다.

워커 Tier는 클라이언트가 직접 EC2 인스턴스에 액세스하지 않는다.
SQS Queue를 사용해서 메시지를 보내고 EC2 인스턴스는 메시지를 처리하기 위해 SQS Queue에서 메시지를 pull할 것이다.

이 경우 Worker 환경은 SQS 메시지 수에 따라 자동으로 스케일이 조정된다. SQS queue에 메시지가 많을수록 더 많은 EC2 인스턴스가 생성된다.

그리고 웹 서버 티어가 워커 환경의 SQS queue로 메시지를 전송해서 두 환경을 함께 사용할 수 있다는 것이다.

Beanstalk에는 두 가지 배포 모드가 있다.

첫 번째는 단일 인스턴스로, 개발 목적에 적합하다.
이 경우 Elastic IP가 있는 하나의 EC2 인스턴스가 있을 것이고, 옵션으로 RDS 데이터베이스를 시작할 수도 있다.
그리나 모든 것이 Elastic IP가 있는 인스턴스를 기반으로 한다.

개발 목적으로는 훌룡하지만 실제로 사용할 때 Elastic Beanstalk를 확장하고 싶다면 로드 밸런서를 사용해 고가용성을 확보해야한다.

고가용성을 확보하는 것은 운영 환경에 적합하고 로드 밸런서가 여러 EC2 인스턴스에 부하를 분산하고 이를 ASG로 관리하며 여러 가용 영역을 사용한다.

마지막으로 RDS 데이터베이스는 마스터와 스탠바이가 있는 멀티 AZ로 구성될 수 있다.

시험에서 알아야할 점은 만약 Beanstalk의 배포 속도가 느리다면 Golden Image를 미리 구축해두는 것이 좋다.

## **[DVA] CloudFormation - Overview **
CloudFormation은 코드만 사용해 모든 리소스에 대한 AWS 인프라를 개략적으로 설명하는 방법이다.

CloudFormation 템플릿에서는 원하는 것을 선언해 이러한 모든 것이 존재하고 서로 연결되어야 한다고 한다.
예를 들어 "나는 보안 그룹이 필요하고, 이 보안 그룹을 사용하는 두 개의 EC2 인스턴스가 필요하고 이 EC2 인스턴스 앞에 연결된 로드 밸런서가 필요하다" 는 내용을 코드로서 선언할 수 있다.

CloudFormation은 자동으로 지정한 구성과 정확한 순서로 리소스들을 생성한다.
따라서 수동으로 콘솔에서 구성하거나 수동으로 작업할 필요가 없이 모든 것이 CloudFormation을 통해 자동으로 프로비저닝 된다.

템플릿을 작성할 때 YAML이나 JSON 형식의 코드가 많아질 것이다. 

CloudFormation Designer에서는 템플릿에 작성한 이러한 리소스가 다이어그램으로 보여지는 것을 알 수 있따.

**CloudFormation을 사용해야하는 이유는 무엇일까?**
-   IaC를 위해서 (Infrastructure as Code)
    -   수동으로 생성된 리소스가 없다는 것을 의미하고 수동으로 관리하지 않아도 되어 제어에 뛰어나다.
    -   CloudFormation code를 Git과 같은 version control을 이용해서 관리할 수 있다.
    -   인프라에 대한 모든 변경은 코드 변경을 통해 검토된다.
-   비용 측면에서
    -   스택 내의 모든 리소스가 식별자로 태그가 지정되므로 CloudFormation 스택이 비용을 얼마나 사용하는지 쉽게 확인할 수 있다.
    -   또한 CloudFormation 템플릿을 사용하면 리소스 비용을 쉽게 추정할 수 있다.
    -   마지막으로 절약을 할 수 있다. 예를 들어 개발 환경에 템플릿을 오후 5:00에 자동으로 삭제하고 오후 8:00에 안전하게 다시 생성할 수 있다.
-   생산성
    -   클라우드에서 인프라를 실시간으로 파괴하고 다시 생성할 수 있다. 이는 클라우드의 전체적인 능력을 활용하는 것으로, 필요한 것만 생성하고 삭제하며 사용한 만큼만 비용을 지불하면 된다.
    -   템플릿에 대한 다이어그램을 자동으로 생성할 수 있어 아키텍처 다이어그램에 매우 유용하고, 템플릿은 선언적 프로그래밍이다. 그래서 리소스의 생성 순서나 오케스트레이션 순서를 추론할 필요가 없다.
-   분리 고려사항
    -   VPC Stack, Network Stack, App Stack 등과 같이 여러 애플리케이션 및 여러 레이어에 대한 많은 CloudFormation 스택을 만들 수 있다.
-   재사용
    -   CloudFormation을 사용하면 웹 및 문서에서 기존 템플릿을 활용해 빠르게 자신의 CloudFormation 템플릿을 작성할 수 있다.

**CloudFormation은 어떻게 작동하는가?**

먼저 템플릿을 Amazon S3에 업로드해야 하며 그런 다음 CloudFormation에서 참조해야한다.
업로드하고 나면 CloudFormation에서 참조해 스택이 생성된다.

CloudFormation 스택이란 무엇인가? 이것은 AWS 리소스로 구성되어 있으며 AWS에서 생성할 수 있는 모든 종류의 것이다.

템플릿을 업데이트하려면 이전에 생성한 것을 업데이트할 수는 없고, 새로운 버전의 템플릿을 AWS에 다시 업로드하고 스택을 업데이트해야 한다.

스택은 리전 내에서 이름으로 식별되며 CloudFormation 스택을 삭제하면 CloudFormation에 의해 생성된 모든 아티팩트와 리소스가 삭제된다.

CloudFormation 템플릿을 배포하는 방법은
-   수동 방법
    -   CloudFormation 디자이너나 코드 편집기에서 템플릿을 편집하고
    -   콘솔을 사용해 매개 변수를 입력한다.
    -   학습 목적으로 전체 프로세스를 확인하기 위해 이 방법을 사용한다.
-   자동 방법
    -   Yaml 파일로 템플릿을 편집하고
    -   CLI 또는 CD 도구를 사용해 템플릿을 배포할 수 있다.
    -   이는 플로우와 인프라를 완전히 자동화하려는 경우 권장되는 방법이다.

CloudFormation의 기본 구성 요소
-   Template
    -   AWSTemplateFormatVersion: 템플릿을 읽는 방법을 정의하는 버전이다. AWS 내부 용도로 사용한다.
    -   Description: 템플릿에 대한 주석이다.
    -   Resource(필수 요소): 템플릿에서 선언된 모든 AWS 리소스를 정의한다.
    -   Parameter: 템플릿에 동적으로 입력 값을 주는 것이다.
    -   Mappings: 템플릿의 정적 변수이며, 파라미터와는 차이점이 있다.
    -   Outputs: 템플릿에서 어떤 항목들이 생성되었는지에 대한 출력이다.
    -   Conditions: 리소스 생성을 수행하기 위한 조건



## **[DVA] YAML Crash Course**
CloudFormation에서 가장 자주 볼 것은 아마 YAML 템플릿일 것이다.

-   YAML은 JSON과 마찬가지로 키-값 쌍을 사용한다. JSON은 많은 문자 보간 등의 이유로 CloudFomation 템플릿을 작성하는 데 좋지 않고, 가독성과 쉽게 구성할 수 있는 측면에서 YAML이 매우 좋다고 생각한다.
-   YAML은 들여쓰기가 된 여러 키-값 쌍이 있다. 이것은 nested object라고 부르며 JSON 내에서는 nest object라고 한다.
-   그리고 배열을 지원한다. 하나의 오브젝트 내에서 여러개의 배열을 나타내는 마이너스 기호가 있다.
-   또한 다중 행 문자열을 지원하며 "|" 파이프 기호를 이용하면 된다.
-   "#" 을 이용해 주석을 추가할 수도 있다.

```yaml
Resources:
  MyInstance:
    Type: AWS::EC2::Instance
    Properties:
      AvailabilityZone: us-east-1a
      ImageId: ami-0a3c3a20c09d6f377
      InstanceType: t2.micro
      SecurityGroups:
        - !Ref SSHSecurityGroup
      # we install our web server with user data
      UserData: 
        Fn::Base64: |
          #!/bin/bash -xe
          dnf update -y
          dnf install -y httpd
          systemctl start httpd
          systemctl enable httpd
          echo "<h1>Hello World from user data</h1>" > /var/www/html/index.html

  # our EC2 security group
  SSHSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: SSH and HTTP
      SecurityGroupIngress:
      - CidrIp: 0.0.0.0/0
        FromPort: 22
        IpProtocol: tcp
        ToPort: 22
      - CidrIp: 0.0.0.0/0
        FromPort: 80
        IpProtocol: tcp
        ToPort: 80

```

## **[DVA] CloudFormation - Resources**

Resources는 CloudForamtion 템플릿의 핵심이며 전체 CloudFormation 템플릿에서 유일하게 필수인 섹션이다.

Resources는 템플릿의 일부로 생성 및 구성된 여러 AWS 구성 요소를 나타낸다.
Resources는 선언되고 서로 참조할 수 있으며, AWS는 자원의 생성, 업데이트 및 삭제를 우리 대신 처리해준다.

다양한 유형의 Resources가 있다. 700개 이상의 Resources 유형이 있어서 문서를 읽는 방법을 가르쳐준다.

Resources 유형 식별자는 `service-provider::service-name::data-type-name` 의 형식으로 되어 있다.

EC2의 경우 아래와 같은 형식의 yaml 파일을 갖는다.

properties의 경우 key value 쌍의 목록이다.
여러 개의 properties를 확인할 수 있으며 User guide 페이지를 확인하게 되면 여러 항목을 어떻게 사용하는 지 확인할 수 있다.

```yaml
Type: AWS::EC2::Instance
Properties:
  AdditionalInfo: String
  Affinity: String
  AvailabilityZone: String
  ~~~
```

많은 리소스에 대해 사용 가능한 많은 속성이 있다.
일반적으로 콘솔에서 지정할 수 있는 모든 것은 CloudFormation을 통해서도 지정할 수 있다.

리소스에 대해 몇 가지 자주 묻는 질문이 있다.
1.  동적 수의 리소스를 생성할 수 있을까?
    -   가능하다. Cloudformation macros와 Transform을 사용해야 하지만 이 강의의 범위에 포함되지 않는다.
2.  모든 AWS 서비스가 지원되는가?
    -   신규 서비스를 제외하고 거의 모든 서비스가 CloudFormation을 지원한다.
    -   CloudFormation Custom Resources를 사용하면 지원되지 않는 서비스를 처리할 수 있다.


## **[DVA] CloudFormation - Parameters**
Parameter는 템플릿에 인풋을 제공하는 방법이다.

CloudFormation 템플릿이 있고 사용자에게 매개 변수 값을 제공하려면 이러한 매개 변수는 CloudFormation 템플릿의 일부로 정의된다.

이전에 보안 그룹에 설명을 부여할 때 매개 변수를 이용해서 입력해주었다.

매개 변수는 여러 사람이 여러 매개 변수를 제공할 수 있도록 템플릿을 여러 곳에서 재사용하려면 알아야 할 중요한 내용이다.

인풋은 미리 결정할 수 없으므로 매개 변수는 강력하게 제어되고 type으로 인해 템플릿에서 오류가 발생하는 것을 방지할 수 있다.

예를들어 SecurityGroupDescription 매개 변수를 설정해서 보안 그룹의 설명을 설정할 수 있다.

우리는 다음과 같은 질문을 해봐야한다.

이 CloudFormation 리소스 config는 미래에 변경될 가능성이 있는가?
이러한 경우 매개 변수로 만드는 것이 좋다.
왜냐면 해당 값을 업데이트하려면 매개 변수만 수정하면 되고 템플릿을 다시 업로드 할 필요가 없기 때문이다.

또한 미리 결정할 수 없다면 매개 변수로 만들어야 한다.

매개 변수에는 여러 설정이 있으며 첫 번째는 유형이다.
String, Number, CommaDelimitedList, List, AWS-Specific Parameter, SSM Parameter 등이 있다.

또 Description, ConstraintDescription(제약 조건), Min/MaxLength, Min/MaxValue, Default, AllowedValues(array), AllowedPattern(regex), NoEcho(Boolean) 등등이 있다.

모든 것을 기억할 필요는 없지만 매개 변수는 단순한 문자열이 아니다.

파라미터는 제약 조건과 유효성 검사를 가질 수 있어서 안전하게 사용할 수 있도록 할 수 있다.

중요한 예시 두 가지를 소개하겠다.

첫번째는 AllowedValues 이다.
여기에는 InstanceType이라는 매개 변수가 있다.

Type: String인 EC2 InstanceType을 선택할 수 있다.

```yaml
AllowedValues:
    - t2.micro
    - t2.small
    - t2.medium
Default: t2.micro
```

이런 형태로 있을 때 이 매개변수는 세 가지 값 중 하나만 선택할 수 있으며 선택권이 주어지지만 제어가 된다.
기본 값이 t2.micro로 설정 되어 있기 때문에 기본적으로 t2.micro가 선택된다.


또한 NoEcho 매개변수가 있다.

예를 들어 매개 변수로 데이터베이스 암호를 입력하려고 하지만 물론 이것은 암호이므로 비밀로 유지해야한다.

따라서 패스워드가 어디에서도 표시되지 않도록 NoEcho: true로 설정해 로그에서 제거한다.

매개 변수를 어떻게 사용하는지 살펴보자

!Ref 함수를 사용하면 매개 변수를 참조하고 템플릿으 ㅣ어디에서나 사용할 수 있다.

Fn::Ref 를 사용할 수도 있지만 !Ref라는 약식 버전이 있다.

이 함수는 매개 변수를 참조하는 것뿐만 아니라 템플릿 내의 다른 요소를 참조하는데 사용할 수 있다.

예를들어 SecurityGroupDescription이라는 매개변수에 Description과 Type: String 을 설정하고 제약 조건이 없다고 가정해보자

!Ref SecurityGroupDecription을 하게 되면 SecurityGroupDecription에 설정되어 있는 설명이 String의 형태로 참조되게 된다.


이것이 !Ref 함수의 사용 방법이고 CloudFormation 템플릿 내에서 매개 변수를 참조하는 방법이다.

!Ref 함수는 다른 위치에서도 사용된다.
꼭 파라미터를 불러오는 것이 아니라 이미 설정 되어 있는 SecurityGroup의 리소스의 리스트를 그대로 다른 SecurityGroup에서 참조하게 할 수도 있다.

따라서 매개 변수를 참조하는 데 동일한 방식이 사용되므로 리소스가 매개 변수와 동일한 이름을 가지지 않도록 주의해야 한다.

Pseudo Parameter가 있다.

AWS는 모든 CloudFormation 템플릿에서 Pseudo Parameter를 제공하고 있다.

이러한 것들은 생성하지 않았더라도 존재하며 언제든지 사용할 수 있으며 기본적으로 활성화되어 있다.

예를들어 아래와 같은 Pseudo Parameter가 있다.

-   AWS::AccountId
    -   실제 계정 ID를 자동으로 확인할 수 있다.
-   AWS::Region
    -   템플릿이 위치한 리전 값
-   AWS::StackId
    -   스택 ID
-   AWS::StackName
    -   스택 이름
-   AWS::NotificationARNs
    -   알람 ARN 값
-   AWS::NoValue
    -   아무 값도 리턴하지 않는 것


## **[DVA] CloudFormation - Mappings**

매칭은 클라우드포메이션 템플릿 내에서 고정된 변수이며, 다른 환경 간ㅇ ㅔ차이를 두고 싶을 때 매우 편리하다.

예를 들어 dev, prod와 같이 다른 값을 제공하거나  AWS 지역이나 AMI 유형과 같은 Region에 따라 다른 값을 제공하고 싶을 때 유용하다.

```yaml
Mappings: 
  RegionMap: 
    us-east-1: 
      "HVM64": "ami-0ff8a91507f77f867"
    us-west-1: 
      "HVM64": "ami-0bdb828fd58c52235"
    eu-west-1: 
      "HVM64": "ami-047bb4163c506cd98"
    ap-southeast-1: 
      "HVM64": "ami-08569b978cc4dfa10"
    ap-northeast-1: 
      "HVM64": "ami-06cd52961ce9f0d85"
```

위와 같이 각 Region에 따라 다른 AMI를 얻을 수 있다.

매핑 값에 액세스하려면 FindInMap 함수를 사용할 수 있다.
`Fn::FindInMap: [ MapName, TopLevelKey, SecondLevelKey ]`
`!FindInMap [ MapName, TopLevelKey, SecondLevelKey ]`

언제 매핑을 사용하는 것이 좋고 언제 매개 변수를 사용하는 것이 좋을까? 
**매핑은 미리 모든 값을 알고 있고 지역, 가용 영역, AWS 계정, 환경(Dev, Prod)과 같은 변수에서 유도할 수 있는 경우에 좋다.**

이러한 템플릿에 대해 더 안전한 제어를 제공한다.

그러나 사용자가 원하는 값이 실행 시점에 어떤 것이며 사용자에게 최대한의 자유를 제공하려면 매개 변수를 사용해야 한다.



## **[DVA] CloudFormation - Outputs & Exports**

Outputs는 선택 사항이며 선택적인 output 값을 선언한다.

이러한 값을 선언하면 다른 스택에서 output 값을 가져올 수 있다.

예를들어 네트워크 스택을 생성하고 내보낸 output이 있는 경우 해당 내보낸 output 값을 다른 애플리케이션 스택에서 참조할 수 있다.

콘솔이나 AWS CLI를 사용해서 output의 값을 볼 수 있다.

따라서 네트워크 스택을 정의하고 VPC ID, Subnet ID를 출력하여 다른 방식으로 재사용하는 경우에 출력이 매우 유용하다.

이렇게 하면 스택 간의 협업을 수행하고 자체 스택을 처리하고 협업할 수 있다.

```yaml
Outputs:
  PublicSubnet:
    Description: The subnet ID to use for public web servers
    Value:
      Ref: PublicSubnet
    Export:
      Name:
        'Fn::Sub': '${AWS::StackName}-SubnetID'
  WebServerSecurityGroup:
    Description: The security group ID to use for public web servers
    Value:
      'Fn::GetAtt':
        - WebServerSecurityGroup
        - GroupId
    Export:
      Name:
        'Fn::Sub': '${AWS::StackName}-SecurityGroupID'
```

위 코드에서는 Output이 있다. 

```yaml
Resources:
  WebServerInstance:
    Type: 'AWS::EC2::Instance'
    Properties:
      InstanceType: t2.micro
      ImageId: ami-a1b23456
      NetworkInterfaces:
        - GroupSet:
            - Fn::ImportValue: 
              'Fn::Sub': '${NetworkStackNameParameter}-SecurityGroupID'
          AssociatePublicIpAddress: 'true'
          DeviceIndex: '0'
          DeleteOnTermination: 'true'
          SubnetId: Fn::ImportValue: 
            'Fn::Sub': '${NetworkStackNameParameter}-SubnetID'
```

Fn::ImportValue 함수를 이용하면 다른 스택에서 내보낸 값을 가져올 수 있다.

두 개의 다른 CloudFormation 템플릿을 연결할 수 있는데, 연결된 상황에서 첫 번째 스택이 내보낸 값을 더 이상 참조하지 않을 때까지 첫 번째 스택을 삭제할 수 없다. **증요**


## **[DVA] CloudFormation - Conditions**

Condition은 특정 조건에 기반하여 리소스 또는 output의 생성을 제어하는 데 사용된다.

예를 들어 개발 환경에서만 생성되어야하는 몇 가지 항목이 있을 수 있다. dev 또는 prod 스택 처럼 특정 환경에서만 생성되어야 하는 항목이 예다.
예를 들어 차이점을 두어 하나는 EBS 볼륨을 가지고 있고 다른 하나는 그렇지 않은 경우이다.

따라서 조건을 원하는 대로 만들 수 있다.

그러나 일반적으로는 개발, 테스트 및 프로덕션과 같은 환경에 따라 조건을 만드는 것이 흔하다. 또는 Region 또는 매개변수 값에 따라 조건을 만들수도 있다.

각 Condition은 서로를 참조하고 매개변수 값이나 매핑을 참조할 수 있다.

```yaml
AWSTemplateFormatVersion: '2010-09-09'
Description: CloudFormation Condition 예제
Parameters:
  EnableFeature:
    Type: String
    AllowedValues: ['true', 'false']
    Description: 특정 기능을 활성화할지 여부를 선택합니다.
Conditions:
  EnableFeatureCondition: !Equals [!Ref EnableFeature, 'true']
Resources:
  MyBucket:
    Type: AWS::S3::Bucket
    Condition: EnableFeatureCondition
    Properties:
      BucketName: MyEnabledBucket
Outputs:
  OutputMessage:
    Description: |
      조건에 따라 S3 버킷이 생성되었습니다.
    Value: !If
      - EnableFeatureCondition
      - "Enabled 기능이 활성화되었습니다."
      - "Enabled 기능이 비활성화되었습니다."
```

예를 들어 위에서는 EnableFeatureCondition 이라는 조건 값을 정의하고 여기에서 Equal을 이용해 EnableFeature의 파라미터와 동일한 값인지 확인한다.

EnableFeature의 파라미터와 동일하다면 true가 된다.

조건을 만들려면 And, Equals, If, Not, Or과 같은 모든 함수를 사용할 수 있고 이런 방식으로 조건을 만들 수 있다.

조건을 리소스에 적용하지만 출력 등에도 적용할 수 있다.

시험에서는 Conditions를 작성하는 방법을 알 필요는 없다. 조건이 존재한다는 것을 알기만 하면 된다.

## **[DVA] CloudFormation - Intrinsic Functions**

Intrinsic Funtions(내장 함수)는 무조건 알아야 할 것이 있다.

-   **must know**
    -   Ref
    -   Fn::GetAtt
    -   Fn::FindInMap
    -   Fn::ImportValue
    -   Condition Functions(Fn::If, Fn::Not, Fn::Equals etc...)
-   일반
    -   Fn::Join
    -   Fn::Sub
    -   Fn::ForEach
    -   Fn::ToJsonString

이러한 함수들은 CloudFormation 문서에서 확인 가능하다.

**Ref 함수**는 매개변수에 대한 값 또는 생성된 기본 리소스(EC2 인스턴스 등)의 물리적 ID를 반환하는 데 사용될 수 있다.

느낌표와 함께 항상 축약하여 사용된다. !Ref

**GetAtt 함수**는 템플릿에서 생성한 모든 리소스에 연결된다. 이 함수는 속성을 가져오는 데 사용된다.

```yaml
AWSTemplateFormatVersion: 2010-09-09
Resources:
  myELB:
    Type: AWS::ElasticLoadBalancing::LoadBalancer
    Properties:
      AvailabilityZones:
        - eu-west-1a
      Listeners:
        - LoadBalancerPort: '80'
          InstancePort: '80'
          Protocol: HTTP
  myELBIngressGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: ELB ingress group
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          SourceSecurityGroupOwnerId: !GetAtt myELB.SourceSecurityGroup.OwnerAlias
          SourceSecurityGroupName: !GetAtt myELB.SourceSecurityGroup.GroupName
```

예제 코드에서 볼 수 있듯이 myELB에 !GetAtt 함수를 이용해서 myELB.SourceSecurityGroup.OwnerAlias 해당 속성 값을 가져오게 된다.

예를 들어 "EC2Instance" EC2 인스턴스를 생성하고 "EC2Instance"라는 이름의 인스턴스에서 가용 영역을 가져오려면 `!GetAtt EC2Instance.AvailabilityZone`을 사용하면 속성을 가져올 수 있다.

FindInMap 함수는 특정 맵에서 특정 키의 값을 가져오는 데 사용된다. 주로 매필을 사용할 때 사용된다.

ImportValue 함수는 다른 스택에서 내보낸 값을 가져오는 데 사용된다.

Base64 함수는 문자열을 Base64 표현으로 변환하는 데 사용된다. 주로 EC2 인스턴스의 Userdata에 데이터를 전달할 때 사용된다.

이런 식으로 내장 함수들은 템플릿 내에서 동적이고 유연한 작업을 수행하는 데 중요한 도구이다.

## **[DVA] CloudFormation - Rollbacks**
**Stack failure options**
스택을 생성하고 스택 생성이 실패하면 두 가지 옵션이 있다.

첫 번째는 기본 옵션으로 모든 것이 롤백되어 삭제된다.

CloudFormation 생성 로그를 확인하여 실패 이유를 이해할 수 있지만 리소스를 확인할 수는 없다.

두번째는 리소스 중 하나에 문제가 있고 나머지는 유지하고 싶다면 롤백을 비활성화하여 스택 생성 중에 무엇이 발생했는지 문제 해결할 수 있다. (Preserve successfully provisioned resources)

스택 업데이트의 문제인 경우 기본적으로 스택은 자동으로 마지막으로 알려진 작동 중인 상태로 롤백된다. 다시 말해 새롭게 업데이트로 생성된 모든 리소스들이 삭제된다.
생성된 모든 것이 삭제되었을 때 로그를 확인해 오류 메시지를 확인할 수 있다.

롤백 실패의 경우 스택 업데이트 중 롤백이 실패한 경우이다. 이는 스택에 문제가 있으며 수동으로 변경된 리소스가 있을 가능성이 높다. 이 경우 수동으로 리소스를 수정해야 한다.
그 다음 콘솔이나 API를 통해 ContinueUpdateRollback을 호출해 CloudFormation에 다시 롤백을 시도하라고 알릴 수 있다.

디폴트인 상태에서 실패하면 모든 것이 삭제되지만 Preserve successfully provisioned resources로 설정하게되면 일부가 남아있기 때문에 필요에 따라 문제를 해결할 수 있다. 허나 삭제되지 않은 잔여물을 제거하려면 스택을 삭제해야 한다.

## **[DVA] CloudFormation - Service Role**

CloudFormation은 서비스 역할을 사용할 수 있다. 서비스 역할은 CloudFormation 전용으로 만든 IAM 역할로, CloudFormation이 실제로 나를 대신해 스택 리소스를 생성, 업데이트 및 삭제할 수 있게 한다.

따라서 사용자에게 리소스와 직접 작업할 수 있는 권한이 없지만 스택 리소스를 생성, 업데이트 및 삭제할 수 있는 능력을 부여하려면 서비스 역할을 사용한다.

예를 들어 사용자는 템플릿을 생성 가능한 cloudformation에 대한 모든 권한과 PassRole이 있다.
CloudFormation에 할당할 Service Role을 생성하고, 해당 역할은 버킷을 생성, 업데이트 및 삭제할 수 있는 권한을 갖게되면

사용자가 CloudFormation에 PassRole을 이용해서 역할을 전달할 수 있기 때문에 CloudFormation은 이 서비스 역할을 사용해 S3 버킷을 생성할 수 있다.

보안을 위한 사용 사례로는 최소 권한 원칙을 실현하고 사용자에게 스택 리소스를 생성할 수 있는 모든 권한을 부여하지 않고 CloudFormation에서 서비스 역할을 호출할 수 있는 권한만 부여하려는 경우가 있다. 이를 위해 사용자는 iam:PassRole이라는 권한을 가지고 있어야 한다.

## **[DVA] CloudFormation - Capabilities**

**CAPABILITY_NAMED_IAM**과 **CAPABILITY_IAM**이 있다.

이것은 CloudFormation 템플릿이 IAM 리소스를 생성하거나 업데이트할 때 CloudFormation에 부여해야 하는 기능이다.

예를 들어 IAM 사용자, 역할, 그룹, 정책 등을 CloudFormation 템플릿을 통해 생성할 때이다.

리소스에 사용자가 부여한 이름이 지정된 경우 CAPABILITY_NAMED_IAM을 지정하고 그렇지 않으면 단순히 CAPABILITY_IAM을 사용한다.

이렇게 하는 이유는 CloudFormation이 IAM 리소스를 생성할 것임을 명시적으로 인식하려는 것이다. 

**CAPABILITY_AUTO_EXPAND**도 있다.

이는 CloudFormation 템플릿이 매크로와 Nested 스택(스택 내의 스택)을 포함할 때 사용된다.
템플릿이 배포되기 전에 변경될 수 있다는 사실을 명시적으로 인식하고 있다.

결과적으로 CAPABILITY_NAMED_IAM, CAPABILITY_IAM, CAPABILITY_AUTO_EXPAND 는 위 상황에 맞게끔 필수적으로 넣어줘야 하는 매개변수 같은 걸로 이해하면 된다. 없으면 스택 생성하거나 업데이트할 때 충돌이 발생함!

InsufficientCapabilitiesException는 템플릿을 시작할 때 CloudFormation 템플릿이 Capabilities를 요청했지만 사용자가 이를 인증하지 않았다는 것을 의미한다. 
결국 템플릿을 다시 만들고, 업로드하고, Capabilities를 꼭 넣어줘야 한다.

이 capability들은 CLI나 SDK를 사용할 경우 API 호출의 추가 매개변수이고, AWS 콘솔에서는 선택하는 체크박스로 나타난다.

## **[DVA] CloudFormation - Deletion Policy**

Deletion Policy는 템플릿에서 리소스에 적용할 수 있는 설정으로 리소스가 CloudForamtion 템플릿에서 제거되거나 CloudFormation 스택이 삭제될 때 리소스에 대해 어떤 작업을 수행할지를 제어할 수 있게 해준다.

리소스를 보존하고 백업하는 방법으로 사용된다.

기본적으로 CloudFormation 템플릿을 삭제하면 내부의 모든 리소스가 삭제된다. 이는 기본적으로 DeletionPolicy가 delete로 설정되어 있어서이다.

템플릿 내에 S3가 있을 경우 S3는 제외이다. S3는 버킷이 비어있을 경우에만 DeletionPolicy가 작동된다.

DeletionPolicy: Retain는 템플릿에서 보존하려는 리소스를 지정하는 것이다.

DeletionPolicy: Snapshot이 있다. 이는 리소스를 삭제하기 전에 마지막 스냅샷을 생성하는 것이다. 
EBS 볼륨, ElastiCache 클러스터, ElastiCache ReplicationGroup, RDS DBInstance, DB 클러스터, Redshift, Neptune, DocumentDB 등에서 지원된다.

백업 및 안전성 목적으로 매우 유용하다.

```yaml
# Does not exist DeletionPolicy
Resources:
  SGroup1:
    Type: 'AWS::EC2::SecurityGroup'
    Properties:
      GroupDescription: EC2 Instance access

# Retain
AWSTemplateFormatVersion: '2010-09-09'
Resources:
  myS3Bucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Retain

# Snapshot
AWSTemplateFormatVersion: '2010-09-09'
Resources:
  myvol:
    Type: AWS::EC2::Volume
    DeletionPolicy: Snapshot
```

**정리**
-   DeletionPolicy는 템플릿에서 리소스에 적용할 수 있는 설정으로 템플릿을 삭제할 때 리소스를 보존하고 백업하는 방법으로 사용된다.
-   기본적으로는 템플릿을 삭제하면 내부의 모든 리소스가 삭제 되지만 DeletionPolicy를 설정해주면 삭제되지 않는다.
-   옵션은 아래와 같다.
    -   DeletionPolicy: 없음
        -   DeletionPolicy가 Resource에 따로 지정되어 있지 않다면 리소스를 삭제한다는 이야기이다.
    -   DeletionPolicy: Retain
        -   Retain으로 지정하는 경우 리소스를 보존한다는 의미다.
    -   DeletionPolicy: Snapshot
        -   EBS 볼륨, ElastiCache 클러스터, ElastiCache ReplicationGroup, RDS DBInstance, DB 클러스터, Redshift, Neptune, DocumentDB 의 경우 Snapshot 옵션을 지원한다.
        -   Snapshot의 경우 리소스를 삭제하기 이전에 마지막으로 스냅샷을 생성하고 리소스를 삭제한다.

## **[DVA] CloudFormation - Stack Policy**

기본적으로 CloudFormation 스택을 업데이트할 때 모든 리소스에 대해 모든 작업이 허용된다.

그래서 스택을 원하는대로 변경할 수 있지만 때로는 전체 스택 또는 일부 스택을 업데이트로부터 보호하고 싶을 수도 있다.

스택 정책은 JSON 문서로 스택 업데이트 중에 특정 리소스에서 허용되는 업데이트 작업을 정의한다.

```json
{
  "Statement" : [
  {
    "Effect" : "Allow",
    "Principal" : "*",
    "Action" : "Update:*",
    "Resource" : "*",
  }
  ]
}
```

위와 같은 형식의 JSON 문서로 구성되며 Effect가 Allow라면 모든 것에 대한 업데이트를 허용한다는 이야기이다.

스택 정책은 의도하지 않은 업데이트로부터 리소스를 보호하는 것이며, 스택 정책을 설정하면 기본적으로 모든 리소스가 보호된다.
업데이트를 허용하려는 리소스에 대해 명시적으로 "Allow"가 필요하다


## **[DVA] CloudFormation - Termination Protection**

스택이 실수로 삭제되는 것을 방지하려면 Termination Protection을 사용해야한다.

Termination Protection이 활성화되어 있으면 먼저 Termination Protection을 비활성화해야 스택을 삭제할수 있다고 출력이 될 것이다.

## **[DVA] CloudFormation - Custom Resources**

CloudFormation에서 지원하지 않거나 CloudFormation 외부에서 사용자 정의 프로비저닝 로직을 정의하려면 사용자 정의 리소스가 필요하다.

예를들면 온프레미스 리소스나 Third-party 리소스, 또는 CloudFormation 스택의 생성, 업데이트 및 삭제 단계에서 Lambda 함수를 통해 사용자 지정 스크립트를 실행하려는 경우이다.

예를들어 Lambda 함수를 실행해 S3 버킷을 삭제하기 전에 비우는 스크립트를 설정할 수 있다. (시험에 자주 등장하는 케이스의 문제)

사용자 정의 리소스를 정의하려면 템플릿에서 정의하면 되고, AWS::CloudFormation::CustomResource 또는 Custom::MyCustomResourceTypeName(추천) 로 정의하면 된다.

```yaml
Resources:
  MyCustomResourceUsingLambda:
    Type: Custom::MyCustomResourceTypeName
    properties:
      ServiceToken: arn:aws:lambda:REGION:ACCOUNT_ID:function:RUNCTION_NAME
      ExampleProperty: "ExampleValue"
```

위 예제에서 볼 수 있듯이 Type 항목을 Custom::MyCustomResourceTypeName 로 지정했다. 예를 들어 Custom::MyLambdaResource 로 지정할수도 있다.

ServiceToken은 Lamgda 함수의 ARN이나 SNS의 ARN을 기입하면 된다.

사용 사례는 S3 버킷에서 오브젝트를 삭제하는 게 있다.
왜냐하면 비어 있지 않은 S3는 CloudFormation에서 삭제할 수 없기 때문이다.

그래서 보통 유저가 delete stack을 할 때 Custom resource로 S3 버킷을 비우는 람다 함수를 생성해 사용한다.

## **[DVA] CloudFormation - Dynamic References**

System Manager Parameter store에 값을 저장하거나 Secrets Manager에 시크릿을 저장할 수 있다.
이 값을 CloudFormation 템플릿에 참조할 수 있다. 템플릿 생성, 업데이트 또는 삭제 작업 중에 CloudFormation이 지정된 참조의 값을 검색한다는 개념

예를 들어 Secrets Manager에서 RDS 데이터베이스 인스턴스의 마스터 암호를 검색하려고 할 수 있다.

CloudFormation을 이용하면 3가지 유형의 키를 사용해 Parameter Store 또는 Secrets Manager에서 값을 가져올 수 있다.

1.  Systems Manager Parameter Store에 저장된 평문 값을 나타내는 ssm
2.  Systems Manager Parameter Store에 저장된 보안 문자열을 나타내는 ssm-secure
3.  그리고 Secrets Manager 서비스에 저장된 비밀 값을 나타내는 secretsmanager

{{resolve:service-name:reference-key}} 아래와 같은 형태로 값을 불러올 수 있고 ssm 의 경우 {{resolve:ssm:parameter-name:version}}이다.

```yaml
  MyRDSInstance:
    Type: 'AWS::RDS::DBInstance'
    Properties:
      DBName: MyRDSInstance
      AllocatedStorage: '20'
      DBInstanceClass: db.t2.micro
      Engine: mysql
      MasterUsername: '{{resolve:secretsmanager:MyRDSSecret:SecretString:username}}'
      MasterUserPassword: '{{resolve:secretsmanager:MyRDSSecret:SecretString:password}}'
```

위 예문에서는 secretsmanager에 있는 사용자 이름과 암호를 동적 참조를 사용해 불러온다.

AWS::RDS::DBCluster 예를 들어 aurora를 생성하는 스택을 만들면 ManageMasterUserPassword가 True로 설정되어 Secrets Manager에 마스터 사용자의 비밀번호가 암시적으로 생성된다. 
즉, RDS 서비스 자체가 Secrets Manager에 마스터 사용자 비밀번호 및 rotation을 관리하기 위한 비밀을 생성한다.

```yaml
Resources:
  MyCluster:
    Type: AWS::RDS::DBCluster
    Properties:
      Engine: aurora-mysql
      MasterUsername: masteruser
      ManageMasterUserPassword: true

Outputs:
  Secret:
    Value: !GetAtt Mycluster.MasterUserSecret.SecretArn
```

그래서 Secrets의 ARN을 가져오기 위해서는 Output에서 !GetAtt Mycluster.MasterUserSecret.SecretArn 등을 사용해 Secret을 가져와야한다.

다른 방법은 동적 참조를 이용하는 방법이다.

```yaml
Resources:
  MyDatabaseSecret:
    Type: AWS::SecretsManager::Secret
    properties:
      Name: MyDatabaseSecret
      GenerateSecretString:
        SecretStringTemplate: '{"username": "admin"}'
        GenerateStringKey: "password"
        PasswordLength: 16
        ExcludeCharacters: '"@/\'
```

이번에는 !GetAtt 로 가져오는 것이 아니라 비밀번호를 직접 생성하는 GenerateSecretString을 사용한다.
CloudFormation 내에서 자동으로 비밀번호를 생성한다.

```yaml
MyDBInstance:
  Type: AWS::RDS::DBInstance
  Properties:
    DBName: mydatabase
    AllocatedStorage: 20
    DBInstanceClass: db.t2.micro
    Engine: mysql
    MasterUsername: '{{resolve:secretsmanager:MyDatabaseSecret:SecretString:username}}'
    MasterUserPassword: '{{resolve:secretsmanager:MyDatabaseSecret:SecretString:password}}'
```

그 다음으로는 DB 인스턴스가 있는데, 이 데이터베이스 인스턴스는 resolve 함수를 활용해 RDS 데이터베이스 인스턴스에서 비밀을 참조할 것이다. (실제로 값은 Secrets Manager에 저장)
즉, 데이터베이스 인스턴스가 Secrets Manager에서 시크릿을 활용하게 된다.

```yaml
SecretRDSAttachment:
  Type: AWS::SecretsManager::SecretTargetAttachment
  properties:
    SecretId: !Ref MyDatabaseSecret
    TargetId: !Ref MyDBInstance
    TargetType: AWS::RDS::DBInstance
```

마지막으로 위 두 가지를 서로 연결하고 비밀번호 Rotation이 있는지 확인하기 위해 SecretTargetAttachement를 만들어 데이터베이스에 Secrets Manager에서 이 Secret에 연결해야 한다는 것을 알려주면 시간이 지나면 Secret이 Rotate되고 RDS 데이터베이스가 자동으로 업데이트될 수 있다.

## **CloudFormation - User Data**

CloudFormation을 이용해서 EC2 인스턴스에 User Data를 전달할 수 있다.

User data는 EC2 인스턴스 시작을 위한 스크립트로 사용될 수 있으며, 콘솔로 설정할 수도 있지만 CloudFormation 템플릿을 통해 동일한 작업을 수행할 수도 있다.

중요한 것은 스크립트 전체를 Base64라는 함수를 통해 전달하는 것이다.

User data 스크립트는 /var/log/cloud-init-output.log 라는 파일에도 저장된다.
이 파일을 통해 어떤 일이 발생했는지 어떤 문제가 있었는지 확인 가능하다.

```yaml
    Properties:
        UserData: 
            Fn::Base64: |
            #!/bin/bash -xe
            dnf update -y
            dnf install -y httpd
            systemctl start httpd
            systemctl enable httpd
            echo "<h1>Hello World from user data</h1>" > /var/www/html/index.html
```

위와 같은 userdata를 사용하는 웹 서버를 시작한다고 가정해보자
Fn::Base64: | 에서 파이프 기호("|")는 이 전체 스크립트를 사용자 데이터로 전달한다는 것을 의미한다.

인스턴스가 실행되고 userdata및 결과를 확인하려면 /var/log/cloud-init-output.log 파일을 확인해 clouds-init의 로그를 확인하면 명령과 결과를 확인할 수 있다.

**정리**
-   콘솔에서 인스턴스를 생성할 때 Userdata를 작성하듯이 CloudFormation에서 UserData를 작성할 수 있다.
-   UserData는 EC2 인스턴스를 정의하는 템플릿에서 Properties 밑에 작성해야 하며, 꼭 Base64 함수를 이용해 인코딩 후 전달해야 한다.
-   스크립트는 실행된 EC2 인스턴스 내에 /var/log/cloud-init-output.log 파일에도 저장되고 파일을 확인하면 전체 로그가 남아 있다.
-   파이프 기호("|")는 전체 스크립트를 사용자 데이터로 다중 문자열로 전달한다는 것을 의미한다.

## **CloudFormation - cfn-init**

Userdata는 몇 가지 문제가 있다.

인스턴스 구성이 매우 커서 스크립트가 많아지는 경우는 어떻게 해야 하는가? 그리고 Userdata는 인스턴스 첫 시작에만 적용되어 EC2 인스턴스를 종료하고 새로 만들지 않고도 어떻게 userdata를 실행할 수 있을까? userdata를 더 읽기 쉽게 만들려면 어떻게 해야하며 userdata 스크립트가 성공했는지 여부를 어떻게 알수 있을까?

CloudFormation helper scripts를 사용하면 된다.

script는 Python 스크립트이고 Amazon Linux AMI와 함께 제공되거나 yum이나 dnf를 사용해 설치할 수 있다.

그 중에서도 cfn-init, cfn-signal, cfn-get-metadata, cfn-hup 네 가지 중요한 스크립트가 있다.

CloudFormation init 은 리소스 내에서 메타데이터 블록에 속하는 config 블록으로 여러 구성 요소로 되어 있다.

```yaml
Resources:
  MyInstance:
    Type: AWS::EC2::Instance
    Properties:
      AvailabilityZone: us-east-1a
      ImageId: ami-0a3c3a20c09d6f377
      InstanceType: t2.micro
      SecurityGroups:
        - !Ref SSHSecurityGroup
      # we install our web server with user data
      UserData: 
        Fn::Base64:
          !Sub |
            #!/bin/bash -xe
            # Get the latest CloudFormation package
            dnf update -y aws-cfn-bootstrap
            # Start cfn-init
            /opt/aws/bin/cfn-init -s ${AWS::StackId} -r MyInstance --region ${AWS::Region} || error_exit 'Failed to run cfn-init'
    Metadata:
      Comment: Install a simple Apache HTTP page
      AWS::CloudFormation::Init:
        config:
          packages:
            yum:
              httpd: []
          files:
            "/var/www/html/index.html":
              content: |
                <h1>Hello World from EC2 instance!</h1>
                <p>This was created using cfn-init</p>
              mode: '000644'
          commands:
            hello:
              command: "echo 'hello world'"
          services:
            sysvinit:
              httpd:
                enabled: 'true'
                ensureRunning: 'true'
```

packages는 MySQL, PHP 등과 같은 미리 패키지화된 앱 및 구성 요소를 다운로드하고 설치하는 데 사용된다.

파일을 다운로드하고 EC2 인스턴스에 배치하는 데 사용되는 sources:
EC2 인스턴스에 파일을 생성하는 데 사용되는 files:
일련의명령을 실행하는 데 사용되는 commands:
서비스를 시작하는 데 사용되는 services가 있다.

cfn-init 스크립트를 사용하면 복잡한 EC2 구성을 읽기 쉽게 만들 수 있다. 
작동 과정은 EC2 인스턴스는 init 데이터를 얻기 위해 CloudFormation 서비스에 쿼리를 날리고, CloudFormation은 EC2 인스턴스를 시작하고 인스턴스는 cfn-init 스크립트를 실행하며 init 데이터를 CloudFormation에서 직접 검색한다.

CloudFormation init 블록을 리소스의 메타데이터에 정의해야한다.

이러한 작업에 대한 모든 로그는 /var/log/cfn-init.log 파일에 기록된다.

예제 UserData에 `/opt/aws/bin/cfn-init -s ${AWS::StackId} -r MyInstance --region ${AWS::Region}` 명령어가 있는데 -s 인수로 StackId를 전달하고 -r 인수로 어떤 리소스에 메타데이터가 첨부되어 있는지를 찾을지 정해주는 것이다.

**정리**
-   일반적으로 Userdata를 작성하는 데에는 문제가 있을 수 있다.
    -   인스턴스 구성이 커서 스크립트가 많아지는 경우
    -   Userdata는 인스턴스 첫 시작에만 적용 돼 Userdata를 다시 적용하려면 인스턴스를 종료하고 새로 만들어야 함
    -   UserData를 더 읽기 쉽게 만들려면 어떻게 해야하는가?
    -   UserData 스크립트 성공 여부를 어떻게 알 수 있을까?
-   위와 같은 문제가 있어서 CloudFormation helper scripts를 사용한다. script는 Python 스크립트이고 Amazon Linux AMI와 함께 제공되거나 yum이나 dnf를 사용해 설치 가능하다. cfn-init은 그 중 하나의 중요한 스크립트이다.
-   cfn-init은 Resources 내에서 Metadata 블록에 속하는 Config 블록으로 여러 구성 요소로 되어 있다.
    -   packages는 MySQL, PHP 등과 같이 미리 패키지화 된 앱 및 구성 요소를 다운로드하고 설치하는 데 사용된다.
    -   sources는 파일을 다운로드하고 EC2 인스턴스에 배치하는데 사용된다.
    -   files는 EC2 인스턴스에 파일을 생성하는데 사용된다.
    -   commands는 일련의 명령을 실행하는 데 사용된다.
    -   services는 서비스를 시작하는데 사용된다.
-   cfn-init 스크립트를 사용하면 EC2 구성을 읽기 쉽게 만들 수 있다.
-   작동 과정은 이렇다. 
    EC2 인스턴스는 init 데이터를 얻기위해 ClouFormation 서비스에 쿼리 전송 -> CloudFormation은 EC2 인스턴스를 시작하고 인스턴스는 cfn-init 스크립트 실행 -> init 데이터를 CloudFormation에서 직접 검색



## **CloudFormation - cfn-signal & Wait Condition**

EC2 인스턴스를 cfn-init 스크립트를 실행한 후 올바르게 구성되었는지 여부를 알 수 있는 방법에 대해 이야기 해보자

이를 위해서 cfn-signal 스크립트를 사용한다.

일반적으로 cfn-init 스크립트 바로 다음에 cfn-signal 스크립트를 실행한다.

그리고 이 스크립트는 리소스 생성이 성공했는지 실패했는지 CloudFormation에 알려줄 것이다.

이를 위해 우리는 CloudFormation에서 WaitCondition이라고 불리는 것을 정의해야한다.

WaitCondition은 이름에서 알 수 있듯이 템플릿이 cfn-signal로부터 신호를 받을때까지 기다린다.

```yaml
# 성공 스크립트
UserData: 
        Fn::Base64:
          !Sub |
            #!/bin/bash -x
            # Get the latest CloudFormation package
            dnf update -y aws-cfn-bootstrap
            # Initialize EC2 Instance
            /opt/aws/bin/cfn-init -v --stack ${AWS::StackName} --resource MyInstance --region ${AWS::Region}
            # Get result of last command
            INIT_STATUS=$?
            # send result back using cfn-signal
            /opt/aws/bin/cfn-signal -e $INIT_STATUS --stack ${AWS::StackName} --resource SampleWaitCondition --region ${AWS::Region}
            # exit the script
            exit $INIT_STATUS

Metadata:
      Comment: Install a simple Apache HTTP page
      AWS::CloudFormation::Init:
        config:
          packages:
            yum:
              httpd: []
          files:
            "/var/www/html/index.html":
              content: |
                <h1>Hello World from EC2 instance!</h1>
                <p>This was created using cfn-init</p>
              mode: '000644'
          commands:
            hello:
              command: "echo 'hello world'"
          services:
            sysvinit:
              httpd:
                enabled: 'true'
                ensureRunning: 'true'

  SampleWaitCondition:
    CreationPolicy:
      ResourceSignal:
        Timeout: PT3M
        Count: 1
    Type: AWS::CloudFormation::WaitCondition
```

위 예제에서 timeout과 count를 포함하는 생성 정책이 있다.
우리가 하나 이상으로 카운트를 정의하면 하나 이상의 리소스가 CloudFormation에게 성공 신호를 전달하는 것이다.

예를 들어 CloudFormation은 EC2 인스턴스를 시작하고 WaitCondition이 발생할 것이다. EC2 인스턴스는 cfn-init을 실행할 것이고 init 데이터를 검색하지만, init 데이터 바로 뒤에 cfn-signal에서 신호를 수행하여 WaitCondition에서 데이터를 다시 CloudFormation으로 전달한다.

```yaml
UserData: 
        Fn::Base64:
          !Sub |
            #!/bin/bash -x
            # Get the latest CloudFormation package
            dnf update -y aws-cfn-bootstrap
            # Initialize EC2 Instance
            /opt/aws/bin/cfn-init -v --stack ${AWS::StackName} --resource MyInstance --region ${AWS::Region}
            # Get result of last command
            INIT_STATUS=$?
            # send result back using cfn-signal
            /opt/aws/bin/cfn-signal -e $INIT_STATUS --stack ${AWS::StackName} --resource SampleWaitCondition --region ${AWS::Region}
            # exit the script
            exit $INIT_STATUS
```

여기 스크립트가 조금 다른 yaml 파일이 있다. 이전과 마찬가지로 cfn-init을 실행하는데, 마지막 명령의 결과를 INIT_STATUS라는 변수에 저장한다. 그래서 cfn-init이 성공했다면 변수는 0이 될것이다. 실패할 경우 0이 아닌 다른 오류 코드 가 될 것이다.

cfn-signal 스크립트에 INIT_STATUS를 전달하고 최종적으로 CloudFormation에 결과를 전송한다.

WaitCondition에서 Count 1 에 해당하는 신호를 받는데까지 대기하는 시간(타임아웃)은 2분이다. 2분 내에 아무것도 받지 못하면 실패하고 성공 또는 실패 시그널을 받는다.

최종적으로 정리하자면 /opt/aws/bin/cfn-init 스크립트를 실행하고 실행한 결과를 변수화 해 /opt/aws/bin/cfn-signal 스크립트에서 사용해 CloudFormation으로 전송하며, WaitCondition은 /opt/aws/bin/cfn-signal 에서 정상적인 신호를 받을 때까지 기다리는 것이다. 

**정리**
-   cfn-signal 스크립트는 cfn-init 스크립트를 실행한 후 올바르게 구성 되었는지 여부를 알 수 있는 방법이다.
-   cfn-init 스크립트가 실행된 직후 cfn-signal 스크립트를 실행하고 리소스 생성이 성공했는지 실패했는지 CloudFormation에 알려준다.
-   필수적으로 WaitCondition을 정의해야 하는데 이는 템플릿이 cfn-signal로부터 신호를 받을때까지 기다린다.
    -   CreationPolicy와 Type을 WaitCondition으로 지정해주어 하나 이상의 성공 신호를 확인해 2분의 타임아웃 시간동안 스크립트가 정상적으로 수행 되었는지 확인하는 것이다.
-   최종적으로 cfn-signal 스크립트는 cfn-init 스크립트를 실행하고 실행한 결과를 cfn-signal 스크립트에서 사용하고 CloudFormation으로 전송하고 WaitCondition은 cfn-signal에서 정상적인 신호를 받을 때까지 기다린다.


## **CloudFormation - cfn-signal Failures**

```yaml
# 실패 스크립트
UserData: 
        Fn::Base64:
          !Sub |
            #!/bin/bash -x
            # Get the latest CloudFormation package
            dnf update -y aws-cfn-bootstrap
            # Initialize EC2 Instance
            /opt/aws/bin/cfn-init -v --stack ${AWS::StackName} --resource MyInstance --region ${AWS::Region}
            # Get result of last command
            INIT_STATUS=$?
            # send result back using cfn-signal
            /opt/aws/bin/cfn-signal -e $INIT_STATUS --stack ${AWS::StackName} --resource SampleWaitCondition --region ${AWS::Region}
            # exit the script
            exit $INIT_STATUS

Metadata:
      Comment: Install a simple Apache HTTP page
      AWS::CloudFormation::Init:
        config:
          packages:
            yum:
              httpd: []
          files:
            "/var/www/html/index.html":
              content: |
                <h1>Hello World from EC2 instance!</h1>
                <p>This was created using cfn-init</p>
              mode: '000644'
          commands:
            hello:
              command: "echo 'boom' && exit 1"
          services:
            sysvinit:
              httpd:
                enabled: 'true'
                ensureRunning: 'true'

   SampleWaitCondition:
    CreationPolicy:
      ResourceSignal:
        Timeout: PT3M
        Count: 1
    Type: AWS::CloudFormation::WaitCondition
```

WaitCondition이 EC2 인스턴스로부터 필요한 수의 신호를 수신하지 못했다는 문제가 일반적으로 많이 나온다.

여기에 몇 가지 이유가 있다.

사용 중인 AMI에 CloudFormation helper scripts가 설치되지 않았을 수 있다.
스크립트가 포함되어 있지 않다면 인스턴스에 설치하면 된다.

또한 cfn-init 및 cfn-signal 명령의 출력도 확인해야 한다. 몇 개의 로그 파일을 통해 이 명령어들이 어떻게 실행되었는지에 대한 많은 정보를 얻을 수 있다.

인스턴스에 액세스하려면 먼저 CloudFormation의 롤백 기능을 비활성화해야한다.
비활성화 하지 않는다면 실패한 EC2 인스턴스가 실패 상태가 되자마자 자동으로 CloudFormation이 삭제 상태가 되어 삭제되기 때문에 실제로 무슨 일이 발생했는지 파악하기 위함이다.

또한 EC2 인스턴스가 인터넷에 액세스할 수 있는지 확인해야 한다.

그리고 오류 발생 여부를 확인해야 한다. 위 예제에서 볼 수 있듯이 `commands: ` 항목을 확인해보면 echo boom 뒤에 exit 1을 실행한다.

상태코드 0이 아닌 1을 반환하므로 cfn-init 명령어는 1의 코드를 갖고 있게 되고 INIT_STATUS 변수에 1이 저장되며 CloudFormation에는 1 오류 상태를 전달하게되어 CloudFormation이 실패하게 될 것이다.

앞서 말했듯이 위와 같은 실패 상황에서 디버깅을 위해선 rollback 설정을 해제해야한다.

**정리**
-   cfn-signal에서 WaitCondition이 EC2 인스턴스로부터 필요한 수의 신호를 받지 못했다는 문제가 시험에서 많이 나온다고 한다.
-   아래의 이유로 신호를 받지 못한다.
    -   사용 중인 AMI에 CloudFormation helper scripts가 설치되지 않은 경우
    -   EC2 인스턴스가 인터넷에 액세스할 수 있는지
    -   특정 이유로 상태 코드가 0이 아닌 경우
-   cfn-init 및 cfn-signal 명령의 출력을 확인해보면 원인을 찾을 수 있다. 두 파일 모두 명령어들이 어떻게 실행되었는지 확인할 수 있다.
-   또한 인스턴스에서 실제로 무슨 일이 발생했는 지 확인하려면 CloudFormation Rollback 설정을 해제해야 한다.

## **CloudFormation - Nested Stacks**

Nested Stack(중첩 스택)은 다른 스택 안에 있는 스택이다.

중첩 스택을 사용하면 반복되는 패턴과 공통 구성 요소를 별도의 스택에서 분리한 다음 다른 스택에서 호출할 수 있다.

예를 들어 재사용되는 로드 밸런서 구성이 있는 경우 이를 중첩 스택으로 구성할 수 있다. 

중첩된 스택을 업데이트하기 위해서는 항상 상위 스택을 업데이트 해야한다. 루트 스택과 중첩된 스택은 그 자체 안에 중첩된 스택을 가질수 있다. 중첩된 스택안에 중첩된 스택을 다시 넣을수 있어 매우 깊이 들어갈 수 있다.

Cross Stack(교차 스택)이라는 개념도 있다. 교차 스택의 경우 스택의 수명 주기가 다를 때 매우 유용하다.

예를 들어 VPC 스택이 있고 일부 변수를 출력으로 내보내 Application 스택으로 내보내는 경우 즉, 스택 간에 값을 전달해야 할 때 매우 편리하다.

중첩 스택의 경우 재사용해야 하는 컴포넌트가 있는 경우 유용하다. 예를 들어 한 애플리케이션 스택을 구성할 때 RDS 스택, ASG 스택, ELB 스택을 생성해야 할 경우 또 다른 인스턴스를 생성하게 되면 이전에 생성했던 것과는 다른 각각의 RDS 스택, ASG 스택, ELB 스택을 생성하게 된다.

상황에 따라 교차 스택과 중첩 스택을 다르게 사용해야한다.

```yaml
Resources:
  MyKeyPair:
    Type: AWS::EC2::KeyPair
    Properties:
      KeyName: DemoKeyPair
      KeyType: rsa

  myStack:
    Type: AWS::CloudFormation::Stack
    Properties:
      TemplateURL: https://s3.amazonaws.com/cloudformation-templates-us-east-1/LAMP_Single_Instance.template
      Parameters:
        KeyName: !Ref MyKeyPair
        DBName: "mydb"
        DBUser: "user"
        DBPassword: "pass"
        DBRootPassword: "passroot"
        InstanceType: t2.micro
        SSHLocation: "0.0.0.0/0"

Outputs:
  StackRef:
    Value: !Ref myStack
  OutputFromNestedStack:
    Value: !GetAtt myStack.Outputs.WebsiteURL
```

중첩 스택의 경우 Resources 안에 스택을 지정해서 사용한다. 
위 예제에서는 스택의 위치를 TemplateURL로 지정하고 해당 스택에 있는 파라미터를 불러온다.

CAPABILITY_AUTO_EXPAND는 중첩스택을 사용하는 스택을 생성할 때 반드시 필요하니 유의해야한다.

**정리**
-   Nested Stack은 다른 스택 안에 있는 스택이다.
-   반복되는 패턴과 공통 구성 요소를 별도의 스택에서 분리한 다음 다른 스택에서 호출하기 위해 중첩된 스택을 사용한다.
-   중첩된 스택을 업데이트하려면 항상 상위 스택을 업데이트 해야한다.
-   중첩된 스택안에 다시 중첩된 스택을 넣을 수 있어 매우 깊게 들어갈 수 있다.
-   교차 스택이라는 개념도 있다. 교차 스택은 스택의 수명 주기가 다를 때 매우 유용하다.
-   예를 들어 VPC 스택의 일부 변수를 출력으로 내보내 Applicaion 스택으로 내보내는 것과 같이 한 스택의 출력을 다른 스택에서 사용하는 경우 편리하다.
-   CAPABILITY_AUTO_EXPAND는 중첩 스택을 사용하는 스택을 생성할 때 반드시 필요하니 반드시 유의해야한다.

## **CloudFormation - Depends On**

DependsOn은 리소스 생성을 위한 특정 순서를 지정할 수 있는 방법이다.

예를들어 EC2 인스턴스와 RDS 데이터베이스를 템플릿에 기재해놓고 DependsOn DBInstance를 추가한다면 DB 인스턴스가 먼저 성공적으로 생성되어야만 EC2 인스턴스가 생성된다.

사실 intrinsic function(내장 함수)를 사용하면 CloudFormation은 특정 리소스에 대해 의존적이게 만들 수 있다.

예를 들어 EC2 인스턴스를 생성할 때 특정 보안 그룹을 !Ref 내장 함수로서 불러오게끔 하면 특정 보안 그룹을 먼저 생성한 뒤 EC2 인스턴스를 생성하게 된다.

그러나 Ref 함수나 GetAtt 함수를 사용해 연결하지 않는 경우에는 DependsOn 속성을 사용해 연결할 수 있으며, 이는 모든 리소스에서 작동한다.

```yaml
Resources:
  MyEC2Instance:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: ami-0a3c3a20c09d6f377
      InstanceType: t2.micro

  MyBucket:
    Type: AWS::S3::Bucket
    DependsOn: MyEC2Instance
```

위와 같은 예제 코드에서 Mybucket을 생성할 때 DependsOn 속성이 MyEC2Instance로 할당되어 있어 MyEC2Instance가 생성되지 않는 한 S3는 생성되지 않는다.

EC2 인스턴스가 생성 완료되자마자 MyBucket이 생성될 것이다.

그리고 DependsOn 속성은 삭제에서도 똑같이 작용된다.
생성된 역순으로 삭제가 된다. 
S3 버킷이 삭제된 이후에 인스턴스가 삭제될 것이다.

**정리**
-   DependsOn은 리소스 생성을 위한 특정 순서를 지정할 수 있다. 예를 들어 특정 리소스가 먼저 생성되어야만 다음 리소스를 생성할 수 있게 설정할 수 있다.
-   사실 Intrinsic Function을 사용하면 CloudFormation은 특정 리소스에 대해 의존적이게 만들 수 있다. 예를 들어 !Ref 나 !GetAtt 함수를 사용해 특정 리소스들을 연결한다면 의존적이다.
-   DependsOn은 삭제에서도 똑같이 동작한다. 의존적인 리소스부터 의존을 받고있는 리소스로의 순서로 삭제된다.

## **CloudFormation - StackSets**
스택셋은 한 번의 작업으로 여러 계정과 Region에 걸쳐 스택을 배포할 수 있는 방법이다.

관리자 계정으로 스택 셋을 만들고 대상 계정은 스택 셋에서 인스턴스를 생성, 적용 및 삭제하는 데만 사용하도록 할 수 있다.

관리자 계정에서 스택 셋을 업로드하고 업데이트하면 모든 대상 계정이 모든 리전에서 이 업데이트를 받게 된다.

또한 대상 계정과 관리자 계정을 정의하기 위해 AWS Organization 내의 계정에 이를 적용할 수도 있다.

관리자 계정과 대상 계정의 개념이 있기 때문에 두 계정 모두 권한이 있어야한다. 

그래서 관리자 계정과 대상 계정 모두 신뢰 관계(Trust Relationship)가 있는 IAM 역할을 만들어 놓고 해당 역할을 이용해 CloudFormation 템플릿을 대상 계정에 배포할 수 있다.

따라서 관리자 계정에는 모든 대상 계정의 모든 AWSCloudFormationStackSetExecutionRole과 신뢰 관계를 갖는 AWS AWSCloudFormationStackSetAdministrationRole 역할이 있다.
실행 역할 - 관리 역할 두 역할이 있다고 생각하면 된다.

AWS Organization을 사용하지 않는 경우 이러한 역할을 수동으로 생성해야 함.

수동으로 생성하는 경우 관리자 계정에서 역할을 생성할 때 AWSCloudFormationStackSetAdministrationRole라는 명확한 이름을 가진 역할을 생성해야하고 신뢰 관계도 설정해주어야한다.
또한 대상 계정에서 AWSCloudFormationStackSetExecutionRole라는 명확한 이름을 가진 역할을 생성하고 해당 역할에서 CloudFormation이 실행할 수 있는 모든 정책을 허용해줘야한다.

Organization을 사용하는 경우 자동으로 Organization이 사용자를 대신해 IAM 역할을 생성한다.

이러한 작업을 하려면 Organization 및 모든 기능 내에서 "trusted access"를 사용하도록 설정해야 하며, 향후 조직의 새 계정을 포함해 모든 새 계정에 자동으로 배포할 수 있다.

하나의 스택이 생성되는 즉시 모든 계정에 스택을 자동으로 배포하도록 설정할 수도 있다.

보안 및 거버넌스 목적으로 Organization의 특정 구성원 계정에 스택 셋 관리를 위임할수도 있다. 위임된 관리자가 Organization에서 관리하는 계정에 배포할 수 있도록 조직 내에서 trusted access를 활성화 해야한다.

**정리**
-   스택 셋은 한 번의 작업으로 여러 계정과 Region에 걸쳐 스택을 배포할 수 있는 방법이다.
-   관리자 계정에서 스택 셋을 만들고 대상 계정은 스택 셋에서 인스턴스와 같은 자원을 생성, 적용 및 삭제하는 데만 사용하도록 할 수 있다. 업데이트 또한 동일하게 관리자 계정에서만 해주면 모든 대상 계정이 업데이트를 받게 된다.
-   하나의 스택이 생성되는 즉시 모든 계정에 스택을 자동으로 배포하도록 설정할 수도 있다.
-   AWS Organization을 사용하면 관리자 계정과 대상 계정에 대한 권한 관리를 쉽게 할 수 있다. 관리자 계정이 조직 내의 모든 기능을 수행하려면 "Trusted access"를 사용하도록 설정해야 한다.
-   Organization을 사용해주지 않으면 수동으로 IAM 역할을 생성해야한다.
-   보안 및 거버넌스 목적으로 Organization의 특정 구성원 계정에 스택 셋 관리를 위임할 수도 있다. 이 또한 위임된 관리자가 대상 계정에 배포할 수 있도록 "Trusted access"를 사용하도록 해야한다.

## **CloudFormation - Troubleshooting**

DELETE_FAILED 상태에서 확인해야할 사항이 있다.

S3 버킷과 같이 삭제 전에 비워져야 하는 일부 리소스가 있는 경우가 있다. S3 버킷을 수동으로 비우거나 Lambda 함수와 함께 Custom Resources를 사용해 S3 버킷 비우기 작업을 자동화할 수 있다.

Stack 내부에 없는 인스턴스가 Stack 내부의 보안 그룹을 사용 중인 경우 보안 그룹을 삭제할 수 없다.

특정 리소스의 삭제에 문제가 있는 경우 DeletionPolicy=Retain을 사용해 해당 리소스의 삭제를 건너 뛸 수 있다.

UPDATE_ROLLBACK_FAILED가 발생하면 업데이트가 실패하고 롤백이 시도되었지만 롤백도 실패했음을 의미한다.

CloudFormation 외부에서 변경된 리소스, 충분하지 않은 IAM 권한, 충분한 signal을 받지 못하는 Auto Scaling Group이 이유가 될 수 있다.

이 경우 오류를 수동으로 수정하여 해결하고 이것이 작동하는지 확인해야한다. 보통 이벤트 로그가 힌트를 제공해줄 것이다.

오류가 수정되었다면 ContinueUpdateRollback이라는 API 호출을 해야한다. 롤백이 계속 진행되고, 오류가 완벽히 수정된 경우 최종적으로 롤백이 성공할 것이다.

이번엔 StackSets 문제 해결이다.

스택 작업이 실패하고 스택 인스턴스 상태가 OUTDATED로 나타날 수 있다.

이는 템플릿에서 지정된 리소스를 생성하는 데 필요한 대상 계정의 충분한 권한이 없는 문제일 수 있다.

또는 템플릿이 전역 리소스를 생성하려고 하지만 해당 리소스는 고유해야 하는 경우이다. 예를들어 S3 버킷의 이름은 고유해야 하며 템플릿에서 고정적으로 이름이 지정된 경우 한 스택에서는 작동하지만 다른 계정이나 Region에서는 이미 사용중인 이름으로 인식될 것이다.

또는 Trusted Relationship에 문제가 있을 수 있다.
예를 들어 관리자 계정이 대상 계정과 필요한 신뢰 관계가 없을 수 있다.

또는 StackSets는 동일한 스택을 여러 계정에 배포하기 때문에 권한, 할당량, 리소스 이름 등에 따라 일부 계정에서 작동하지 않을 수 있어 더 고려해봐야 한다.

**정리**
-   스택이 DELETE_FAILED가 발생하면 확인해야할 사항이 있다.
    -   S3 버킷과 같이 삭제 전에 반드시 비워져야하는 일부 리소스를 확인해야한다. S3 버킷을 수동으로 지우거나 Lambda 함수와 함께 Custom Resources를 사용해 S3 버킷을 비워야한다.
    -   Stack 내부에 없는 인스턴스가 Stack 내부의 보안 그룹을 사용 중인 경우 보안 그룹을 삭제할 수 없다.
-   UPDATE_ROLLBACK_FAILED가 발생하면 업데이트가 실패하고 롤백이 시도 되었지만 롤백도 실패했음을 의미한다.
    -   CloudFormation 외부에서 변경된 리소스, 충분하지 않은 IAM 권한, 충반한 signal을 받지 못한느 Auto Scaling Group이 이유가 될 수 있다.
    -   위와 같은 경우 오류를 수동으로 수정하여 해결하고 이것이 작동하는지 확인해야 한다. 보통 이벤트 로그가 힌트를 제공해줄 것이다.
    -   모든 오류를 수정하면 ContinueUpdateRollback이라는 API 호출을 해야한다. 롤백이 계속 진행되고 오류가 수정된 경우 롤백이 성공할 것이다.
-   특정 리소스를 삭제하는 데 문제가 있는 경우 DeletionPolicy=Retain을 사용해 해당 리소스의 삭제를 건너뛰고 문제를 찾아볼 수 있다.
-   StackSets에도 문제가 발생한다.
    -   스택 상태가 OUTDATED로 나타날 수 있다.
    -   이 경우 템플릿에서 지정된 리소스를 생성하는 데 필요한 대상 계정의 충분한 권한이 없어서 발생하는 문제일 수 있다.
    -   템플릿이 전역 리소스를 생성하려 하지만 S3 버킷의 이름처럼 고유해야 하는 경우 리소스가 생성이 안될 수도 있다.
    -   Trusted Relationship에 문제가 있을 수 있다. 대상 계정에 관리자 계정에 대한 신뢰 관계가 제대로 설정되어 있지 않을 수 있다.
    -   StackSets는 동일한 스택을 여러 계정에 배포하기 때문에 권한, Quota, 리소스 이름에 따라 일부 계정에서 작동하지 않을 수 있어 꼼꼼히 고려해야 한다.
   
## **Lambda - Overview**

람다는 무엇일까요?
먼저 EC2를 먼저 생각해보면 EC2는 클라우드의 가상 서버이고, 인스턴스를 프로비저닝 해야한다.

우리는 프로비저닝한 인스턴스 타입 별 메모리와 CPU 양에 제한을 받는다.

인스턴스는 계속해서 실행되고 중지하고 재시작하는 과정에서 최적화할 수 있지만 그렇지 않으면 인스턴스는 계속 실행된다.

확장이 필요하면 ASG를 이용할 수 있지만 자동으로 서버를 추가하고 제거하기 위해 추가적인 작업이 수행된다는 것을 의미한다.

Lambda는 서버리스 함수이며, 관리할 서버가 없다.

코드를 프로비저닝하고 함수를 실행할 뿐이다.

최대 15분까지의 짧은 실행 시간을 가지고 있으며 시간에 제한이 있다.
강사의 의견으로는 그리 짧지 않다고 한다.

요청이 발생할 때 실행되며, Lambda를 사용하지 않으면 함수가 실행되지 않고 함수가 실행될 때만 요금이 청구된다.

함수 인스턴스 및 동시성이 필요한 경우 자동으로 AWS가 더 많은 Lambda 함수를 프로비저닝한다.

Lambda는 여러가지 이점이 있다.
-   가격을 책정하는 게 매우 간단하다.
    -   호출 횟수(Lambda가 수신한 요청 수)와 실행 시간(Lambda가 실행되었던 컴퓨터 시간)에 대해 지불하게 된다.
-   많은 종류의 서비스와 통합되어 있다.
    -   여러 가지 프로그래밍 언어를 사용할 수 있어 자유롭다.
-   CloudWatch와의 모니터링 통합이 매우 쉽다.
-   함수당 최대 10GB의 RAM을 프로비저닝할 수 있다.
-   함수의 RAM을 늘리면 CPU 및 네트워크의 품질과 성능도 같이 향상된다.

Lambda는 여러 언어를 지원한다.
node.js(JavaScript), Python, Java(Java 8 호환 또는 Java 11), .NET Core의 C#, Golang, Powershell을 위한 C#, Ruby 등의 다양한 언어를 지원하게 된다.

Lambda의 사용자 지정 런타임 API 덕분에 거의 모든 언어를 Lambda 용으로 작성할 수 있다. 예를 들어 Lambda에서 Rust 언어 Function을 실행하려면 오픈 소스 프로젝트로 사용 가능하다.

Lambda 컨테이너 이미지를 지원한다.
Lambda 컨테이너 이미지는 이미지 자체 Lambda 런타임 API를 구현해야 하므로 Lambda에서 실행할 수 있는 임의의 컨테이너 이미지는 아니다.

Lambda에서 컨테이너를 실행하려는 경우 해당 컨테이너가 Lambda 런타임 API를 구현하지 않은 경우 해당 컨테이너를 ECS 또는 Fargate에서 실행해야 한다.

Lambda는 다양한 서비스와 통합되어 사용된다.
-   API Gateway는 REST API를 생성하고 Lambda 함수를 호출하는 데 사용된다.
-   Kinesis는 Lambda를 사용해 데이터를 실시간으로 변환한다.
-   DynamoDB는 트리거를 생성하는 데 사용된다. DB에 무언가 발생할 때 Lambda 함수가 트리거된다.
-   S3에 파일이 생성될 때마다 트리거된다.
-   CloudFront는 Lambda@Edge를 사용한다.
-   CloudWatch 이벤트 또는 EventBridge는 AWS 인프라에서 이벤트가 발생할 때 반응할 수 있도록 한다. 예를 들어 빌드 파이프라인 상태가 변경되면 그에 기반한 자동화를 수행하고 싶을 때 Lambda 함수를 사용할 수 있다.
-   CloudWatch Logs는 로그를 어디서든 스트리밍할 수 있다.
-   SNS 주제에서 알림에 반응하는 데 Lambda가 사용된다.
-   SQS 대기열에서 메시지를 처리하는 데 사용된다.
-   Cognito는 예를 들어 사용자가 데이터베이스에 로그인할 때 반응하는 데 사용된다.

예를 들어 Lambda를 이용해 서버리스 썸네일 생성을 할 수 있다.
S3에 새 이미지가 업로드 되면 S3 이벤트 알림을 통해 Lambda 함수가 트리거 되고 썸네일이 생성된다. 생성되는 동시에 이미지에 대한 일부 메타데이터를 DynamoDB에 삽입 할 수도 있다.

그리고 또 다른 예는 Cron 작업이 있다.
기존 EC2의 방법으로 Cron 작업을 하게 되면 EC2에 상태 변화가 있거나 Cron이 제대로 동작하지 않을 가능성이 있다.
그래서 CloudWatch 이벤트 규칙 또는 EventBridge 규칙을 생성하고 Lambda 함수와 통합해 같은 작업을 수행할 수 있다.

람다는 호출당 비용을 지불한다. 처음 100만 요청은 무료이고, 추가 100만 요청당 20센트를 지불하게 된다.

또한 시간 대비 비용을 지불한다.

1달을 기준으로 400,000GB/sec 가 무료이다.
함수가 1 기가바이트의 RAM을 갖는 경우 실행 시간이 400,000 초까지 제공된다.
128 MB의 RAM을 갖는 경우 실행 시간이 3,200,000 초까지 제공된다.

그 이후로는 600,000GB/sec 당 1$가 부과된다.

굉장히 싼 요금 부과 정책이다.

## **Lambda & CloudWatch Events / EventBridge**

CloudWatch Events 또는 EventBridge를 Lambda와 통합하는 방법에 대해 이야기 해보자

첫 번째는 서버리스 Cron 또는 Rate 기반 EventBridge Rule을 사용하는 것이다.
예를 들어 EventBridge 규칙을 생성해 1시간마다 람다 함수가 작업을 수행하도록 트리거하는 것이다.

또는 코드 파이프라인 상태가 변경될 때마다 감지하고 상태 변경시 Lambda 함수를 호출하여 작업을 수행하도록 하는 CodePipeline EventBridge 규칙을 만들 수도 있다.

## **Lambda & S3 Event Notifications**

S3 Event Notification과 Lambda를 통합하는 방법을 알아보자

S3 Event Notification은 개체가 생성, 제거, 복원, 복제가 일어날 때마다 알림을 받을 수 있는 방법이다.
접두사 및 접미사 별로 필터링할 수 있다. 예: *.jpg

가장 일반적인 사용 사례는 S3에 업로드된 모든 이미지의 썸네일 이미지를 생성하는 것이다.

S3에 이벤트가 발생하면 S3에서는 이를 세 곳으로 보낼 수 있는데
1.  SNS와 SNS 토픽에서 팬 아웃 패턴을 수행해 여러 SQS Queue로 보내거나, 
2.  SQS Queue로 보내서 람다 함수가 해당 SQS Queue를 직접 읽도록 하거나, 
3.  S3 Event Notification이 람다 함수를 직접 비동기 호출로 호출하는 방법이 있다. 그리고 이 람다 함수는 해당 데이터로 원하는 모든 작업을 수행할 수 있으며, 문제가 발생할 경우 Dead Letter Queue를 설정할 수도 있다.

S3 Event Notification은 일반적으로 몇 초 안에 이벤트를 전달하지만 때로는 1분 이상 걸릴 수 있으므로 이벤트 알림을 놓치지 않으려면 버킷에서 버전 관리를 활성화 해야한다.
그렇지 않으면 같은 개체에 대해 두 개의 쓰기가 동시에 발생하는 경우 알림을 두 개가 아닌 한개만 받을 수 있다.

메타데이터를 동기화하는 패턴이 있다.
S3 버킷에 새 파일 이벤트가 Lambda로 전송된다.
그리고 Lambda 함수는 해당 파일을 처리해 해당 데이터를 DynamoDB 테이블 또는 RDS 데이터베이스의 테이블에 삽입할 수도 있다.

## **Lambda Permissions - IAM Roles & Resource Policies**

람다 실행 역할과 권한에 대해 이야기 해보자

람다 함수에 IAM 역할을 연결해야하고, 이렇게 하면 람다 함수에 AWS 서비스 및 리소스에 액세스할 수 있는 권한이 부여된다.

그리고 관리형 정책을 사용할수도 있다.

예를들어
- AWSLambdaBasicExecutionRole 을 이용해서 CloudWatch에 Log를 업로드하거나,
- AWSLambdaKinesisExecutionRole 를 이용해서 Kinesis에서 읽어오거나
- AWSLambdaDynamoDBExecutionRole 를 이용해서 DynamoDB 스트림에서 읽어 오거나
- AWSLambdaSQSQueueExecutionRole 를 이용해서 SQS에서 읽어오거나
- AWSLambdaVPCAccessExecutionRole 를 이용해서 VPC 내부에 Lambda 함수를 배포할 수 있게 하거나
- AWSXRayDaemonWriteAccess 를 이용해서 trace data를 X-Ray에 업로드하는

여러가지의 관리형 정책이 있다. 람다에 대한 자체 정책을 만들 수도 있다.

따라서 이벤트 소스 매핑을 사용해 함수를 호출하는 것을 사용할 때 람다는 실행 역할을 사용해서 이벤트 데이터를 읽어온다. 그래서 이벤트 데이터를 읽으려면 실행 역할을 사용해야 한다.

반면에 Lambda 함수는 통상 다른 서비스에서 호출되므로 특정 권한이 있는 특정 IAM 역할이 필요하지 않다.

그런데 함수당 하나의 람다 실행 역할을 만드는 것이 가장 좋은 방법이다.

이벤트 소스 매핑을 위한 것이거나 람다 함수가 실제로 다른 서비스를 호출해야 하지만 다른 서비스에서 람다 하수를 호출하는 경우에 리소스 기반 정책을 사용하는데, 이것은 다른 계정이나 다른 AWS 서비스에 람다 리소스를 사용할 수 있는 권한을 부여해 함수에서 이를 호출하는 것이며, 이것은 Amazon S3 버킷의 S3 버킷 정책과 매우 유사하다.

따라서 다음 두 가지 중 하나에 해당하는 경우 IAM 원칙에 따라 Lambda 함수에 액세스할 수 있다.

첫째로는 principal에 연결된 IAM 정책이 승인한다.
예를 들어 IAM 사용자가 있고 전체 권한을 가지고 있어 관리자 액세스 정책 덕분에 람다 함수에 액세스할 수 있다.

두번째로는 리소스 기반 정책을 통해 람다 함수에 대한 액세스 권한을 부여하는 경우 서비스 대 서비스 액세스 권한이 있을 때 더 유용하다.

Amazon S3와 같은 다른 AWS 서비스에서 람다 함수를 호출하려는 경우 리소스 기반 정책을 통해 액세스 권한을 부여해야 한다.
